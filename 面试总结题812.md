面试总结题

## URL链接

https://www.iamshuaidi.com/1864.html

https://www.iamshuaidi.com/1346.html

https://www.iamshuaidi.com/1402.html

https://www.zhihu.com/column/c_1104074839660294144

https://lailin.xyz/post/go-design-pattern.html

https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/

https://segmentfault.com/a/1190000021468353

## go语言
### go语言优势/为什么用go

直接编译成机器码，不依赖其他库，glibc的版本有一定要求，部署就是扔一个文件上去就完成了。
静态类型语言，但是有动态语言的感觉，静态类型的语言就是可以在编译的时候检查出来隐藏的大多数问题，动态语言的感觉就是有很多的包可以使用，写起来的效率很高。
语言层面支持并发，这个就是Go最大的特色，天生的支持并发，Go就是基因里面支持的并发，可以充分的利用多核，很容易的使用并发。
内置runtime，支持垃圾回收，这属于动态语言的特性之一吧，虽然目前来说GC不算完美，但是足以应付我们所能遇到的大多数情况，特别是Go1.1之后的GC。
简单易学，Go语言的作者都有C的基因，那么Go自然而然就有了C的基因，那么Go关键字是25个，但是表达能力很强大，几乎支持大多数你在其他语言见过的特性：继承、重载、对象等。
丰富的标准库，Go目前已经内置了大量的库，特别是网络库非常强大，我最爱的也是这部分。
内置强大的工具，Go语言里面内置了很多工具链，最好的应该是gofmt工具，自动化格式化代码，能够让团队review变得如此的简单，代码格式一模一样，想不一样都很困难。
跨平台编译，如果你写的Go代码不包含cgo，那么就可以做到window系统编译linux的应用，如何做到的呢？Go引用了plan9的代码，这就是不依赖系统的信息。
内嵌C支持，前面说了作者是C的作者，所以Go里面也可以直接包含c代码，利用现有的丰富的C库。

### 1.golang的垃圾回收机制？
#### Golang 垃圾回收/GC过程

Golang的垃圾回收（GC）算法使用的是无无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。原因在于：

- 对象整理的优势是解决内存碎片问题以及“允许”使用顺序内存分配器。但 Go 运行时的分配算法基于`tcmalloc`，基本上没有碎片问题。 并且顺序内存分配器在多线程的场景下并不适用。Go 使用的是基于`tcmalloc`的现代内存分配算法，对对象进行整理不会带来实质性的性能提升。
- 分代`GC`依赖分代假设，即`GC`将主要的回收目标放在新创建的对象上（存活时间短，更倾向于被回收），而非频繁检查所有对象。
- Go 的编译器会通过逃逸分析将大部分新生对象存储在栈上（栈直接被回收），只有那些需要长期存在的对象才会被分配到需要进行垃圾回收的堆中。也就是说，分代`GC`回收的那些存活时间短的对象在 Go 中是直接被分配到栈上，当`goroutine`死亡后栈也会被直接回收，不需要`GC`的参与，进而分代假设并没有带来直接优势。
- Go 的垃圾回收器与用户代码并发执行，使得 STW 的时间与对象的代际、对象的 size 没有关系。Go 团队更关注于如何更好地让 GC 与用户代码并发执行（使用适当的 CPU 来执行垃圾回收），而非减少停顿时间这一单一目标上。

|       阶段       |                            说明                            | 赋值器状态 |
| :--------------: | :--------------------------------------------------------: | :--------: |
| SweepTermination | 清扫终止阶段，为下一个阶段的并发标记做准备工作，启动写屏障 |    STW     |
|       Mark       |         扫描标记阶段，与赋值器并发执行，写屏障开启         |    并发    |
| MarkTermination  |    标记终止阶段，保证一个周期内标记任务完成，停止写屏障    |    STW     |
|      GCoff       |    内存清扫阶段，将需要回收的内存归还到堆中，写屏障关闭    |    并发    |
|      GCoff       |    内存归还阶段，将过多的内存归还给操作系统，写屏障关闭    |    并发    |

#### **垃圾回收、三色标记原理**

垃圾回收就是对程序中不再使用的内存资源进行自动回收的操作。

#### 1.1 常见的垃圾回收算法：

##### 引用计数

：每个对象维护一个引用计数，当被引用对象被创建或被赋值给其他对象时引用计数自动加 +1；如果这个对象被销毁，则计数 -1 ，当计数为 0 时，回收该对象。

- 优点：对象可以很快被回收，不会出现内存耗尽或到达阀值才回收。
- 缺点：不能很好的处理循环引用

##### 标记清除：

从根变量开始遍历所有引用的对象，引用的对象标记“被引用”，没有被标记的则进行回收。

- 优点：解决了引用计数的缺点。
- 缺点：需要 STW（stop the world），暂时停止程序运行。

##### 分代收集：

按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。

- 优点：回收性能好
- 缺点：算法复杂

##### 标记整理算法（Mark-Compact）

为了提升内存的利用率，科学家提出了标记-整理算法，该算法的起始过程和标记-清除算法相同，先标记处待回收对象的内存区域，但是在清除时不是对所有可回收对象清除，而是让所有存活对象往内存空间的一边移动，把存活对象边界外的内存直接清空掉。
标记-整理算法提高了内存的利用率、解决了大对象分配时的内存碎片问题，看似完美的垃圾收集算法，也有它的弊端
在移动存活对象的过程中，需要全程暂停用户程序的执行，被设计者称为“Stop The World”。

#### 1.2 三色标记法

- 三色标记法将对象分为三类，并用不同的颜色相称：

  - 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。
  - 灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象。
  - 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。

  标记过程如下：

  （1）起初所有的对象都是白色的；

  （2）从根对象出发扫描所有可达对象，标记为灰色，放入待处理队列；

  （3）从待处理队列中取出灰色对象，将其引用的对象标记为灰色并放入待处理队列中，自身标记为黑色；

  （4）重复步骤（3），直到待处理队列为空，此时白色对象即为不可达的“垃圾”，回收白色对象；

  > 根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：

  1. 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。
  2. 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。
  3. 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。

#### 1.3 STW（Stop The World）

`STW` 可以是 `Stop the World` 的缩写，也可以是 `Start the World` 的缩写。通常意义上指指代从 `Stop the World` 这一动作发生时到 `Start the World` 这一动作发生时这一段时间间隔，即万物静止。STW 在垃圾回收过程中为了保证实现的正确性、防止无止境的内存增长等问题而不可避免的需要停止赋值器进一步操作对象图的一段过程。

- 为了避免在 GC 的过程中，对象之间的引用关系发生新的变更，使得GC的结果发生错误（如GC过程中新增了一个引用，但是由于未扫描到该引用导致将被引用的对象清除了），停止所有正在运行的协程。
- STW对性能有一些影响，Golang目前已经可以做到1ms以下的STW。

####  如何观察垃圾回收？

GODEBUG=gctrace=1

go tool trace

debug.ReadGCStats

runtime.ReadMemStats

#### 有了垃圾回收机制，为什么还会发生内存泄露？

预期能被快速释放的内存因被根对象引用而没有得到迅速释放

当有一个全局对象时，可能不经意间将某个变量附着在其上，且忽略的将其进行释放，则该内存永远不会得到释放。

goroutine 泄漏

Goroutine 作为一种逻辑上理解的轻量级线程，需要维护执行用户代码的上下文信息。在运行过程中也需要消耗一定的内存来保存这类信息，而这些内存在目前版本的 Go 中是不会被释放的。因此，如果一个程序持续不断地产生新的 goroutine、且不结束已经创建的 goroutine 并复用这部分内存，就会造成内存泄漏的现象。

#### 并发标记清除法的难点是什么/多并发垃圾回收出现的问题？

在没有用户态代码并发修改`三色抽象`的情况下，回收可以正常结束。但是并发回收的根本问题在于，用户态代码在回收过程中会并发地更新对象图，从而造成赋值器和回收器可能对对象图的结构产生不同的认知。

并发标记清除中面临的一个根本问题就是如何保证标记与清除过程的正确性。

- 初始状态：假设某个黑色对象 C 指向某个灰色对象 A ，而 A 指向白色对象 B；
- `C.ref3 = C.ref2.ref1`：赋值器并发地将黑色对象 C 指向（ref3）了白色对象 B；
- `A.ref1 = nil`：移除灰色对象 A 对白色对象 B 的引用（ref2）；
- 最终状态：在继续扫描的过程中，白色对象 B 永远不会被标记为黑色对象了（回收器不会重新扫描黑色对象），进而对象 B 被错误地回收。

![gc-mutator](https://golang.design/go-questions/memgc/assets/gc-mutator.png)

#### 1.4 写屏障(Write Barrier)

- 为了避免GC的过程中新修改的引用关系到--GC的结果发生错误，我们需要进行STW。但是STW会影响程序的性能，所以我们要通过写屏障技术尽可能地缩短STW的时间。保证**不应出现对象的丢失，也不应错误的回收还不需要回收的对象。**

可以证明，当以下两个条件同时满足时会破坏垃圾回收器的正确性：

- **条件 1**: 赋值器修改对象图，导致某一黑色对象引用白色对象；
- **条件 2**: 从灰色对象出发，到达白色对象的、未经访问过的路径被赋值器破坏。

只要能够避免其中任何一个条件，则不会出现对象丢失的情况，因为：

- 如果条件 1 被避免，则所有白色对象均被灰色对象引用，没有白色对象会被遗漏；
- 如果条件 2 被避免，即便白色对象的指针被写入到黑色对象中，但从灰色对象出发，总存在一条没有访问过的路径，从而找到到达白色对象的路径，白色对象最终不会被遗漏。

写屏障破坏两个条件其一即可

- 破坏条件1：Dijistra写屏障

满足强三色不变性：黑色节点不允许引用白色节点 当黑色节点新增了白色节点的引用时，将对应的白色节点改为灰色

Dijkstra 插入屏障的好处在于可以立刻开始并发标记。但存在两个缺点：

1. 由于 Dijkstra 插入屏障的“保守”，在一次回收过程中可能会残留一部分对象没有回收成功，只有在下一个回收过程中才会被回收；
2. 在标记阶段中，每次进行指针赋值操作时，都需要引入写屏障，这无疑会增加大量性能开销；为了避免造成性能问题，Go 团队在最终实现时，没有为所有栈上的指针写操作，启用写屏障，而是当发生栈上的写操作时，将栈标记为灰色，但此举产生了灰色赋值器，将会需要标记终止阶段 STW 时对这些栈进行重新扫描。



- 破坏条件2：Yuasa删除屏障

满足弱三色不变性：黑色节点允许引用白色节点，但是该白色节点有其他灰色节点间接的引用（确保不会被遗漏） 当白色节点被删除了一个引用时，悲观地认为它一定会被一个黑色节点新增引用，所以将它置为灰色

Yuasa 删除屏障的优势则在于不需要标记结束阶段的重新扫描，结束时候能够准确的回收所有需要回收的白色对象。缺陷是 Yuasa 删除屏障会拦截写操作，进而导致波面的退后，产生“冗余”的扫描

#### go垃圾回收解决三色标记法问题的方法

将 Dijkstra 插入屏障和 Yuasa 删除屏障进行混合，形成混合写屏障。该屏障提出时的基本思想是：**对正在被覆盖的对象进行着色，且如果当前栈未扫描完成，则同样对指针进行着色。**




**什么时候进行清理？**

主动触发（runtime.GC()）被动触发：使用系统监控，当超过两分钟没有产生任何 GC 时，强制触发 GC。使用步调（Pacing）算法，其核心思想是控制内存增长的比例。

#### 有了 GC，为什么还会发生内存泄露？
预期能被快速释放的内存因被根对象引用而没有得到迅速释放
当有一个全局对象时，可能不经意间将某个变量附着在其上，且忽略的将其进行释放，则该内存永远不会得到释放。
goroutine 泄漏 #
Goroutine 作为一种逻辑上理解的轻量级线程，需要维护执行用户代码的上下文信息。在运行过程中也需要消耗一定的内存来保存这类信息，而这些内存在目前版本的 Go 中是不会被释放的。因此，如果一个程序持续不断地产生新的 goroutine、且不结束已经创建的 goroutine 并复用这部分内存，就会造成内存泄漏的现象

#### 辅助垃圾回收/辅助gc，如果内存分配速度超过了标记清除的速度怎么办？

当 GC 触发后，会首先进入并发标记的阶段。并发标记会设置一个标志，并在 mallocgc 调用时进行检查。当存在新的内存分配时，会暂停分配内存过快的那些 goroutine，并将其转去执行一些辅助标记（Mark Assist）的工作，从而达到放缓继续分配、辅助 GC 的标记工作的目的。

#### Go 的垃圾回收如何调优？

最小化 Go 的 GC 对 CPU 的使用率（即调整 GOGC），遇到海量请求的时，为了避免 GC 频繁触发，是否可以通过将 GOGC 的值设置得更大，让 GC 触发的时间变得更晚，从而减少其触发频率，进而增加用户代码对机器的使用率

合理化内存分配的速度、提高赋值器的CPU 利用率

降低并复用已经申请的内存

### 2.GPM 调度 和 CSP 模型

**协程的深入剖析**

#### 2.1 CSP 模型？

CSP 模型是“以通信的方式来共享内存”，不同于传统的多线程通过共享内存来通信。用于描述两个独立的并发实体通过共享的通讯 channel (管道)进行通信的并发模型。Go 的并发原则非常优秀，目标就是简单：尽量使用 channel；把 goroutine 当作免费的资源，随便用。
#### 什么是调度器
Go 程序的执行由两层组成：Go Program，Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel 通信、goroutines 创建等功能。用户程序进行的系统调用都会被 Runtime 拦截，以此来帮助它进行调度以及垃圾回收相关的工作。

#### 为什么要调度器
Go scheduler 可以说是 Go 运行时的一个最重要的部分了。Runtime 维护所有的 goroutines，并通过 scheduler 来进行调度。Goroutines 和 threads 是独立的，但是 goroutines 要依赖 threads 才能执行。
Go 程序执行的高效和 scheduler 的调度是分不开的。
### 只用GM调度的缺点？
M 想要执行、放回 G 都必须访问全局 G 队列，并且 M 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。

老调度器有几个缺点：

创建、销毁、调度 G 都需要每个 M 获取锁，这就形成了激烈的锁竞争。
M 转移 G 会造成延迟和额外的系统负载。比如当 G 中包含创建新协程的时候，M 创建了 G’，为了继续执行 G，需要把 G’交给 M’执行，也造成了很差的局部性，因为 G’和 G 是相关的，最好放在 M 上执行，而不是其他 M’。
系统调用 (CPU 在 M 之间的切换) 导致频繁的线程阻塞和取消阻塞操作增加了系统开销。
#### 2.2 调度器原理/GPM 分别是什么、分别有多少数量？

- G: 它是Goroutine，存储了Goroutine的执行栈信息、Goroutine状态以及Goroutine的任务函数等（G是可以重用的）。主要保存 goroutine 的一些状态信息以及 CPU 的一些寄存器的值，例如 IP 寄存器，以便在轮到本 goroutine 执行时，CPU 知道要从哪一条指令处开始执行。当 goroutine 被调离 CPU 时，调度器负责把 CPU 寄存器的值保存在 g 对象的成员变量之中。当 goroutine 被调度起来运行时，调度器又负责把 g 对象的成员变量所保存的寄存器值恢复到 CPU 的寄存器。

- P: 代表一个虚拟的 处理器，它维护一个处于 Runnable 状态的 g 队列，`m` 需要获得 `p` 才能运行 `g`。P的数量决定了系统内最大可并行的G的数据（物理CPU核数>=P的数量）；P最大的作用是它有各种G对象队列、链表、缓存和状态。为 M 的执行提供“上下文”，保存 M 执行 G 时的一些资源，例如本地可运行 G 队列，memeory cache 等。一个 M 只有绑定 P 才能执行 goroutine，当 M 被阻塞时，整个 P 会被传递给其他 M ，或者说整个 P 被接管。

  M: 表示内核线程，包含正在运行的 goroutine 等字段。它是真正执行计算的资源。在绑定有效的P后，一个调度循环开始；而调度循环的机制是从各种队列、P的本地运行队列中获取G,切换到G的执行栈上并行执行G的函数，调用goexit做清理工作，然后回到M。这样反复。M并不保存G的状态，这是G可以跨M调度的基础。当 M 没有工作可做的时候，在它休眠前，会“自旋”地来找工作：检查全局队列，查看 network poller，试图执行 gc 任务，或者“偷”工作。它保存了 M 自身使用的栈信息、当前正在 M 上执行的 G 信息、与之绑定的 P 信息

G 需要在 M 上才能运行，M 依赖 P 提供的资源，P 则持有待运行的 G。你中有我，我中有你。

M 会从与它绑定的 P 的本地队列获取可运行的 G，也会从 network poller 里获取可运行的 G，还会从其他 P 偷 G。

#### 初始化过程/调度器的生命周期？
![img](https://www.topgoer.com/static/7.1/gmp/14.png)
M0

M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。

G0

G0 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。

> 在程序初始化时，这些全局变量都会被初始化为零值：指针被初始化为 nil 指针，切片被初始化为 nil 切片，int 被初始化为 0，结构体的所有成员变量按其类型被初始化为对应的零值。

> 因此程序刚启动时 allgs，allm 和allp 都不包含任何 g，m 和 p。

不仅是 Go 程序，系统加载可执行文件大概都会经过这几个阶段：

> 1. 从磁盘上读取可执行文件，加载到内存
> 2. 创建进程和主线程
> 3. 为主线程分配栈空间
> 4. 把由用户在命令行输入的参数拷贝到主线程的栈
> 5. 主线程放入操作系统的运行队列等待被调度

调整 SP：将 SP 调整到了一个地址是 16 的倍数的位置

初始化 g0 栈：开始初始化 g0 的栈了。g0 栈的作用就是为运行 runtime 代码提供一个“环境”。

主线程绑定 m0：因为 m0 是全局变量，而 m0 又要绑定到工作线程才能执行。我们又知道，runtime 会启动多个工作线程，每个线程都会绑定一个 m0。而且，代码里还得保持一致，都是用 m0 来表示。这就要用到线程本地存储的知识了，也就是常说的 TLS（Thread Local Storage）。简单来说，TLS 就是线程本地的私有的全局变量。

初始化 m0：osinit 函数初始化系统核心数，将全局变量 ncpu 初始化的核心数，schedinit 则是本文的核心：调度器的初始化。

初始化 allp：这里就是设置 procs，它决定创建 P 的数量。ncpu 这里已经被赋上了系统的核心数，因此代码里不设置 GOMAXPROCS 也是没问题的。这里还限制了 procs 的最大值，为 1024。



#### 什么是MN模型

Go runtime 会负责 goroutine 的生老病死，从创建到销毁，都一手包办。Runtime 会在程序启动的时候，M个用户线程对应N个系统线程

在同一时刻，一个线程上只能跑一个 goroutine。当 goroutine 发生阻塞（例如上篇文章提到的向一个 channel 发送数据，被阻塞）时，runtime 会把当前 goroutine 调度走，让其他 goroutine 来执行。目的就是不让一个线程闲着，榨干 CPU 的每一滴油水。

#### 2.4.GPM的数量限制情况

- M：有限制，默认数量限制是 10000，可调整。

- G：没限制，但受内存影响。假设一个 Goroutine 创建需要 4k(via @GoWKH)：

  - 4k * 80,000 = 320,000k ≈ 0.3G内存
  - 4k * 1,000,000 = 4,000,000k ≈ 4G内存

  以此就可以相对计算出来一台单机在通俗情况下，所能够创建 Goroutine 的大概数量级别。

  注：Goroutine 创建所需申请的 2-4k 是需要连续的内存块。

- P：受本机的核数影响，可大可小，不影响 G 的数量创建。P 的数量受环境变量 GOMAXPROCS 的直接影响。在 Go 语言中，通过设置 GOMAXPROCS，用户可以调整调度中 P(Processor)的数量。

#### Go调度的核心思想是：

1. reuse threads；
2. 限制同时运行（不包含阻塞）的线程数为 N，N 等于 CPU 的核心数目；
3. 线程私有的 runqueues，并且可以从其他线程 stealing goroutine 来运行，线程阻塞后，可以将 runqueues 传递给其他线程。

#### 为什么需要 P 这个组件，直接把 runqueues 放到 M 不行吗？

当一个线程阻塞的时候，将和它绑定的 P 上的 goroutines 转移到其他线程。

Go scheduler 会启动一个后台线程 sysmon，用来检测长时间（超过 10 ms）运行的 goroutine，将其调度到 global runqueues。这是一个全局的 runqueue，优先级比较低，以示惩罚。

#### goroutine 调度器调度时机有哪些？

| 情形            | 说明                                                         |
| --------------- | ------------------------------------------------------------ |
| 使用关键字 `go` | go 创建一个新的 goroutine，Go scheduler 会考虑调度           |
| GC              | 由于进行 GC 的 goroutine 也需要在 M 上运行，因此肯定会发生调度。当然，Go scheduler 还会做很多其他的调度，例如调度不涉及堆访问的 goroutine 来运行。GC 不管栈上的内存，只会回收堆上的内存 |
| 系统调用        | 当 M0的goroutine 进行系统调用时，会阻塞 M0，所以M0的p会被调度走，M1获取之前的p继续执行。 |
| 内存同步访问    | atomic，mutex，channel 操作等会使 goroutine 阻塞，因此会被调度走。等条件满足后（例如其他 goroutine 解锁了）还会被调度上来继续运行 |

#### goroutine和 线程 有什么区别？

- 内存占用

创建一个 goroutine 的栈内存消耗为 2 KB，实际运行过程中，如果栈空间不够用，会自动进行扩容。创建一个 thread 则需要消耗 1 MB 栈内存，而且还需要一个被称为 “a guard page” 的区域用于和其他 thread 的栈空间进行隔离。

对于一个用 Go 构建的 HTTP Server 而言，对到来的每个请求，创建一个 goroutine 用来处理是非常轻松的一件事。而如果用一个使用线程作为并发原语的语言构建的服务，例如 Java 来说，每个请求对应一个线程则太浪费资源了，很快就会出 OOM 错误（OutOfMemoryError）。

- 创建和销毀

Thread 创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池。而 goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是用户级。

- 切换

当 threads 切换时，需要保存各种寄存器，以便将来恢复：

> 16 general purpose registers, PC (Program Counter), SP (Stack Pointer), segment registers, 16 XMM registers, FP coprocessor state, 16 AVX registers, all MSRs etc.

而 goroutines 切换只需保存三个寄存器：Program Counter, Stack Pointer and BP。

一般而言，线程切换会消耗 1000-1500 纳秒，一个纳秒平均可以执行 12-18 条指令。所以由于线程切换，执行指令的条数会减少 12000-18000。

Goroutine 的切换约为 200 ns，相当于 2400-3600 条指令。

因此，goroutines 切换成本比 threads 要小得多。

#### 2.3 go调度器调度工作流程
![](assets/16529765659933.jpg)

先从本地队列找，定期会从全局队列找，最后实在没办法，就去别的 P 

从工作线程本地运行队列中寻找goroutine。如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。

从全局运行队列中寻找goroutine。为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。



第三步，从其它工作线程的运行队列中偷取goroutine。如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。

// One round of scheduler: find a runnable goroutine and execute it.
// Never returns.
func schedule() {
    _g_ := getg()   //_g_ = m.g0

    ......
    
    var gp *g
    
     ......
    
    if gp == nil {
    // Check the global runnable queue once in a while to ensure fairness.
    // Otherwise two goroutines can completely occupy the local runqueue
    // by constantly respawning each other.
        //为了保证调度的公平性，每个工作线程每进行61次调度就需要优先从全局运行队列中获取goroutine出来运行，
        //因为如果只调度本地运行队列中的goroutine，则全局运行队列中的goroutine有可能得不到运行
        if _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {
            lock(&sched.lock) //所有工作线程都能访问全局运行队列，所以需要加锁
            gp = globrunqget(_g_.m.p.ptr(), 1) //从全局运行队列中获取1个goroutine
            unlock(&sched.lock)
        }
    }
    if gp == nil {
         //从与m关联的p的本地运行队列中获取goroutine
        gp, inheritTime = runqget(_g_.m.p.ptr())
        if gp != nil && _g_.m.spinning {
            throw("schedule: spinning with local work")
        }
    }
    if gp == nil {
         //如果从本地运行队列和全局运行队列都没有找到需要运行的goroutine，
         //则调用findrunnable函数从其它工作线程的运行队列中偷取，如果偷取不到，则当前工作线程进入睡眠，
         //直到获取到需要运行的goroutine之后findrunnable函数才会返回。
        gp, inheritTime = findrunnable() // blocks until work is available
    }
    
    ......
    
     //当前运行的是runtime的代码，函数调用栈使用的是g0的栈空间
     //调用execte切换到gp的代码和栈空间去运行
    execute(gp, inheritTime)  
}

#### goroutine协程之间的切换调度方法？

##### 从全局运行队列中寻找goroutine

首先根据全局队列的可运行 goroutine 长度和 P 的总数，来计算一个数值，表示每个 P 可平均分到的 goroutine 数量。

然后根据函数参数中的 max 以及 P 本地队列的长度来决定把多少全局队列中的 goroutine 转移到 P 本地。

最后，for 循环挨个把全局队列中 n-1 个 goroutine 转移到本地，并且返回最开始获取到的队列头所指向的 goroutine，毕竟它最需要得到运行的机会。

把全局队列中的可运行 goroutine 转移到本地队列，给了全局队列中可运行 goroutine 运行的机会，不然全局队列中的 goroutine 一直得不到运行。

```
// Try get a batch of G's from the global runnable queue.
// Sched must be locked.
func globrunqget(_p_ *p, max int32) *g {
    if sched.runqsize == 0 {  //全局运行队列为空
         return nil
     }

     //根据p的数量平分全局运行队列中的goroutines
     n := sched.runqsize / gomaxprocs + 1
     if n > sched.runqsize { //上面计算n的方法可能导致n大于全局运行队列中的goroutine数量
         n = sched.runqsize
     }
     if max > 0 && n > max {
         n = max   //最多取max个goroutine
     }
     if n > int32(len(_p_.runq)) / 2 {
         n = int32(len(_p_.runq)) / 2  //最多只能取本地队列容量的一半
     }

     sched.runqsize -= n

     //直接通过函数返回gp，其它的goroutines通过runqput放入本地运行队列
     gp := sched.runq.pop()  //pop从全局运行队列的队列头取
     n--
     for ; n > 0; n-- {
         gp1 := sched.runq.pop()  //从全局运行队列中取出一个goroutine
         runqput(_p_, gp1, false)  //放入本地运行队列
     }
     return gp
}
```



##### 从工作任务本地运行中获取goroutine**

runqget

第一个 for 循环尝试返回 P 的 runnext 成员，因为 runnext 具有最高的运行优先级，因此要首先尝试获取 runnext。当发现 runnext 为空时，直接跳出循环，进入第二个。否则，用原子操作获取 runnext，并将其值修改为 0，也就是空。这里用到原子操作的原因是防止在这个过程中，有其他线程过来“偷工作”，导致并发修改 runnext 成员。

第二个 for 循环则是在尝试获取 runnext 成员失败后，尝试从本地队列中返回队列头的 goroutine。同样，先用原子操作获取队列头，使用原子操作的原因同样是防止其他线程“偷工作”时并发对队列头的并发写操作。之后，直接获取队列尾，因为不担心其他线程同时更改，所以直接获取。注意，“偷工作”时只会修改队列头。

比较队列头和队列尾，如果两者相等，说明 P 本地队列没有可运行的 goroutine，直接返回空。否则，算出队列头指向的 goroutine，再用一个 CAS 原子操作来尝试修改队列头，使用原子操作的原因同上。

```
// Get g from local runnable queue.
// If inheritTime is true, gp should inherit the remaining time in the
// current time slice. Otherwise, it should start a new time slice.
// Executed only by the owner P.
func runqget(_p_ *p) (gp *g, inheritTime bool) {
    // If there's a runnext, it's the next G to run.
     //从runnext成员中获取goroutine
    for {
         //查看runnext成员是否为空，不为空则返回该goroutine
        next := _p_.runnext   
        if next == 0 {
            break
        }
        if _p_.runnext.cas(next, 0) {
            return next.ptr(), true
        }
    }

     //从循环队列中获取goroutine
    for {
        h := atomic.LoadAcq(&_p_.runqhead) // load-acquire, synchronize with other consumers
        t := _p_.runqtail
        if t == h {
            return nil, false
        }
        gp := _p_.runq[h%uint32(len(_p_.runq))].ptr()
        if atomic.CasRel(&_p_.runqhead, h, h+1) { // cas-release, commits consume
            return gp, false
        }
    }
}
```

##### 从其他地方偷取过程

从本地运行队列和全局运行队列都没有找到需要运行的 goroutine，
// 调用 findrunnable 函数从其它工作线程的运行队列中偷取，如果偷不到，则当前工作线程进入睡眠
// 直到获取到 runnable goroutine 之后 findrunnable 函数才会返回。

尽力去各个运行队列中寻找 goroutine，如果实在找不到则进入睡眠状态，等待有工作时，被其他 M 唤醒。

先获取当前指向的 g，也就是 g0，然后拿到其绑定的 p，即 _p_。

首先再次尝试从 _p_ 本地队列获取 goroutine，如果没有获取到，则尝试从全局队列获取。如果还没有获取到就会尝试去“偷”了，这也是没有办法的事。

不过，在偷之前，先看大的局势。如果其他所有的 P 都处于空闲状态，就说明其他 P 肯定没有工作可做，就没必要再去偷了，毕竟“地主家也没有余粮了”，跳到 stop 部分。接着再看下当前正在“偷工作”的线程数量“太多了”，就没必要扎堆了，这么多人，竞争肯定大，工作肯定不好找，也不好偷。

在真正的“偷”工作之前，把自己的自旋状态设置为 true，全局自旋数量加 1。

终于到了“偷工作”的部分了，好紧张！整个过程由两层 for 循环组成，外层控制尝试偷的次数，内层控制“偷”的顺序，并真正的去“偷”。实际上，内层会遍历所有的 P，因此，整体看来，会尝试 4 次扫遍所有的 P，并去“偷工作”，是不是非常有毅力！

第二层的循环并不是每次都按一个固定的顺序去遍历所有的 P，这样不太科学，而是使用了一些方法，“随机”地遍历
#### 调度器的设计策略/调度策略
复用线程：避免频繁的创建、销毁线程，而是对线程的复用。



1）work stealing 机制

 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。

2）hand off 机制

 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。

当G0系统调用结束后，跟据M0是否能获取到P，将会将G0做不同的处理：

1. 如果有空闲的P，则获取一个P，继续执行G0。
2. 如果没有空闲的P，则将G0放入全局队列，等待被其他的P调度。然后M0将进入缓存池睡眠。

3）队列轮转

每个P维护着一个包含G的队列，不考虑G进入系统调用或IO操作的情况下，P周期性的将G调度到M中执行，执行一小段时间，将上下文保存下来，然后将G放到队列尾部，然后从队列中重新取出一个G进行调度。

除了每个P维护的G队列以外，还有一个全局的队列，每个P会周期性的查看全局队列中是否有G待运行并将期调度到M中执行，全局队列中G的来源，主要有从系统调用中恢复的G。之所以P会周期性的查看全局队列，也是为了防止全局队列中的G被饿死。



利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。

抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。

全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。



#### 什么是工作窃取

当一个 P 发现自己的 LRQ 已经没有 G 时，会从其他 P “偷” 一些 G 来运行。看看这是什么精神！自己的工作做完了，为了全局的利益，主动为别人分担。这被称为 `Work-stealing`，Go 从 1.1 开始实现。Go scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。如果 P 上的 M 阻塞了，那它就需要其他的 M 来运行 P 的 LRQ 里的 goroutines。

找到一个可执行的 goroutine 后，就会一直执行下去，直到被阻塞。

当 P2 上的一个 G 执行结束，它就会去 LRQ 获取下一个 G 来执行。如果 LRQ 已经空了，就是说本地可运行队列已经没有 G 需要执行，并且这时 GRQ 也没有 G 了。这时，P2 会随机选择一个 P（称为 P1），P2 会从 P1 的 LRQ “偷”过来一半的 G。



### Go 调度器调度场景过程全解析

(1) 场景 1

P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 go func() 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。

![img](https://www.topgoer.com/static/7.1/gmp/22.jpg)

(2) 场景 2

G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2，从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。

![img](https://www.topgoer.com/static/7.1/gmp/23.jpg)

(3) 场景 3

假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 3 个 G（G3, G4, G5）已经加入 p1 的本地队列，p1 本地队列满了。

![img](https://www.topgoer.com/static/7.1/gmp/24.jpg)

(4) 场景 4

G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行负载均衡 (把 P1 中本地队列中前一半的 G，还有新创建 G 转移到全局队列)

> （实现中并不一定是新的 G，如果 G 是 G2 之后就执行的，会被保存在本地队列，利用某个老的 G 替换新 G 加入全局队列）

![img](https://www.topgoer.com/static/7.1/gmp/25.jpg)

这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。

(5) 场景 5

G2 创建 G8 时，P1 的本地队列未满，所以 G8 会被加入到 P1 的本地队列。

![img](https://www.topgoer.com/static/7.1/gmp/26.jpg)

G8 加入到 P1 点本地队列的原因还是因为 P1 此时在与 M1 绑定，而 G2 此时是 M1 在执行。所以 G2 创建的新的 G 会优先放置到自己的 M 绑定的 P 上。

(6) 场景 6

规定：在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。

![img](https://www.topgoer.com/static/7.1/gmp/27.jpg)

假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程（没有 G 但为运行状态的线程，不断寻找 G）。

(7) 场景 7

M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：findrunnable()）。M2 从全局队列取的 G 数量符合下面的公式：

> n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))

至少从全局队列取 1 个 g，但每次不要从全局队列移动太多的 g 到 p 本地队列，给其他 p 留点。这是从全局队列到 P 本地队列的负载均衡。

![img](https://www.topgoer.com/static/7.1/gmp/28.jpg)

假定我们场景中一共有 4 个 P（GOMAXPROCS 设置为 4，那么我们允许最多就能用 4 个 P 来供 M 使用）。所以 M2 只从能从全局队列取 1 个 G（即 G3）移动 P2 本地队列，然后完成从 G0 到 G3 的切换，运行 G3。

(8) 场景 8

假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。

![img](https://www.topgoer.com/static/7.1/gmp/29.jpg)

全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。

(9) 场景 9

G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。

![img](https://www.topgoer.com/static/7.1/gmp/30.jpg)

为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新 goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 GOMAXPROCS 个自旋的线程 (当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。

(10) 场景 10

 假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以 P 的数量应该永远是 M>=P, 大部分都是 M 在抢占需要运行的 P)，G8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑，P2 会执行以下判断：如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定，否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。

![img](https://www.topgoer.com/static/7.1/gmp/31.jpg)

(11) 场景 11

G8 创建了 G9，假如 G8 进行了非阻塞系统调用。

![img](https://www.topgoer.com/static/7.1/gmp/32.jpg)

 M2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。



### 3.CHANNEL 通道原理

#### 3.1数据结构

```
  type hchan struct {
	// chan 里元素数量
	qcount   uint
	// chan 底层循环数组的长度
	dataqsiz uint
	// 指向底层循环数组的指针
	// 只针对有缓冲的 channel
	buf      unsafe.Pointer
	// chan 中元素大小
	elemsize uint16
	// chan 是否被关闭的标志
	closed   uint32
	// chan 中元素类型
	elemtype *_type // element type
	// 已发送元素在循环数组中的索引
	sendx    uint   // send index
	// 已接收元素在循环数组中的索引
	recvx    uint   // receive index
	// 等待接收的 goroutine 队列
	recvq    waitq  // list of recv waiters
	// 等待发送的 goroutine 队列
	sendq    waitq  // list of send waiters

	// 保护 hchan 中所有字段`lock` 用来保证每个读 channel 或写 channel 的操作都是原子的。
	lock mutex
}
```

`buf` 指向底层循环数组，只有缓冲型的 channel 才有。

`sendx`，`recvx` 均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组）。

`sendq`，`recvq` 分别表示被阻塞的 goroutine，这些 goroutine 由于尝试读取 channel 或向 channel 发送数据而被阻塞。

`waitq` 是 `sudog` 的一个双向链表，而 `sudog` 实际上是对 goroutine 的一个封装：

```golang
type waitq struct {
	first *sudog
	last  *sudog
}
```

#### channel创建过程

```golang
const hchanSize = unsafe.Sizeof(hchan{}) + uintptr(-int(unsafe.Sizeof(hchan{}))&(maxAlign-1))

func makechan(t *chantype, size int64) *hchan {
	elem := t.elem

	// 省略了检查 channel size，align 的代码
	// ……

	var c *hchan
	// 如果元素类型不含指针 或者 size 大小为 0（无缓冲类型）
	// 只进行一次内存分配
	if elem.kind&kindNoPointers != 0 || size == 0 {
		// 如果 hchan 结构体中不含指针，GC 就不会扫描 chan 中的元素
		// 只分配 "hchan 结构体大小 + 元素大小*个数" 的内存
		c = (*hchan)(mallocgc(hchanSize+uintptr(size)*elem.size, nil, true))
		// 如果是缓冲型 channel 且元素大小不等于 0（大小等于 0的元素类型：struct{}）
		if size > 0 && elem.size != 0 {
			c.buf = add(unsafe.Pointer(c), hchanSize)
		} else {
			// race detector uses this location for synchronization
			// Also prevents us from pointing beyond the allocation (see issue 9401).
			// 1. 非缓冲型的，buf 没用，直接指向 chan 起始地址处
			// 2. 缓冲型的，能进入到这里，说明元素无指针且元素类型为 struct{}，也无影响
			// 因为只会用到接收和发送游标，不会真正拷贝东西到 c.buf 处（这会覆盖 chan的内容）
			c.buf = unsafe.Pointer(c)
		}
	} else {
		// 进行两次内存分配操作
		c = new(hchan)
		c.buf = newarray(elem, int(size))
	}
	c.elemsize = uint16(elem.size)
	c.elemtype = elem
	// 循环数组长度
	c.dataqsiz = uint(size)

	// 返回 hchan 指针
	return c
}
```

#### 3.2 读写流程

**向 channel 写数据:**

若等待接收队列 recvq 不为空，则缓冲区中无数据或无缓冲区，将直接从 recvq 取出 G ，并把数据写入，最后把该 G 唤醒，结束发送过程。

若缓冲区中有空余位置，则将数据写入缓冲区，结束发送过程。

若缓冲区中没有空余位置，则将发送数据写入 G，将当前 G 加入 sendq ，进入睡眠，等待被读 goroutine 唤醒。

**从 channel 读数据**

若等待发送队列 sendq 不为空，且没有缓冲区，直接从 sendq 中取出 G ，把 G 中数据读出，最后把 G 唤醒，结束读取过程。

如果等待发送队列 sendq 不为空，说明缓冲区已满，从缓冲区中首部读出数据，把 G 中数据写入缓冲区尾部，把 G 唤醒，结束读取过程。

如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程。

如果没有数据，将当前 goroutine 加入 recvq ，进入睡眠，等待被写 goroutine 唤醒。

**关闭 channel过程**

close 逻辑比较简单，对于一个 channel，recvq 和 sendq 中分别保存了阻塞的发送者和接收者。关闭 channel 后，对于等待接收者而言，会收到一个相应类型的零值。对于等待发送者，会直接 panic。所以，在不了解 channel 还有没有接收者的情况下，不能贸然关闭 channel。

close 函数先上一把大锁，接着把所有挂在这个 channel 上的 sender 和 receiver 全都连成一个 sudog 链表，再解锁。最后，再将所有的 sudog 全都唤醒。

唤醒之后，该干嘛干嘛。sender 会继续执行 chansend 函数里 goparkunlock 函数之后的代码，很不幸，检测到 channel 已经关闭了，panic。receiver 则比较幸运，进行一些扫尾工作后，返回。这里，selected 返回 true，而返回值 received 则要根据 channel 是否关闭，返回不同的值。如果 channel 关闭，received 为 false，否则为 true。这我们分析的这种情况下，received 返回 false。

1.关闭 channel 时会将 recvq 中的 G 全部唤醒，本该写入 G 的数据位置为 nil。将 sendq 中的 G 全部唤醒，但是这些 G 会 panic。

panic 出现的场景还有：

- 关闭值为 nil 的 channel
- 关闭已经关闭的 channel
- 向已经关闭的 channel 中写数据

#### 3.2 无缓冲 Chan 的发送和接收是否同步?

```
// 无缓冲的channel由于没有缓冲发送和接收需要同步
ch := make(chan int)   
//有缓冲channel不要求发送和接收操作同步
ch := make(chan int, 2)  
```

channel 无缓冲时，发送阻塞直到数据被接收，接收阻塞直到读到数据；channel有缓冲时，当缓冲满时发送阻塞，当缓冲空时接收阻塞。

#### Channel 发送和接收元素的本质是什么？

channel 的发送和接收操作本质上都是 “值的拷贝”，无论是从 sender goroutine 的栈到 chan buf，还是从 chan buf 到 receiver goroutine，或者是直接从 sender goroutine 到 receiver goroutine。

#### Channel 什么时候会引发 goroutine 泄漏？

泄漏的原因是 goroutine 操作 channel 后，处于发送或接收阻塞状态，而 channel 处于满或空的状态，一直得不到改变。同时，垃圾回收器也不会回收此类资源，进而导致 gouroutine 会一直处于等待队列中，不见天日。

另外，程序运行过程中，对于一个 channel，如果没有任何 goroutine 引用了，gc 会对其进行回收操作，不会引起内存泄漏。

#### 如何优雅的关闭channel
增加一个传递关闭信号的 channel，receiver 通过信号 channel 下达关闭数据 channel 指令。senders 监听到关闭信号后，停止发送数据。
stopCh 就是信号 channel，它本身只有一个 sender，因此可以直接关闭它。senders 收到了关闭信号后，select 分支 “case <- stopCh” 被选中，退出函数，不再发送数据。
而如果有 M 个 receiver，由 receiver 直接关闭 stopCh 的话，就会重复关闭一个 channel，导致 panic。因此需要增加一个中间人，M 个 receiver 都向它发送关闭 dataCh 的“请求”，中间人收到第一个请求后，就会直接下达关闭 dataCh 的指令（通过关闭 stopCh，这时就不会发生重复关闭的情况，因为 stopCh 的发送方只有中间人一个）。另外，这里的 N 个 sender 也可以向中间人发送关闭 dataCh 的请求。
 toStop 就是中间人的角色，使用它来接收 senders 和 receivers 发送过来的关闭 dataCh 请求。

这里将 toStop 声明成了一个 缓冲型的 channel。假设 toStop 声明的是一个非缓冲型的 channel，那么第一个发送的关闭 dataCh 请求可能会丢失。因为无论是 sender 还是 receiver 都是通过 select 语句来发送请求，如果中间人所在的 goroutine 没有准备好，那 select 语句就不会选中，直接走 default 选项，什么也不做。这样，第一个关闭 dataCh 的请求就会丢失。
#### channel的应用

停止信号

channel 用于停止信号的场景还是挺多的，经常是关闭某个 channel 或者向 channel 发送一个元素，使得接收 channel 的那一方获知道此信息，进而做一些其他的操作。

定时

与 timer 结合，一般有两种玩法：实现超时控制，实现定期执行某个任务。

解耦生产方和消费方

服务启动时，启动 n 个 worker，作为工作协程池，这些协程工作在一个 `for {}` 无限循环里，从某个 channel 消费工作任务并执行

#### channel发送先后
第 n 个 send 一定 happened before 第 n 个 receive finished，无论是缓冲型还是非缓冲型的 channel。
对于容量为 m 的缓冲型 channel，第 n 个 receive 一定 happened before 第 n+m 个 send finished。
对于非缓冲型的 channel，第 n 个 receive 一定 happened before 第 n 个 send finished。
channel close 一定 happened before receiver 得到通知

### 4. context 结构原理

#### 4.1 用途

Context（上下文）是Golang应用开发常用的并发控制技术 ，它可以控制一组呈树状结构的goroutine，每个goroutine拥有相同的上下文。Context 是并发安全的，主要是用于控制多个协程之间的协作、取消操作。

context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。

随着 context 包的引入，标准库中很多接口因此加上了 context 参数，例如 database/sql 包。context 几乎成为了并发控制和超时控制的标准做法。

> context.Context 类型的值可以协调多个 groutine 中的代码执行“取消”操作，并且可以存储键值对。最重要的是它是并发安全的。

> 与它协作的 API 都可以由外部控制执行“取消”操作，例如：取消一个 HTTP 请求的执行。

![null](https://www.topgoer.cn/uploads/blog/202111/attach_16b40224aa38da32.jpg)

#### context 有什么作用

这些 goroutine 需要共享这个请求的基本数据，例如登陆的 token，处理请求的最大超时时间（如果超过此值再返回数据，请求方因为超时接收不到）等等。当请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的 goroutine 需要快速退出，因为它们的“工作成果”不再被需要了。在相关联的 goroutine 都退出后，系统就可以回收相关的资源。

再多说一点，Go 语言中的 server 实际上是一个“协程模型”，也就是说一个协程处理一个请求。例如在业务的高峰期，某个下游服务的响应变慢，而当前系统的请求又没有超时控制，或者超时时间设置地过大，那么等待下游服务返回数据的协程就会越来越多。而我们知道，协程是要消耗系统资源的，后果就是协程数激增，内存占用飙涨，甚至导致服务不可用。更严重的会导致雪崩效应，整个服务对外表现为不可用，这肯定是 P0 级别的事故。这时，肯定有人要背锅了。



#### 4.2 数据结构

Context 只定义了接口，凡是实现该接口的类都可称为是一种 context。

并发控制神器之Context

```
type Context interface {
	// 当 context 被取消或者到了 deadline，返回一个被关闭的 channel
	Done() <-chan struct{}

	// 在 channel Done 关闭后，返回 context 取消原因
	Err() error

	// 返回 context 是否会被取消以及自动取消时间（即 deadline）
	Deadline() (deadline time.Time, ok bool)

	// 获取 key 对应的 value
	Value(key interface{}) interface{}
}
```

Context` 是一个接口，定义了 4 个方法，它们都是`幂等`的。也就是说连续多次调用同一个方法，得到的结果都是相同的。

`Done()` 返回一个 channel，可以表示 context 被取消的信号：当这个 channel 被关闭时，说明 context 被取消了。注意，这是一个只读的channel。 我们又知道，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 `receive-only` 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。

`Err()` 返回一个错误，表示 channel 被关闭的原因。例如是被取消，还是超时。

`Deadline()` 返回 context 的截止时间，通过此时间，函数就可以决定是否进行接下来的操作，如果时间太短，就可以不往下做了，否则浪费系统资源。当然，也可以用这个 deadline 来设置一个 I/O 操作的超时时间。

`Value()` 获取之前设置的 key 对应的 value。

![classes](https://golang.design/go-questions/stdlib/context/assets/4.png)

#### canceler接口

```golang
type canceler interface {
	cancel(removeFromParent bool, err error)
	Done() <-chan struct{}
}
```

实现了上面定义的两个方法的 Context，就表明该 Context 是可取消的。源码中有两个类型实现了 canceler 接口：`*cancelCtx` 和 `*timerCtx`。注意是加了 `*` 号的，是这两个结构体的指针实现了 canceler 接口。

Context 接口设计成这个样子的原因：

- “取消”操作应该是建议性，而非强制性

caller 不应该去关心、干涉 callee 的情况，决定如何以及何时 return 是 callee 的责任。caller 只需发送“取消”信息，callee 根据收到的信息来做进一步的决策，因此接口并没有定义 cancel 方法。

- “取消”操作应该可传递

“取消”某个函数时，和它相关联的其他函数也应该“取消”。因此，`Done()` 方法返回一个只读的 channel，所有相关函数监听此 channel。一旦 channel 关闭，通过 channel 的“广播机制”，所有监听者都能收到。

#### emptyCtx结构体

```golang
type emptyCtx int

func (*emptyCtx) Deadline() (deadline time.Time, ok bool) {
	return
}

func (*emptyCtx) Done() <-chan struct{} {
	return nil
}

func (*emptyCtx) Err() error {
	return nil
}

func (*emptyCtx) Value(key interface{}) interface{} {
	return nil
}
```

这实际上是一个空的 context，永远不会被 cancel，没有存储值，也没有 deadline。

被包装成

```golang
var (
	background = new(emptyCtx)
	todo       = new(emptyCtx)
)
```

```golang
func Background() Context {
	return background
}

func TODO() Context {
	return todo
}
```

background 通常用在 main 函数中，作为所有 context 的根节点。

todo 通常用在并不知道传递什么 context的情形。例如，调用一个需要传递 context 参数的函数，你手头并没有其他 context 可以传递，这时就可以传递 todo。这常常发生在重构进行中，给一些函数添加了一个 Context 参数，但不知道要传什么，就用 todo “占个位子”，最终要换成其他 context。

#### cancelCtx结构体

```golang
type cancelCtx struct {
	Context

	// 保护之后的字段
	mu       sync.Mutex
	done     chan struct{}
	children map[canceler]struct{}
	err      error
}
```

这是一个可以取消的 Context，实现了 canceler 接口。它直接将接口 Context 作为它的一个匿名字段，这样，它就可以被看成一个 Context。

```golang
func (c *cancelCtx) Done() <-chan struct{} {
	c.mu.Lock()
	if c.done == nil {
		c.done = make(chan struct{})
	}
	d := c.done
	c.mu.Unlock()
	return d
}
```

c.done 是“懒汉式”创建，只有调用了 Done() 方法的时候才会被创建。再次说明，函数返回的是一个只读的 channel，而且没有地方向这个 channel 里面写数据。所以，直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。

```golang
func (c *cancelCtx) cancel(removeFromParent bool, err error) {
    // 必须要传 err
	if err == nil {
		panic("context: internal error: missing cancel error")
	}
	c.mu.Lock()
	if c.err != nil {
		c.mu.Unlock()
		return // 已经被其他协程取消
	}
	// 给 err 字段赋值
	c.err = err
	// 关闭 channel，通知其他协程
	if c.done == nil {
		c.done = closedchan
	} else {
		close(c.done)
	}
	
	// 遍历它的所有子节点
	for child := range c.children {
	    // 递归地取消所有子节点
		child.cancel(false, err)
	}
	// 将子节点置空
	c.children = nil
	c.mu.Unlock()

	if removeFromParent {
	    // 从父节点中移除自己 
		removeChild(c.Context, c)
	}
}
```

总体来看，`cancel()` 方法的功能就是关闭 channel：c.done；递归地取消它的所有子节点；从父节点从删除自己。达到的效果是通过关闭 channel，将取消信号传递给了它的所有子节点。goroutine 接收到取消信号的方式就是 select 语句中的`读 c.done` 被选中。



### 5. 竞态、内存逃逸

#### Linux的4种锁机制

##### 互斥锁：mutex

  互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。**往下翻看go互斥锁sync.Mutex原理**

##### 读写锁：rwlock

  读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。

**往下翻看go读写锁sync.RWMutex原理**
  

##### 自旋锁：spinlock

  自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。

##### RCU

  RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。

**并发控制，同步原语 sync 包**

#### 5.1 竞态

资源竞争，就是在程序中，同一块内存同时被多个 goroutine 访问。我们使用 go build、go run、go test 命令时，添加 -race 标识可以检查代码中是否存在资源竞争。

解决这个问题，我们可以给资源进行加锁，让其在同一时刻只能被一个协程来操作。

##### go互斥锁sync.Mutex原理

互斥锁是并发程序中对共享资源进行访问控制的主要手段，对此Go语言提供了非常简单易用的Mutex，Mutex为一结构体类型，对外暴露两个方法Lock()和Unlock()分别用于加锁和解锁。

###### Mutex结构体

源码包`src/sync/mutex.go:Mutex`定义了互斥锁的数据结构：

```go
type Mutex struct {
    state int32
    sema  uint32
}
```

- Mutex.state表示互斥锁的状态，比如是否被锁定等。
- Mutex.sema表示信号量，协程阻塞等待该信号量，解锁的协程释放信号量从而唤醒等待信号量的协程。

###### Mutex的内存布局：

- Locked: 表示该Mutex是否已被锁定，0：没有锁定 1：已被锁定。
- Woken: 表示是否有协程已被唤醒，0：没有协程唤醒 1：已有协程唤醒，正在加锁过程中。
- Starving：表示该Mutex是否处理饥饿状态， 0：没有饥饿 1：饥饿状态，说明有协程阻塞了超过1ms。
- Waiter: 表示阻塞等待锁的协程个数，协程解锁时根据此值来判断是否需要释放信号量。

协程之间抢锁实际上是抢给Locked赋值的权利，能给Locked域置1，就说明抢锁成功。抢不到的话就阻塞等待Mutex.sema信号量，一旦持有锁的协程解锁，等待的协程会依次被唤醒。

###### 简单加锁

加锁过程会去判断Locked标志位是否为0，如果是0则把Locked位置1，代表加锁成功

###### 加锁被阻塞

假定加锁时，锁已被其他协程占用了，当协程B对一个已被占用的锁再次加锁时，Waiter计数器增加了1，此时协程B将被阻塞，直到Locked值变为0后才会被唤醒。

###### 简单解锁

由于没有其他协程阻塞等待加锁，所以此时解锁时只需要把Locked位置为0即可，不需要释放信号量。

###### 解锁并唤醒协程

假定解锁时，有1个或多个协程阻塞，协程A解锁过程分为两个步骤，一是把Locked位置0，二是查看到Waiter>0，所以释放一个信号量，唤醒一个阻塞的协程，被唤醒的协程B把Locked位置1，于是协程B获得锁。

###### 自旋过程

加锁时，如果当前Locked位为1，说明该锁当前由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续的探测Locked位是否变为0，这个过程即为自旋过程。

自旋时间很短，但如果在自旋过程中发现锁已被释放，那么协程可以立即获取锁。此时即便有协程被唤醒也无法获取锁，只能再次阻塞。

自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换。

###### Mutex模式

前面分析加锁和解锁过程中只关注了Waiter和Locked位的变化，现在我们看一下Starving位的作用。

每个Mutex都有两个模式，称为Normal和Starving。下面分别说明这两个模式。

###### normal模式

默认情况下，Mutex的模式为normal。

该模式下，协程如果加锁不成功不会立即转入阻塞排队，而是判断是否满足自旋的条件，如果满足则会启动自旋过程，尝试抢锁。

###### starvation模式

自旋过程中能抢到锁，一定意味着同一时刻有协程释放了锁，我们知道释放锁时如果发现有阻塞等待的协程，还会释放一个信号量来唤醒一个等待协程，被唤醒的协程得到CPU后开始运行，此时发现锁已被抢占了，自己只好再次阻塞，不过阻塞前会判断自上次阻塞到本次阻塞经过了多长时间，如果超过1ms的话，会将Mutex标记为"饥饿"模式，然后再阻塞。

处于饥饿模式下，不会启动自旋过程，也即一旦有协程释放了锁，那么一定会唤醒协程，被唤醒的协程将会成功获取锁，同时也会把等待计数减1。

##### go读写锁sync.RWMutex原理

###### 读写锁数据结构

源码包`src/sync/rwmutex.go:RWMutex`定义了读写锁数据结构：

```go
type RWMutex struct {
    w           Mutex  //用于控制多个写锁，获得写锁首先要获取该锁，如果有一个写锁在进行，那么再到来的写锁将会阻塞于此
    writerSem   uint32 //写阻塞等待的信号量，最后一个读者释放锁时会释放信号量
    readerSem   uint32 //读阻塞的协程等待的信号量，持有写锁的协程释放锁后会释放信号量
    readerCount int32  //记录读者个数
    readerWait  int32  //记录写阻塞时读者个数
}
```

由以上数据结构可见，读写锁内部仍有一个互斥锁，用于将两个写操作隔离开来，其他的几个都用于隔离读操作和写操作。

###### 接口定义

RWMutex提供4个简单的接口来提供服务：

- RLock()：读锁定
- RUnlock()：解除读锁定
- Lock(): 写锁定，与Mutex完全一致
- Unlock()：解除写锁定，与Mutex完全一致

###### Lock()实现逻辑

写锁定操作需要做两件事：

- 获取互斥锁
- 阻塞等待所有读操作结束（如果有的话）

所以`func (rw *RWMutex) Lock()`接口实现流程如下图所示：

![img](https://books.studygolang.com/GoExpertProgramming/chapter02/images/rwmutex-01-lock.png)

###### Unlock()实现逻辑

解除写锁定要做两件事：

- 唤醒因读锁定而被阻塞的协程（如果有的话）
- 解除互斥锁

所以`func (rw *RWMutex) Unlock()`接口实现流程如下图所示

![img](https://books.studygolang.com/GoExpertProgramming/chapter02/images/rwmutex-02-unlock.png)

###### RLock()实现逻辑

读锁定需要做两件事：

- 增加读操作计数，即readerCount++
- 阻塞等待写操作结束(如果有的话)

所以`func (rw *RWMutex) RLock()`接口实现流程如下图所示：

![img](https://books.studygolang.com/GoExpertProgramming/chapter02/images/rwmutex-03-rlock.png)

###### RUnlock()实现逻辑

解除读锁定需要做两件事：

- 减少读操作计数，即readerCount--
- 唤醒等待写操作的协程（如果有的话）

所以`func (rw *RWMutex) RUnlock()`接口实现流程如下图所示：

![img](https://books.studygolang.com/GoExpertProgramming/chapter02/images/rwmutex-04-runlock.png)

###### 写操作是如何阻止读操作的

这个是读写锁实现中最精华的技巧。

我们知道RWMutex.readerCount是个整型值，用于表示读者数量，不考虑写操作的情况下，每次读锁定将该值+1，每次解除读锁定将该值-1，所以readerCount取值为[0, N]，N为读者个数，实际上最大可支持2^30个并发读者。

当写锁定进行时，会先将readerCount减去2^30，从而readerCount变成了负值，此时再有读锁定到来时检测到readerCount为负值，便知道有写操作在进行，只好阻塞等待。而真实的读操作个数并不会丢失，只需要将readerCount加上2^30即可获得。

所以，写操作将readerCount变成负值来阻止读操作的



###### 读操作是如何阻止写操作的

读锁定会先将RWMutext.readerCount加1，此时写操作到来时发现读者数量不为0，会阻塞等待所有读操作结束。

所以，读操作通过readerCount来将来阻止写操作的。

###### 为什么写锁定不会被饿死

我们知道，写操作要等待读操作结束后才可以获得锁，写操作等待期间可能还有新的读操作持续到来，如果写操作等待所有读操作结束，很可能被饿死。然而，通过RWMutex.readerWait可完美解决这个问题。

写操作到来时，会把RWMutex.readerCount值拷贝到RWMutex.readerWait中，用于标记排在写操作前面的读者个数。

前面的读操作结束后，除了会递减RWMutex.readerCount，还会递减RWMutex.readerWait值，当RWMutex.readerWait值变为0时唤醒写操作。

所以以，写操作就相当于把一段连续的读操作划分成两部分，前面的读操作结束后唤醒写操作，写操作结束后唤醒后面的读操作

#### go原子锁CAS

都是借用了CPU提供的原子性指令来实现。CAS操作修改共享变量时候不需要对共享变量加锁，而是通过类似乐观锁的方式进行检查，本质还是不断的占用CPU 资源换取加锁带来的开销（比如上下文切换开销）。

下面一个例子使用CAS来实现计数器

```go
package main
import (
    "fmt"
    "sync"
    "sync/atomic"
)

var (
    counter int32          //计数器
    wg      sync.WaitGroup //信号量
)

func main() {

    threadNum := 5

    //1. 五个信号量
    wg.Add(threadNum)

    //2.开启5个线程
    for i := 0; i < threadNum; i++ {
        go incCounter(i)
    }

    //3.等待子线程结束
    wg.Wait()
    fmt.Println(counter)
}

func incCounter(index int) {
    defer wg.Done()

    spinNum := 0
    for {
        //2.1原子操作
        old := counter
        ok := atomic.CompareAndSwapInt32(&counter, old, old+1)
        if ok {
            break
        } else {
            spinNum++
        }
    }

    fmt.Printf("thread,%d,spinnum,%d\n",index,spinNum)

}
```

- 如上代码main线程首先创建了5个信号量，然后开启五个线程执行incCounter方法
- incCounter内部执行代码2.1 使用cas操作递增counter的值， atomic.CompareAndSwapInt32具有三个参数，第一个是变量的地址，第二个是变量当前值，第三个是要修改变量为多少，该函数如果发现传递的old值等于当前变量的值，则使用第三个变量替换变量的值并返回true，否则返回false。
- 先从一个内存地址 `&addr` 读取出来当前存储的值，假如读取完以后，没有其它线程对此变量 进行修改的话，则下面的 `atomic.CompareAndSwapInt32` 语句会在执行时先再判断一次它的值是否与上次的相等，这时必须是相等的，则直接更新它的值；如果在读取值后，有其它线程对变量值进行了修改，发现值不相等，这时就再重新开始下一轮的判断，直到修改成功为止。
- 这里之所以使用无限循环是因为在高并发下每个线程执行CAS并不是每次都成功，失败了的线程需要重写获取变量当前的值，然后重新执行CAS操作。读者可以把线程数改为10000或者更多会发现输出thread,5329,spinnum,1其中1说明该线程尝试了两个CAS操作，第二次才成功。

go中CAS操作可以有效的减少使用锁所带来的开销，但是需要注意在高并发下这是使用cpu资源做交换的。

对于 `atomic.CompareAndSwapIntxx()` 之类函数的实现是在 `src/sync/atomic.asm.s` 文件里声明的，真正对应的汇编文件位于 `src/runtime/internal/atomic/*.s`，如64架构对应的文件为 `asm_amd64.s`。

`atomic.CompareAndSwapInt32` 和 `atomic.CompareAndSwapUint32` 对应的汇编是 `runtime∕internal∕atomic·Cas`;

```
// bool Cas(int32 *val, int32 old, int32 new)
// Atomically:
//    if(*val == old){
//        *val = new;
//        return 1;
//    } else
//        return 0;
TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17
    MOVQ    ptr+0(FP), BX
    MOVL    old+8(FP), AX
    MOVL    new+12(FP), CX
    LOCK
    CMPXCHGL    CX, 0(BX)
    SETEQ    ret+16(FP)
    RET
```

#### atomic源码实现：

##### Add操作

`AddUintptr` 、 `AddInt64` 以及 `AddUint64`都是由方法`runtime∕internal∕atomic·Xadd64`实现:

```
TEXT runtime∕internal∕atomic·Xadd64(SB), NOSPLIT, $0-24
	MOVQ	ptr+0(FP), BX // 第一个参数保存到BX
	MOVQ	delta+8(FP), AX // 第二个参数保存到AX
	MOVQ	AX, CX  // 将第二个参数临时存到CX寄存器中
	LOCK			// LOCK指令进行锁住操作，实现对共享内存独占访问
	XADDQ	AX, 0(BX) // xaddq指令，实现寄存器AX的值与BX指向的内存存的值互换，
	// 并将这两个值的和存在BX指向的内存中，此时AX寄存器存的是第一个参数指向的值
	ADDQ	CX, AX // 此时AX寄存器的值是Add操作之后的值，和0(BX)值一样
	MOVQ	AX, ret+16(FP) # 返回值
	RET
```

**LOCK**指令是一个指令前缀，其后是**读-写**性质的指令，在多处理器环境中，LOCK指令能够确保在执行LOCK随后的指令时，处理器拥有对数据的独占使用。若对应数据已经在cache line里，也就不用锁定总线，仅锁住缓存行即可，否则需要锁住总线来保证独占性。

**XADDQ**指令用于交换加操作，会将源操作数与目的操作数互换，并将两者的和保存到源操作数中。

`AddInt32` 、 `AddUint32` 都是由方法`runtime∕internal∕atomic·Xadd`实现，实现逻辑和`runtime∕internal∕atomic·Xadd64`一样，只是Xadd中相关数据操作指令后缀是`L`：

```
TEXT runtime∕internal∕atomic·Xadd(SB), NOSPLIT, $0-20
	MOVQ	ptr+0(FP), BX // 注意第一个参数是一个指针类型，是64位，所以还是MOVQ指令
	MOVL	delta+8(FP), AX // 第二个参数32位的，所以是MOVL指令
	MOVL	AX, CX
	LOCK
	XADDL	AX, 0(BX)
	ADDL	CX, AX
	MOVL	AX, ret+16(FP)
	RET
```

##### Store操作

`StoreInt64`、`StoreUint64`、`StoreUintptr`三个是`runtime∕internal∕atomic·Store64`方法实现:

```
TEXT runtime∕internal∕atomic·Store64(SB), NOSPLIT, $0-16
	MOVQ	ptr+0(FP), BX // 第一个参数保存到BX
	MOVQ	val+8(FP), AX // 第二个参数保存到AX
	XCHGQ	AX, 0(BX) // 将AX寄存器与BX寄存指向内存的值互换，
	// 那么第一个参数指向的内存存的值为第二个参数
	RET
```

**XCHGQ**指令是交换指令，用于交换源操作数和目的操作数。

`StoreInt32`、`StoreUint32`是由`runtime∕internal∕atomic·Store`方法实现，与`runtime∕internal∕atomic·Store64`逻辑一样，这里不在赘述。

##### CompareAndSwap操作

`CompareAndSwapUintptr`、`CompareAndSwapInt64`和`CompareAndSwapUint64`都是由`runtime∕internal∕atomic·Cas64`实现：

```
TEXT runtime∕internal∕atomic·Cas64(SB), NOSPLIT, $0-25
	MOVQ	ptr+0(FP), BX // 将第一个参数保存到BX
	MOVQ	old+8(FP), AX // 将第二个参数保存到AX
	MOVQ	new+16(FP), CX // 将第三个参数保存CX
	LOCK				 // LOCK指令进行上锁操作
	CMPXCHGQ	CX, 0(BX) // BX寄存器指向的内存的值与AX寄存器值进行比较，若相等则把CX寄存器值存储到BX寄存器指向的内存中
	SETEQ	ret+24(FP)
	RET
```

**CMPXCHGQ**指令是比较并交换指令，它的用法是将目的操作数和累加寄存器AX进行比较，若相等，则将源操作数复制到目的操作数中，否则将目的操作复制到累加寄存器中。

##### Swap操作

`SwapInt64`、`SwapUint64`、`SwapUintptr`实现的方法是`runtime∕internal∕atomic·Xchg64`，`SwapInt32`和`SwapUint32`底层实现是`runtime∕internal∕atomic·Xchg`，这里面只分析64的操作：

```
TEXT runtime∕internal∕atomic·Xchg64(SB), NOSPLIT, $0-24
	MOVQ	ptr+0(FP), BX // 第一个参数保存到BX
	MOVQ	new+8(FP), AX // 第一个参数保存到AX中
	XCHGQ	AX, 0(BX) // XCHGQ指令交互AX值到0(BX)中
	MOVQ	AX, ret+16(FP) // 将旧值返回
	RET
```

##### Load操作

`LoadInt32`、`LoadUint32`、`LoadInt64` 、 `LoadUint64` 、 `LoadUint64`、 `LoadUintptr`、`LoadPointer`实现都是Go实现的：

```
//go:linkname Load
//go:linkname Loadp
//go:linkname Load64

//go:nosplit
//go:noinline
func Load(ptr *uint32) uint32 {
	return *ptr
}

//go:nosplit
//go:noinline
func Loadp(ptr unsafe.Pointer) unsafe.Pointer {
	return *(*unsafe.Pointer)(ptr)
}

//go:nosplit
//go:noinline
func Load64(ptr *uint64) uint64 {
	return *ptr
}
```

最后我们来分析atomic.Value类型提供Load/Store操作。

##### atomic.Value类型的Load/Store操作

atomic.Value类型定义如下：

```
type Value struct {
	v interface{}
}

 // ifaceWords是空接口底层表示
type ifaceWords struct {
	typ  unsafe.Pointer
	data unsafe.Pointer
}
```

atomic.Value底层存储的是空接口类型，空接口底层结构如下：

```
type eface struct {
	_type *_type // 空接口持有的类型
	data  unsafe.Pointer // 指向空接口持有类型变量的指针
}
```

atomic.Value内存布局如下所示：

[![img](https://static.cyub.vip/images/202104/atomic_value_mem_layout.png)](https://static.cyub.vip/images/202104/atomic_value_mem_layout.png)

从上图可以看出来atomic.Value内部分为两部分，第一个部分是_type类型指针，第二个部分是unsafe.Pointer类型，两个部分大小都是8字节（64系统下）。我们可以通过以下代码进行测试：

```
type Value struct {
	v interface{}
}

type ifaceWords struct {
	typ  unsafe.Pointer
	data unsafe.Pointer
}

func main() {
	func main() {
	val := Value{v: 123456}
	t := (*ifaceWords)(unsafe.Pointer(&val))
	dp := (*t).data            // dp是非安全指针类型变量
	fmt.Println(*((*int)(dp))) // 输出123456

	var val2 Value
	t = (*ifaceWords)(unsafe.Pointer(&val2))
	fmt.Println(t.typ) // 输出nil
}
```

接下来我们看下Store方法：

```
func (v *Value) Store(x interface{}) {
	if x == nil { // atomic.Value类型变量不能是nil
		panic("sync/atomic: store of nil value into Value")
	}
	vp := (*ifaceWords)(unsafe.Pointer(v)) // 将指向atomic.Value类型指针转换成*ifaceWords类型
	xp := (*ifaceWords)(unsafe.Pointer(&x)) // xp是*faceWords类型指针，指向传入参数x
	for {
		typ := LoadPointer(&vp.typ) // 原子性返回vp.typ
		if typ == nil { // 第一次调用Store时候，atomic.Value底层结构体第一部分是nil，
		// 我们可以从上面测试代码可以看出来
			runtime_procPin() // pin process处理，防止M被抢占
			if !CompareAndSwapPointer(&vp.typ, nil, unsafe.Pointer(^uintptr(0))) { // 通过cas操作，将atomic.Value的第一部分存储为unsafe.Pointer(^uintptr(0))，若没操作成功，继续操作
				runtime_procUnpin() // unpin process处理，释放对当前M的锁定
				continue
			}

			// vp.data == xp.data
			// vp.typ == xp.typ
			StorePointer(&vp.data, xp.data)
			StorePointer(&vp.typ, xp.typ)
			runtime_procUnpin()
			return
		}
		if uintptr(typ) == ^uintptr(0) { // 此时说明第一次的Store操作未完成，正在处理中，此时其他的Store等待第一次操作完成
			continue
		}

		if typ != xp.typ { // 再次Store操作时进行typ类型校验，确保每次Store数据对象都必须是同一类型
			panic("sync/atomic: store of inconsistently typed value into Value")
		}
		StorePointer(&vp.data, xp.data) // vp.data == xp.data
		return
	}
}
```

总结上面Store流程：

1. 每次调用Store方法时候，会将传入参数转换成interface{}类型。当第一次调用Store方法时候，分两部分操作，分别将传入参数空接口类型的_typ和data，存储到Value类型中。
2. 当再次调用Store类型时候，进行传入参数空接口类型的_type和Value的_type比较，若不一致直接panic，若一致则将data存储到Value类型中

从流程2可以看出来，**每次调用Store方法时传入参数都必须是同一类型的变量**。当Store完成之后，实现了“鸠占鹊巢”，atomic.Value底层存储的实际上是(interface{})x。

最后我们看看atomic.Value的Load操作：

```
func (v *Value) Load() (x interface{}) {
	vp := (*ifaceWords)(unsafe.Pointer(v)) // 将指向v指针转换成*ifaceWords类型
	typ := LoadPointer(&vp.typ)
	if typ == nil || uintptr(typ) == ^uintptr(0) { // typ == nil 说明Store方法未调用过
	// uintptr(typ) == ^uintptr(0) 说明第一Store方法调用正在进行中
		return nil
	}
	data := LoadPointer(&vp.data)
	xp := (*ifaceWords)(unsafe.Pointer(&x))
	xp.typ = typ
	xp.data = data
	return
}
```

#### 5.2 逃逸分析

**go逃逸场景有哪些，我？？？**

「逃逸分析」就是程序运行时内存的分配位置(栈或堆)，是由编译器来确定的。堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。

逃逸场景：

- 指针逃逸
- 栈空间不足逃逸
- 动态类型逃逸
- 闭包引用对象逃逸

### 6. go 中除了加 Mutex 锁以外还有哪些方式安全读写共享变量？

Go 中 Goroutine 可以通过 Channel 进行安全读写共享变量。

### 7. golang中new和make的区别？

用new还是make？到底该如何选择？

- make 仅用来分配及初始化类型为 slice、map、chan 的数据。
- new 可分配任意类型的数据，根据传入的类型申请一块内存，返回指向这块内存的指针，即类型 *Type。
- make 返回引用，即 Type，new 分配的空间被清零， make 分配空间后，会进行初始。

### 8. Go中对nil的Slice和空Slice的处理是一致的吗?

首先Go的JSON 标准库对 nil slice 和 空 slice 的处理是不一致。

- slice := make([]int,0）：slice不为nil，但是slice没有值，slice的底层的空间是空的。
- slice := []int{} ：slice的值是nil，可用于需要返回slice的函数，当函数出现异常的时候，保证函数依然会有nil的返回值。

### 9. 协程和线程和进程的区别？

并发掌握，goroutine和channel声明与使用！

- 进程: 进程是具有一定独立功能的程序，进程是系统资源分配和调度的最小单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。
- 线程: 线程是进程的一个实体,线程是内核态,而且是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

协程: 协程是一种用户态的轻量级线程，协程的调度完全是由用户来控制的。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

- 一个线程可以有多个协程
- 线程、进程都是同步机制，而协程是异步
- 协程可以保留上一次调用时的状态，当过程重入时，相当于进入了上一次的调用状态
- 协程是需要线程来承载运行的，所以协程并不能取代线程，「线程是被分割的CPU资源，协程是组织好的代码流程

### 10. Golang的内存模型中为什么小对象多了会造成GC压力？

通常小对象过多会导致GC三色法消耗过多的GPU。优化思路是，减少对象分配。

### 11. channel 为什么它可以做到线程安全？

Channel 可以理解是一个先进先出的队列，通过管道进行通信,发送一个数据到Channel和从Channel接收一个数据都是原子性的。不要通过共享内存来通信，而是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。设计Channel的主要目的就是在多任务间传递数据的，本身就是安全的。

### 12. 垃圾回收机制的触发条件？

主动触发(手动触发)，通过调用 runtime.GC 来触发GC，此调用阻塞式地等待当前GC运行完毕。
被动触发，分为两种方式：

- 使用步调（Pacing）算法，其核心思想是控制内存增长的比例,每次内存分配时检查当前内存分配量是否已达到阈值（环境变量GOGC）：默认100%，即当内存扩大一倍时启用GC。
- 使用系统监控，当超过两分钟没有产生任何GC时，强制触发 GC。

### 13. 怎么查看Goroutine的数量？怎么限制Goroutine的数量？

- 在Golang中,GOMAXPROCS中控制的是未被阻塞的所有Goroutine,可以被 Multiplex 到多少个线程上运行,通过GOMAXPROCS可以查看Goroutine的数量。
- 使用通道。每次执行的go之前向通道写入值，直到通道满的时候就阻塞了。

### 14. Channel是同步的还是异步的？

Channel是异步进行的, channel存在3种状态：

- nil，未初始化的状态，只进行了声明，或者手动赋值为nil
- active，正常的channel，可读或者可写
- closed，已关闭，千万不要误认为关闭channel后，channel的值是nil

| 操作     | 一个零值nil通道 | 一个非零值但已关闭的通道 | 一个非零值且尚未关闭的通道 |
| :------- | :-------------- | :----------------------- | :------------------------- |
| 关闭     | 产生恐慌        | 产生恐慌                 | 成功关闭                   |
| 发送数据 | 永久阻塞        | 产生恐慌                 | 阻塞或者成功发送           |
| 接收数据 | 永久阻塞        | 永不阻塞                 | 阻塞或者成功接收           |

### 16. Go的Struct能不能比较？

- 相同struct类型的可以比较
- 不同struct类型的不可以比较,编译都不过，类型不匹配

### 17. Go主协程如何等其余协程完再操作？

使用sync.WaitGroup。WaitGroup，就是用来等待一组操作完成的。WaitGroup内部实现了一个计数器，用来记录未完成的操作个数。Add()用来添加计数；Done()用来在操作结束时调用，使计数减一；Wait()用来等待所有的操作结束，即计数变为0，该函数会在计数不为0时等待，在计数为0时立即返回。

### 18. Go的Slice如何扩容？

**slice 实现原理**

- `Data` 是指向数组的指针;
- `Len` 是当前切片的长度；
- `Cap` 是当前切片的容量，即 `Data` 数组的大小

`Data` 是一片连续的内存空间，这片内存空间可以用于存储切片中的全部元素，数组中的元素只是逻辑上的概念，底层存储其实都是连续的，所以我们可以将切片理解成一片连续的内存空间加上长度与容量的标识。

在使用 append 向 slice 追加元素时，若 slice 空间不足则会发生扩容，扩容会重新分配一块更大的内存，将原 slice 拷贝到新 slice ，然后返回新 slice。扩容后再将数据追加进去。

扩容操作只对容量，扩容后的 slice 长度不变，容量变化规则如下：

- 若 slice 容量小于1024个元素，那么扩容的时候slice的cap就翻番，乘以2；一旦元素个数超过1024个元素，增长因子就变成1.25，即每次增加原来容量的四分之一。
- 若 slice 容量够用，则将新元素追加进去，slice.len++，返回原 slice
- 若 slice 容量不够用，将 slice 先扩容，扩容得到新 slice，将新元素追加进新 slice，slice.len++，返回新 slice。
- 如果期望容量大于当前容量的两倍就会使用期望容量；
- 如果当前切片的长度小于 1024 就会将容量翻倍；
- 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量

### 19. Go中的map如何实现顺序读取？

Go中map如果要实现顺序读取的话，可以先把map中的key，通过sort包排序。

### 20.map哈希设计解决冲突

#### 开放寻址法 [#](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/#开放寻址法)

[开放寻址法](https://en.wikipedia.org/wiki/Open_addressing)[2](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/#fn:2)是一种在哈希表中解决哈希碰撞的方法，这种方法的核心思想是**依次探测和比较数组中的元素以判断目标键值对是否存在于哈希表中**，如果我们使用开放寻址法来实现哈希表，那么实现哈希表底层的数据结构就是数组，不过因为数组的长度有限，向哈希表写入 (author, draven) 这个键值对时会从如下的索引开始遍历：

```go
index := hash("author") % array.len
```

当我们向当前哈希表写入新的数据时，如果发生了冲突，就会将键值对写入到下一个索引不为空的位置：

![open-addressing-and-set](https://img.draveness.me/2019-12-30-15777168478785-open-addressing-and-set.png)



如上图所示，当 Key3 与已经存入哈希表中的两个键值对 Key1 和 Key2 发生冲突时，Key3 会被写入 Key2 后面的空闲位置。当我们再去读取 Key3 对应的值时就会先获取键的哈希并取模，这会先帮助我们找到 Key1，找到 Key1 后发现它与 Key 3 不相等，所以会继续查找后面的元素，直到内存为空或者找到目标元素。

![open-addressing-and-get](https://img.draveness.me/2019-12-30-15777168478791-open-addressing-and-get.png)



当需要查找某个键对应的值时，会从索引的位置开始线性探测数组，找到目标键值对或者空内存就意味着这一次查询操作的结束。

开放寻址法中对性能影响最大的是**装载因子**，它是数组中元素的数量与数组大小的比值。随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会影响哈希表的读写性能。当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找和插入任意元素的时间复杂度都是 O(n)O(n) 的，这时需要遍历数组中的全部元素，所以在实现哈希表时一定要关注装载因子的变化。

#### 拉链法 [#](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/#拉链法)

与开放地址法相比，拉链法是哈希表最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。

实现拉链法一般会使用数组加上链表，不过一些编程语言会在拉链法的哈希中引入红黑树以优化性能，拉链法会使用链表数组作为哈希底层的数据结构，我们可以将它看成可以扩展的二维数组：

![separate-chaing-and-set](https://img.draveness.me/2019-12-30-15777168478798-separate-chaing-and-set.png)

如上图所示，当我们需要将一个键值对 (Key6, Value6) 写入哈希表时，键值对中的键 Key6 都会先经过一个哈希函数，哈希函数返回的哈希会帮助我们选择一个桶，和开放地址法一样，选择桶的方式是直接对哈希返回的结果取模：

```go
index := hash("Key6") % array.len
```

选择了 2 号桶后就可以遍历当前桶中的链表了，在遍历链表的过程中会遇到以下两种情况：

1. 找到键相同的键值对 — 更新键对应的值；
2. 没有找到键相同的键值对 — 在链表的末尾追加新的键值对；

如果要在哈希表中获取某个键对应的值，会经历如下的过程：

<img src="https://img.draveness.me/2019-12-30-15777168478804-separate-chaing-and-get.png" alt="separate-chaing-and-get" style="zoom: 50%;" />

Key11 展示了一个键在哈希表中不存在的例子，当哈希表发现它命中 4 号桶时，它会依次遍历桶中的链表，然而遍历到链表的末尾也没有找到期望的键，所以哈希表中没有该键对应的值。

在一个性能比较好的哈希表中，每一个桶中都应该有 0~1 个元素，有时会有 2~3 个，很少会超过这个数量。计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：

装载因子:=元素数量÷桶数量

与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差。在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。

### 21.map原理

哈希查找表，并且使用链表解决哈希冲突

```
// A header for a Go map.
type hmap struct {
    // 元素个数，调用 len(map) 时，直接返回此值
	count     int
	flags     uint8
	// buckets 的对数 log_2
	B         uint8
	//B 表示当前哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数，所以该字段会存储对数，也就是 len(buckets) == 2^B；
	// overflow 的 bucket 近似数
	noverflow uint16
	// 计算 key 的哈希的时候会传入哈希函数
	hash0     uint32
    // 指向 buckets 数组，大小为 2^B
    // 如果元素个数为0，就为 nil
	buckets    unsafe.Pointer
	// 等量扩容的时候，buckets 长度和 oldbuckets 相等
	// 双倍扩容的时候，buckets 长度会是 oldbuckets 的两倍
	oldbuckets unsafe.Pointer
	// 指示扩容进度，小于此地址的 buckets 迁移完成
	nevacuate  uintptr
	extra *mapextra // optional fields
}

type mapextra struct {
	overflow    *[]*bmap
	oldoverflow *[]*bmap
	nextOverflow *bmap
}
count 表示当前哈希表中的元素数量；

hash0 是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入；
oldbuckets 是哈希在扩容时用于保存之前 buckets 的字段，它的大小是当前 buckets 的一半；
```

哈希表 [`runtime.hmap`](https://draveness.me/golang/tree/runtime.hmap) 的桶是 [`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap)。每一个 [`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap) 都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 `extra.nextOverflow` 中桶存储溢出的数据。

上述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶，上图中黄色的 [`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap) 就是正常桶，绿色的 [`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap) 是溢出桶，溢出桶是在 Go 语言还使用 C 语言实现时使用的设计[3](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/#fn:3)，由于它能够减少扩容的频率所以一直使用至今。

桶的结构体 [`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap) 在 Go 语言源代码中的定义只包含一个简单的 `tophash` 字段，`tophash` 存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能：

```go
type bmap struct {	
    tophash [bucketCnt]uint8
}
```

在运行期间，[`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap) 结构体其实不止包含 `tophash` 字段，因为哈希表中可能存储不同类型的键值对，而且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导。[`runtime.bmap`](https://draveness.me/golang/tree/runtime.bmap) 中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的 [`cmd/compile/internal/gc.bmap`](https://draveness.me/golang/tree/cmd/compile/internal/gc.bmap) 函数重建它的结构：



```go
type bmap struct {
    topbits  [8]uint8
    keys     [8]keytype
    values   [8]valuetype
    pad      uintptr
    overflow uintptr
}
```

<img src="https://golang.design/go-questions/map/assets/1.png" alt="bmap struct" style="zoom:33%;" />

随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。

`bmap` 就是我们常说的“桶”，桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置）。

<img src="https://golang.design/go-questions/map/assets/0.png" alt="hashmap bmap" style="zoom:33%;" />

#### map访问get操作？

- 当接受一个参数时，会使用 [`runtime.mapaccess1`](https://draveness.me/golang/tree/runtime.mapaccess1)，该函数仅会返回一个指向目标值的指针；
- 当接受两个参数时，会使用 [`runtime.mapaccess2`](https://draveness.me/golang/tree/runtime.mapaccess2)，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 `bool` 值：

[`runtime.mapaccess1`](https://draveness.me/golang/tree/runtime.mapaccess1) 会先通过哈希表设置的哈希函数、种子获取当前键对应的哈希，再通过 [`runtime.bucketMask`](https://draveness.me/golang/tree/runtime.bucketMask) 和 [`runtime.add`](https://draveness.me/golang/tree/runtime.add) 拿到该键值对所在的桶序号和哈希高位的 8 位数字。

#### map为什么访问是无序的？

map 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。

当然，如果我就一个 hard code 的 map，我也不会向 map 进行插入删除的操作，按理说每次遍历这样的 map 都会返回一个固定顺序的 key/value 序列吧。的确是这样，但是 Go 杜绝了这种做法，因为这样会给新手程序员带来误解，以为这是一定会发生的事情，在某些情况下，可能会酿成大错。

当然，Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。这样，即使你是一个写死的 map，仅仅只是遍历它，也不太可能会返回一个固定序列的 key/value 对了。



#### map写入过程？，map桶满了怎么办？

当形如 `hash[k]` 的表达式出现在赋值符号左侧时，该表达式也会在编译期间转换成 [`runtime.mapassign`](https://draveness.me/golang/tree/runtime.mapassign) 函数的调用，该函数与 [`runtime.mapaccess1`](https://draveness.me/golang/tree/runtime.mapaccess1) 比较相似，我们将其分成几个部分依次分析，首先是函数会根据传入的键拿到对应的哈希和桶，然后通过遍历比较桶中存储的 `tophash` 和键的哈希，如果找到了相同结果就会返回目标位置的地址。其中 `inserti` 表示目标元素的在桶中的索引，`insertk` 和 `val` 分别表示键值对的地址，获得目标地址之后会通过算术计算寻址获得键值对 `k` 和 `val`，上述的 for 循环会依次遍历正常桶和溢出桶中存储的数据，整个过程会分别判断 `tophash` 是否相等、`key` 是否相等，遍历结束后会从循环中跳出。

如果当前桶已经满了，哈希会调用 [`runtime.hmap.newoverflow`](https://draveness.me/golang/tree/runtime.hmap.newoverflow) 创建新桶或者使用 [`runtime.hmap`](https://draveness.me/golang/tree/runtime.hmap) 预先在 `noverflow` 中创建好的桶来保存数据，新创建的桶不仅会被追加到已有桶的末尾，还会增加哈希表的 `noverflow` 计数器。

如果写入的当前键值对在哈希中不存在，哈希会为新键值对规划存储的内存地址，通过 [`runtime.typedmemmove`](https://draveness.me/golang/tree/runtime.typedmemmove) 将键移动到对应的内存空间中并返回键对应值的地址 `val`。

如果当前键值对在哈希中存在，那么就会直接返回目标区域的内存地址，哈希并不会在 [`runtime.mapassign`](https://draveness.me/golang/tree/runtime.mapassign) 这个运行时函数中将值拷贝到桶中，该函数只会返回内存地址，真正的赋值操作是在编译期间插入的。

#### map删除过程

写操作底层的执行函数是 `mapdelete`：

| `1 ` | `func mapdelete(t *maptype, h *hmap, key unsafe.Pointer)  ` |
| ---- | ----------------------------------------------------------- |
|      |                                                             |

根据 key 类型的不同，删除操作会被优化成更具体的函数：

| key 类型 | 删除                                              |
| -------- | ------------------------------------------------- |
| uint32   | mapdelete_fast32(t *maptype, h *hmap, key uint32) |
| uint64   | mapdelete_fast64(t *maptype, h *hmap, key uint64) |
| string   | mapdelete_faststr(t *maptype, h *hmap, ky string) |

当然，我们只关心 `mapdelete` 函数。它首先会检查 h.flags 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。

计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。

删除操作同样是两层循环，核心还是找到 key 的具体位置。寻找过程都是类似的，在 bucket 中挨个 cell 寻找。

找到对应位置后，对 key 或者 value 进行“清零”操作：

```golang
// 对 key 清零
if t.indirectkey {
	*(*unsafe.Pointer)(k) = nil
} else {
	typedmemclr(t.key, k)
}

// 对 value 清零
if t.indirectvalue {
	*(*unsafe.Pointer)(v) = nil
} else {
	typedmemclr(t.elem, v)
}
```

最后，将 count 值减 1，将对应位置的 tophash 值置成 `Empty`。

#### map扩容过程

哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。

装载因子：

```golang
loadFactor := count / (2^B)
```

[`runtime.mapassign`](https://draveness.me/golang/tree/runtime.mapassign) 函数会在以下两种情况发生时触发哈希的扩容：

1. 装载因子已经超过 6.5；
2. overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B >= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。

第 1 点：我们知道，每个 bucket 有 8 个空位，在没有溢出，且所有的桶都装满了的情况下，装载因子算出来的结果是 8。因此当装载因子超过 6.5 时，表明很多 bucket 都快要装满了，查找效率和插入效率都变低了。在这个时候进行扩容是有必要的。

第 2 点：是对第 1 点的补充。就是说在装载因子比较小的情况下，这时候 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是 bucket 数量多（真实分配的 bucket 数量多，包括大量的 overflow bucket）。

不难想像造成这种情况的原因：不停地插入、删除元素。先插入很多元素，导致创建了很多 bucket，但是装载因子达不到第 1 点的临界值，未触发扩容来缓解这种情况。之后，删除元素降低元素总数量，再插入很多元素，导致创建很多的 overflow bucket，但就是不会触犯第 1 点的规定，你能拿我怎么办？overflow bucket 数量太多，导致 key 会很分散，查找插入效率低得吓人，因此出台第 2 点规定。这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。

对于命中条件 1，2 的限制，都会发生扩容。但是扩容的策略并不相同，毕竟两种条件应对的场景不同。

对于条件 1，元素太多，而 bucket 数量太少，很简单：将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。

对于条件 2，其实元素没那么多，但是 overflow bucket 数特别多，说明很多 bucket 都没装满。解决办法就是开辟一个新 bucket 空间，将老 bucket 中的元素移动到新 bucket，使得同一个 bucket 中的 key 排列地更紧密。这样，原来，在 overflow bucket 中的 key 可以移动到 bucket 中来。结果是节省空间，提高 bucket 利用率，map 的查找和插入效率自然就会提升。

由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。

上面说的 `hashGrow()` 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 `growWork()` 函数中，而调用 `growWork()` 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。

#### map创建过程

```golang
func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap {
	// 省略各种条件检查...

	// 找到一个 B，使得 map 的装载因子在正常范围内
	B := uint8(0)
	for ; overLoadFactor(hint, B); B++ {
	}

	// 初始化 hash table
	// 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配
	// 如果长度比较大，分配内存会花费长一点
	buckets := bucket
	var extra *mapextra
	if B != 0 {
		var nextOverflow *bmap
		buckets, nextOverflow = makeBucketArray(t, B)
		if nextOverflow != nil {
			extra = new(mapextra)
			extra.nextOverflow = nextOverflow
		}
	}

	// 初始化 hamp
	if h == nil {
		h = (*hmap)(newobject(t.hmap))
	}
	h.count = 0
	h.B = B
	h.extra = extra
	h.flags = 0
	h.hash0 = fastrand()
	h.buckets = buckets
	h.oldbuckets = nil
	h.nevacuate = 0
	h.noverflow = 0

	return h
}
```

#### slice 和 map 分别作为函数参数时有什么区别？

函数返回的结果：`*hmap`，它是一个指针，而我们之前讲过的 `makeslice` 函数返回的是 `Slice` 结构体：

| `1 ` | `func makeslice(et *_type, len, cap int) slice ` |
| ---- | ------------------------------------------------ |
|      |                                                  |

回顾一下 slice 的结构体定义：

| `1 2 3 4 5 6 ` | `// runtime/slice.go type slice struct {    array unsafe.Pointer // 元素指针    len   int // 长度     cap   int // 容量 } ` |
| -------------- | ------------------------------------------------------------ |
|                |                                                              |

结构体内部包含底层的数据指针。

makemap 和 makeslice 的区别，带来一个不同点：当 map 和 slice 作为函数参数时，在函数参数内部对 map 的操作会影响 map 自身；而对 slice 却不会（之前讲 slice 的文章里有讲过）。

主要原因：一个是指针（`*hmap`），一个是结构体（`slice`）。Go 语言中的函数传参都是值传递，在函数内部，参数会被 copy 到本地。`*hmap`指针 copy 完之后，仍然指向同一个 map，因此函数内部对 map 的操作会影响实参。而 slice 被 copy 后，会成为一个新的 slice，对它进行的操作不会影响到实参。

#### map key 定位过程，插入过程 [#](https://golang.design/go-questions/map/principal/#key-定位过程)

key 经过哈希计算后得到哈希值，共 64 个 bit 位（64位机，32位机就不讨论了，现在主流都是64位机），计算它到底要落在哪个桶时，只会用到最后 B 个 bit 位。还记得前面提到过的 B 吗？如果 B = 5，那么桶的数量，也就是 buckets 数组的长度是 2^5 = 32。

例如，现在有一个 key 经过哈希函数计算后，得到的哈希结果是：

| `1 ` | ` 10010111 | 000011110110110010001111001010100010010110010101010 │ 01010 ` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

用最后的 5 个 bit 位，也就是 `01010`，值为 10，也就是 10 号桶。这个操作实际上就是取余操作，但是取余开销太大，所以代码实现上用的位操作代替。

再用哈希值的高 8 位，找到此 key 在 bucket 中的位置，这是在寻找已有的 key。最开始桶内还没有 key，新加入的 key 会找到第一个空位，放入。

buckets 编号就是桶编号，当两个不同的 key 落在同一个桶中，也就是发生了哈希冲突。冲突的解决手段是用链表法：在 bucket 中，从前往后找到第一个空位。这样，在查找某个 key 时，先找到对应的桶，再去遍历 bucket 中的 key。

<img src="https://golang.design/go-questions/map/assets/2.png" alt="mapacess" style="zoom:30%;" />

上图中，假定 B = 5，所以 bucket 总数就是 2^5 = 32。首先计算出待查找 key 的哈希，使用低 5 位 `00110`，找到对应的 6 号 bucket，使用高 8 位 `10010111`，对应十进制 151，在 6 号 bucket 中寻找 tophash 值（HOB hash）为 151 的 key，找到了 2 号槽位，这样整个查找过程就结束了。

如果在 bucket 中没找到，并且 overflow 不为空，还要继续去 overflow bucket 中寻找，直到找到或是所有的 key 槽位都找遍了，包括所有的 overflow bucket。

```golang
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	// ……
	
	// 如果 h 什么都没有，返回零值
	if h == nil || h.count == 0 {
		return unsafe.Pointer(&zeroVal[0])
	}
	
	// 写和读冲突
	if h.flags&hashWriting != 0 {
		throw("concurrent map read and map write")
	}
	
	// 不同类型 key 使用的 hash 算法在编译期确定
	alg := t.key.alg
	
	// 计算哈希值，并且加入 hash0 引入随机性
	hash := alg.hash(key, uintptr(h.hash0))
	
	// 比如 B=5，那 m 就是31，二进制是全 1
	// 求 bucket num 时，将 hash 与 m 相与，
	// 达到 bucket num 由 hash 的低 8 位决定的效果
	m := uintptr(1)<<h.B - 1
	
	// b 就是 bucket 的地址
	b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))
	
	// oldbuckets 不为 nil，说明发生了扩容
	if c := h.oldbuckets; c != nil {
	    // 如果不是同 size 扩容（看后面扩容的内容）
	    // 对应条件 1 的解决方案
		if !h.sameSizeGrow() {
			// 新 bucket 数量是老的 2 倍
			m >>= 1
		}
		
		// 求出 key 在老的 map 中的 bucket 位置
		oldb := (*bmap)(add(c, (hash&m)*uintptr(t.bucketsize)))
		
		// 如果 oldb 没有搬迁到新的 bucket
		// 那就在老的 bucket 中寻找
		if !evacuated(oldb) {
			b = oldb
		}
	}
	
	// 计算出高 8 位的 hash
	// 相当于右移 56 位，只取高8位
	top := uint8(hash >> (sys.PtrSize*8 - 8))
	
	// 增加一个 minTopHash
	if top < minTopHash {
		top += minTopHash
	}
	for {
	    // 遍历 bucket 的 8 个位置
		for i := uintptr(0); i < bucketCnt; i++ {
		    // tophash 不匹配，继续
			if b.tophash[i] != top {
				continue
			}
			// tophash 匹配，定位到 key 的位置
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			// key 是指针
			if t.indirectkey {
			    // 解引用
				k = *((*unsafe.Pointer)(k))
			}
			// 如果 key 相等
			if alg.equal(key, k) {
			    // 定位到 value 的位置
				v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))
				// value 解引用
				if t.indirectvalue {
					v = *((*unsafe.Pointer)(v))
				}
				return v
			}
		}
		
		// bucket 找完（还没找到），继续到 overflow bucket 里找
		b = b.overflow(t)
		// overflow bucket 也找完了，说明没有目标 key
		// 返回零值
		if b == nil {
			return unsafe.Pointer(&zeroVal[0])
		}
	}
}
```

#### map遍历过程

遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value

先是调用 `mapiterinit` 函数初始化迭代器，然后循环调用 `mapiternext` 函数进行 map 迭代。

迭代器的结构体定义：

```
type hiter struct {
	// key 指针
	key         unsafe.Pointer
	// value 指针
	value       unsafe.Pointer
	// map 类型，包含如 key size 大小等
	t           *maptype
	// map header
	h           *hmap
	// 初始化时指向的 bucket
	buckets     unsafe.Pointer
	// 当前遍历到的 bmap
	bptr        *bmap
	overflow    [2]*[]*bmap
	// 起始遍历的 bucket 编号
	startBucket uintptr
	// 遍历开始时 cell 的编号（每个 bucket 中有 8 个 cell）
	offset      uint8
	// 是否从头遍历了
	wrapped     bool
	// B 的大小
	B           uint8
	// 指示当前 cell 序号
	i           uint8
	// 指向当前的 bucket
	bucket      uintptr
	// 因为扩容，需要检查的 bucket
	checkBucket uintptr
}
```

`mapiterinit` 就是对 hiter 结构体里的字段进行初始化赋值操作。

```golang
// 生成随机数 r
r := uintptr(fastrand())
if h.B > 31-bucketCntBits {
	r += uintptr(fastrand()) << 31
}

// 从哪个 bucket 开始遍历
it.startBucket = r & (uintptr(1)<<h.B - 1)
// 从 bucket 的哪个 cell 开始遍历
it.offset = uint8(r >> h.B & (bucketCnt - 1))
```

在 `mapiternext` 函数中就会从 it.startBucket 的 it.offset 号的 cell 开始遍历，取出其中的 key 和 value，直到又回到起点 bucket，完成遍历过程

#### map赋值过程

对 key 计算 hash 值，根据 hash 值按照之前的流程，找到要赋值的位置（可能是插入新 key，也可能是更新老 key），对相应位置进行赋值。

源码大体和之前讲的类似，核心还是一个双层循环，外层遍历 bucket 和它的 overflow bucket，内层遍历整个 bucket 的各个 cell

#### map可以边遍历边删除吗

map 并不是一个线程安全的数据结构。同时读写一个 map 是未定义的行为，如果被检测到，会直接 panic。

上面说的是发生在多个协程同时读写同一个 map 的情况下。 如果在同一个协程内边遍历边删除，并不会检测到同时读写，理论上是可以这样做的。但是，遍历的结果就可能不会是相同的了，有可能结果遍历结果集中包含了删除的 key，也有可能不包含，这取决于删除 key 的时间：是在遍历到 key 所在的 bucket 时刻前或者后。

一般而言，这可以通过读写锁来解决：`sync.RWMutex`。

读之前调用 `RLock()` 函数，读完之后调用 `RUnlock()` 函数解锁；写之前调用 `Lock()` 函数，写完之后，调用 `Unlock()` 解锁。

另外，`sync.Map` 是线程安全的 map，也可以使用。

#### 可以对 map 的元素取地址吗

无法对 map 的 key 或 value 进行取址。

如果通过其他 hack 的方式，例如 unsafe.Pointer 等获取到了 key 或 value 的地址，也不能长期持有，因为一旦发生扩容，key 和 value 的位置就会改变，之前保存的地址也就失效了。

#### 如何比较两个 map 相等

map 深度相等的条件：

```shell
1、都为 nil
2、非空、长度相等，指向同一个 map 实体对象
3、相应的 key 指向的 value “深度”相等
```

直接将使用 map1 == map2 是错误的。这种写法只能比较 map 是否为 nil。

因此只能是遍历map 的每个元素，比较元素是否都是深度相等。

#### map线程安全吗？

map 不是线程安全的。

在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（等于1），则直接 panic。赋值和删除函数在检测完写标志是复位之后，先将写标志位置位，才会进行之后的操作。

### 21. Go值接收者和指针接收者的区别？

**究竟在什么情况下才使用指针？**

**参数传递中，值、引用及指针之间的区别！**

方法的接收者:

- 值类型，既可以调用值接收者的方法，也可以调用指针接收者的方法；
- 指针类型，既可以调用指针接收者的方法，也可以调用值接收者的方法。

但是接口的实现，值类型接收者和指针类型接收者不一样：

- 以值类型接收者实现接口，类型本身和该类型的指针类型，都实现了该接口；
- 以指针类型接收者实现接口，只有对应的指针类型才被认为实现了接口。

通常我们使用指针作为方法的接收者的理由：

- 使用指针方法能够修改接收者指向的值。
- 可以避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。

### 22. 在Go函数中为什么会发生内存泄露？

Goroutine 需要维护执行用户代码的上下文信息，在运行过程中需要消耗一定的内存来保存这类信息，如果一个程序持续不断地产生新的 goroutine，且不结束已经创建的 goroutine 并复用这部分内存，就会造成内存泄漏的现象。

- 临时性泄露，指的是该释放的内存资源没有及时释放，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是 string、slice 底层 buffer 的错误共享，导致无用数据对象无法及时释放，或者 defer 函数导致的资源没有及时释放。
- 永久性泄露，指的是在进程后续生命周期内，泄露的内存都没有机会回收，如 goroutine 内部预期之外的`for-loop`或者`chan select-case`导致的无法退出的情况，导致协程栈及引用内存永久泄露问题。

### 23. Goroutine发生了泄漏如何检测？

可以通过Go自带的工具pprof或者使用Gops去检测诊断当前在系统上运行的Go进程的占用的资源。

### 24. Go中两个Nil可能不相等吗？

Go中两个Nil可能不相等。

接口(interface) 是对非接口值(例如指针，struct等)的封装，内部实现包含 2 个字段，类型 T 和 值 V。一个接口等于 nil，当且仅当 T 和 V 处于 unset 状态（T=nil，V is unset）。

两个接口值比较时，会先比较 T，再比较 V。接口值与非接口值比较时，会先将非接口值尝试转换为接口值，再比较。

```
func main() {
 var p *int = nil
 var i interface{} = p
 fmt.Println(i == p) // true
 fmt.Println(p == nil) // true
 fmt.Println(i == nil) // false
}
```

- 例子中，将一个nil非接口值p赋值给接口i，此时,i的内部字段为(T=*int, V=nil)，i与p作比较时，将 p 转换为接口后再比较，因此 i == p，p 与 nil 比较，直接比较值，所以 p == nil。
- 但是当 i 与nil比较时，会将nil转换为接口(T=nil, V=nil),与i(T=*int, V=nil)不相等，因此 i != nil。因此 V 为 nil ，但 T 不为 nil 的接口不等于 nil。

### 25. Go语言函数传参是值类型还是引用类型？

- 在Go语言中只存在值传递，要么是值的副本，要么是指针的副本。无论是值类型的变量还是引用类型的变量亦或是指针类型的变量作为参数传递都会发生值拷贝，开辟新的内存空间。
- 另外值传递、引用传递和值类型、引用类型是两个不同的概念，不要混淆了。引用类型作为变量传递可以影响到函数外部是因为发生值拷贝后新旧变量指向了相同的内存地址。

### 26. Go语言中的内存对齐了解吗？

CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如 32 位的 CPU ，字长为 4 字节，那么 CPU 访问内存的单位也是 4 字节。

CPU 始终以字长访问内存，如果不进行内存对齐，很可能增加 CPU 访问内存的次数，例如：

![null](https://www.topgoer.cn/uploads/blog/202111/attach_16b441eb3214e65c.jpg)

变量 a、b 各占据 3 字节的空间，内存对齐后，a、b 占据 4 字节空间，CPU 读取 b 变量的值只需要进行一次内存访问。如果不进行内存对齐，CPU 读取 b 变量的值需要进行 2 次内存访问。第一次访问得到 b 变量的第 1 个字节，第二次访问得到 b 变量的后两个字节。

也可以看到，内存对齐对实现变量的原子性操作也是有好处的，每次内存访问是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，这个特性在并发场景下至关重要。

简言之：合理的内存对齐可以提高内存读写的性能，并且便于实现变量操作的原子性。

### 27. 两个 interface 可以比较吗？

- 判断类型是否一样

reflect.TypeOf(a).Kind() == reflect.TypeOf(b).Kind()

- 判断两个interface{}是否相等

reflect.DeepEqual(a, b interface{})

- 将一个interface{}赋值给另一个interface{}

reflect.ValueOf(a).Elem().Set(reflect.ValueOf(b))

### 28. go 打印时 %v %+v %#v 的区别？

- %v 只输出所有的值；
- %+v 先输出字段名字，再输出该字段的值；
- %#v 先输出结构体名字值，再输出结构体（字段名字+字段的值）；

```
package main
import "fmt"

type student struct {
 id   int32
 name string
}

func main() {
 a := &student{id: 1, name: "微客鸟窝"}

 fmt.Printf("a=%v \n", a) // a=&{1 微客鸟窝} 
 fmt.Printf("a=%+v \n", a) // a=&{id:1 name:微客鸟窝} 
 fmt.Printf("a=%#v \n", a) // a=&main.student{id:1, name:"微客鸟窝"}
}
```

### 29. 什么是 rune 类型？

Go语言的字符有以下两种：

- uint8 类型，或者叫 byte 型，代表了 ASCII 码的一个字符。
- rune 类型，代表一个 UTF-8 字符，当需要处理中文、日文或者其他复合字符时，则需要用到 rune 类型。rune 类型等价于 int32 类型。

```
package main
import "fmt"

func main() {
    var str = "hello 你好" //思考下 len(str) 的长度是多少？

    //golang中string底层是通过byte数组实现的，直接求len 实际是在按字节长度计算  
    //所以一个汉字占3个字节算了3个长度
    fmt.Println("len(str):", len(str))  // len(str): 12

    //通过rune类型处理unicode字符
    fmt.Println("rune:", len([]rune(str))) //rune: 8
}
```

### 30. 空 struct{} 占用空间么？

可以使用 unsafe.Sizeof 计算出一个数据类型实例需要占用的字节数:

```
package main

import (
 "fmt"
 "unsafe"
)

func main() {
 fmt.Println(unsafe.Sizeof(struct{}{}))  //0
}
```

空结构体 struct{} 实例不占据任何的内存空间。

### 31. 空 struct{} 的用途？

因为空结构体不占据内存空间，因此被广泛作为各种场景下的占位符使用。

1. 将 map 作为集合(Set)使用时，可以将值类型定义为空结构体，仅作为占位符使用即可。

```
type Set map[string]struct{}

func (s Set) Has(key string) bool {
 _, ok := s[key]
 return ok
}

func (s Set) Add(key string) {
 s[key] = struct{}{}
}

func (s Set) Delete(key string) {
 delete(s, key)
}

func main() {
 s := make(Set)
 s.Add("Tom")
 s.Add("Sam")
 fmt.Println(s.Has("Tom"))
 fmt.Println(s.Has("Jack"))
}
```

1. 不发送数据的信道(channel)
   使用 channel 不需要发送任何的数据，只用来通知子协程(goroutine)执行任务，或只用来控制协程并发度。

```
func worker(ch chan struct{}) {
 <-ch
 fmt.Println("do something")
 close(ch)
}

func main() {
 ch := make(chan struct{})
 go worker(ch)
 ch <- struct{}{}
}
```

1. 结构体只包含方法，不包含任何的字段

```
type Door struct{}

func (d Door) Open() {
 fmt.Println("Open the door")
}

func (d Door) Close() {
 fmt.Println("Close the door")
}
```

### 32.defer原理

```go
type _defer struct {
	siz       int32
	started   bool
	openDefer bool
	sp        uintptr
	pc        uintptr
	fn        *funcval
	_panic    *_panic
	link      *_defer
}
- `siz` 是参数和结果的内存大小；
- `sp` 和 `pc` 分别代表栈指针和调用方的程序计数器；
- `fn` 是 `defer` 关键字中传入的函数；
- `_panic` 是触发延迟调用的结构体，可能为空；
- `openDefer` 表示当前 `defer` 是否经过开放编码的优化
```

[`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 结构体是延迟调用链表上的一个元素，所有的结构体都会通过 `link` 字段串联成链表。

#### 堆上分配

#### 创建延迟调用

编译器不仅将 `defer` 关键字都转换成 [`runtime.deferproc`](https://draveness.me/golang/tree/runtime.deferproc) 函数，它还会通过以下三个步骤为所有调用 `defer` 的函数末尾插入 [`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn) 的函数调用：

1. [`cmd/compile/internal/gc.walkstmt`](https://draveness.me/golang/tree/cmd/compile/internal/gc.walkstmt) 在遇到 `ODEFER` 节点时会执行 `Curfn.Func.SetHasDefer(true)` 设置当前函数的 `hasdefer` 属性；
2. [`cmd/compile/internal/gc.buildssa`](https://draveness.me/golang/tree/cmd/compile/internal/gc.buildssa) 会执行 `s.hasdefer = fn.Func.HasDefer()` 更新 `state` 的 `hasdefer`；
3. [`cmd/compile/internal/gc.state.exit`](https://draveness.me/golang/tree/cmd/compile/internal/gc.state.exit) 会根据 `state` 的 `hasdefer` 在函数返回之前插入 [`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn) 的函数调用；

当运行时将 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 分配到堆上时，Go 语言的编译器不仅将 `defer` 转换成了 [`runtime.deferproc`](https://draveness.me/golang/tree/runtime.deferproc)，还在所有调用 `defer` 的函数结尾插入了 [`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn)。上述两个运行时函数是 `defer` 关键字运行时机制的入口，它们分别承担了不同的工作：

- [`runtime.deferproc`](https://draveness.me/golang/tree/runtime.deferproc) 负责创建新的延迟调用；
- [`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn) 负责在函数调用结束时执行所有的延迟调用；

[`runtime.deferproc`](https://draveness.me/golang/tree/runtime.deferproc) 会为 `defer` 创建一个新的 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 结构体、设置它的函数指针 `fn`、程序计数器 `pc` 和栈指针 `sp` 并将相关的参数拷贝到相邻的内存空间中

最后调用的 [`runtime.return0`](https://draveness.me/golang/tree/runtime.return0) 是唯一一个不会触发延迟调用的函数，它可以避免递归 [`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn) 的递归调用。

[`runtime.deferproc`](https://draveness.me/golang/tree/runtime.deferproc) 中 [`runtime.newdefer`](https://draveness.me/golang/tree/runtime.newdefer) 的作用是想尽办法获得 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 结构体，这里包含三种路径：

1. 从调度器的延迟调用缓存池 `sched.deferpool` 中取出结构体并将该结构体追加到当前 Goroutine 的缓存池中；
2. 从 Goroutine 的延迟调用缓存池 `pp.deferpool` 中取出结构体；
3. 通过 [`runtime.mallocgc`](https://draveness.me/golang/tree/runtime.mallocgc) 在堆上创建一个新的结构体；

无论使用哪种方式，只要获取到 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 结构体，它都会被追加到所在 Goroutine `_defer` 链表的最前面。

`defer` 关键字的插入顺序是从后向前的，而 `defer` 关键字执行是从前向后的，这也是为什么后调用的 `defer` 会优先执行。

#### 执行延迟调用

[`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn) 会从 Goroutine 的 `_defer` 链表中取出最前面的 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 并调用 [`runtime.jmpdefer`](https://draveness.me/golang/tree/runtime.jmpdefer) 传入需要执行的函数和参数，[`runtime.jmpdefer`](https://draveness.me/golang/tree/runtime.jmpdefer) 是一个用汇编语言实现的运行时函数，它的主要工作是跳转到 `defer` 所在的代码段并在执行结束之后跳转回 [`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn)。[`runtime.deferreturn`](https://draveness.me/golang/tree/runtime.deferreturn) 会多次判断当前 Goroutine 的 `_defer` 链表中是否有未执行的结构体，该函数只有在所有延迟函数都执行后才会返回。

#### defer执行机制

##### 栈上分配

在默认情况下，我们可以看到 Go 语言中 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 结构体都会在堆上分配，如果我们能够将部分结构体分配到栈上就可以节约内存分配带来的额外开销。

Go 语言团队在 1.13 中对 `defer` 关键字进行了优化，当该关键字在函数体中最多执行一次时，编译期间的 [`cmd/compile/internal/gc.state.call`](https://draveness.me/golang/tree/cmd/compile/internal/gc.state.call) 会将结构体分配到栈上并调用 [`runtime.deferprocStack`]

因为在编译期间我们已经创建了 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 结构体，所以在运行期间 [`runtime.deferprocStack`](https://draveness.me/golang/tree/runtime.deferprocStack) 只需要设置一些未在编译期间初始化的字段，就可以将栈上的 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 追加到函数的链表上。

除了分配位置的不同，栈上分配和堆上分配的 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 并没有本质的不同，而该方法可以适用于绝大多数的场景，与堆上分配的 [`runtime._defer`](https://draveness.me/golang/tree/runtime._defer) 相比，该方法可以将 `defer` 关键字的额外开销降低 ~30%。

##### 开放编码

使用代码内联优化 `defer` 关键的额外开销并引入函数数据 `funcdata` 管理 `panic` 的调用[3](https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-defer/#fn:3)，该优化可以将 `defer` 的调用开销从 1.13 版本的 ~35ns 降低至 ~6ns 左右：

然而开放编码作为一种优化 `defer` 关键字的方法，它不是在所有的场景下都会开启的，开放编码只会在满足以下的条件时启用：

1. 函数的 `defer` 数量少于或者等于 8 个；
2. 函数的 `defer` 关键字不能在循环中执行；
3. 函数的 `return` 语句与 `defer` 语句的乘积小于或者等于 15 个；



### 1.使用值为 nil 的 slice、map会发生啥

允许对值为 nil 的 slice 添加元素，但对值为 nil 的 map 添加元素，则会造成运行时 panic。

```
// map 错误示例
func main() {
    var m map[string]int
    m["one"] = 1  // error: panic: assignment to entry in nil map
    // m := make(map[string]int)// map 的正确声明，分配了实际的内存
}    

// slice 正确示例
func main() {
 var s []int
 s = append(s, 1)
}
```

### 2.访问 map 中的 key，需要注意啥

当访问 map 中不存在的 key 时，Go 则会返回元素对应数据类型的零值，比如 nil、’’ 、false 和 0，取值操作总有值返回，故不能通过取出来的值，来判断 key 是不是在 map 中。

检查 key 是否存在可以用 map 直接访问，检查返回的第二个参数即可。

```
// 错误的 key 检测方式
func main() {
 x := map[string]string{"one": "2", "two": "", "three": "3"}
 if v := x["two"]; v == "" {
  fmt.Println("key two is no entry") // 键 two 存不存在都会返回的空字符串
 }
}

// 正确示例
func main() {
 x := map[string]string{"one": "2", "two": "", "three": "3"}
 if _, ok := x["two"]; !ok {
  fmt.Println("key two is no entry")
 }
}
```

### 3.string 类型的值可以修改吗

不能，尝试使用索引遍历字符串，来更新字符串中的个别字符，是不允许的。

string 类型的值是只读的二进制 byte slice，如果真要修改字符串中的字符，将 string 转为 []byte 修改后，再转为 string 即可。

```
// 修改字符串的错误示例
func main() {
 x := "text"
 x[0] = "T"  // error: cannot assign to x[0]
 fmt.Println(x)
}


// 修改示例
func main() {
 x := "text"
 xBytes := []byte(x)
 xBytes[0] = 'T' // 注意此时的 T 是 rune 类型
 x = string(xBytes)
 fmt.Println(x) // Text
}
```

### 4.switch 中如何强制执行下一个 case 代码块

switch 语句中的 case 代码块会默认带上 break，但可以使用 fallthrough 来强制执行下一个 case 代码块。

```
func main() {
 isSpace := func(char byte) bool {
  switch char {
  case ' ': // 空格符会直接 break，返回 false // 和其他语言不一样
  // fallthrough // 返回 true
  case '\t':
   return true
  }
  return false
 }
 fmt.Println(isSpace('\t')) // true
 fmt.Println(isSpace(' ')) // false
}
```

### 5.你是如何关闭 HTTP 的响应体的

直接在处理 HTTP 响应错误的代码块中，直接关闭非 nil 的响应体；手动调用 defer 来关闭响应体。

```
// 正确示例
func main() {
 resp, err := http.Get("http://www.baidu.com")

    // 关闭 resp.Body 的正确姿势
    if resp != nil {
  defer resp.Body.Close()
 }

 checkError(err)
 defer resp.Body.Close()

 body, err := ioutil.ReadAll(resp.Body)
 checkError(err)

 fmt.Println(string(body))
}
```

### 6.你是否主动关闭过http连接，为啥要这样做

有关闭，不关闭会程序可能会消耗完 socket 描述符。有如下2种关闭方式：

- 直接设置请求变量的 Close 字段值为 true，每次请求结束后就会主动关闭连接。设置 Header 请求头部选项 Connection: close，然后服务器返回的响应头部也会有这个选项，此时 HTTP 标准库会主动断开连接

```
// 主动关闭连接
func main() {
 req, err := http.NewRequest("GET", "http://golang.org", nil)
 checkError(err)

 req.Close = true
 //req.Header.Add("Connection", "close") // 等效的关闭方式

 resp, err := http.DefaultClient.Do(req)
 if resp != nil {
  defer resp.Body.Close()
 }
 checkError(err)

 body, err := ioutil.ReadAll(resp.Body)
 checkError(err)

 fmt.Println(string(body))
}
```

你可以创建一个自定义配置的 HTTP transport 客户端，用来取消 HTTP 全局的复用连接。

```
func main() {
 tr := http.Transport{DisableKeepAlives: true}
 client := http.Client{Transport: &tr}

 resp, err := client.Get("https://golang.google.cn/")
 if resp != nil {
  defer resp.Body.Close()
 }
 checkError(err)

 fmt.Println(resp.StatusCode) // 200

 body, err := ioutil.ReadAll(resp.Body)
 checkError(err)

 fmt.Println(len(string(body)))
}
```

### 7.解析 JSON 数据时，默认将数值当做哪种类型

在 encode/decode JSON 数据时，Go 默认会将数值当做 float64 处理。

```
func main() {
     var data = []byte(`{"status": 200}`)
     var result map[string]interface{}

     if err := json.Unmarshal(data, &result); err != nil {
     log.Fatalln(err)
}
```

解析出来的 200 是 float 类型。

### 8.如何从 panic 中恢复

在一个 defer 延迟执行的函数中调用 recover ，它便能捕捉/中断 panic。

```
// 错误的 recover 调用示例
func main() {
 recover() // 什么都不会捕捉
 panic("not good") // 发生 panic，主程序退出
 recover() // 不会被执行
 println("ok")
}

// 正确的 recover 调用示例
func main() {
 defer func() {
  fmt.Println("recovered: ", recover())
 }()
 panic("not good")
}
```

### 9.简短声明的变量需要注意啥

- 简短声明的变量只能在函数内部使用
- struct 的变量字段不能使用 := 来赋值
- 不能用简短声明方式来单独为一个变量重复声明， := 左侧至少有一个新变量，才允许多变量的重复声明

### 10.range 迭代 map是有序的吗

无序的。Go 的运行时是有意打乱迭代顺序的，所以你得到的迭代结果可能不一致。但也并不总会打乱，得到连续相同的 5 个迭代结果也是可能的。

### 11.recover的执行时机

无，recover 必须在 defer 函数中运行。recover 捕获的是祖父级调用时的异常，直接调用时无效。

```
func main() {
    recover()
    panic(1)
}
```

直接 defer 调用也是无效。

```
func main() {
    defer recover()
    panic(1)
}
```

defer 调用时多层嵌套依然无效。

```
func main() {
    defer func() {
        func() { recover() }()
    }()
    panic(1)
}
```

必须在 defer 函数中直接调用才有效。

```
func main() {
    defer func() {
        recover()
    }()
    panic(1)
}
```

### 12.闭包错误引用同一个变量问题怎么处理

在每轮迭代中生成一个局部变量 i 。如果没有 i := i 这行，将会打印同一个变量。

```
func main() {
    for i := 0; i < 5; i++ {
        i := i
        defer func() {
            println(i)
        }()
    }
}
```

或者是通过函数参数传入 i 。

```
func main() {
    for i := 0; i < 5; i++ {
        defer func(i int) {
            println(i)
        }(i)
    }
}
```

### 13.在循环内部执行defer语句会发生啥

defer 在函数退出时才能执行，在 for 执行 defer 会导致资源延迟释放。

```
func main() {
    for i := 0; i < 5; i++ {
        func() {
            f, err := os.Open("/path/to/file")
            if err != nil {
                log.Fatal(err)
            }
            defer f.Close()
        }()
    }
}
```

func 是一个局部函数，在局部函数里面执行 defer 将不会有问题。

### 14.说出一个避免Goroutine泄露的措施

可以通过 context 包来避免内存泄漏。

```
func main() {
    ctx, cancel := context.WithCancel(context.Background())

    ch := func(ctx context.Context) <-chan int {
        ch := make(chan int)
        go func() {
            for i := 0; ; i++ {
                select {
                case <- ctx.Done():
                    return
                case ch <- i:
                }
            }
        } ()
        return ch
    }(ctx)

    for v := range ch {
        fmt.Println(v)
        if v == 5 {
            cancel()
            break
        }
    }
}
```

下面的 for 循环停止取数据时，就用 cancel 函数，让另一个协程停止写数据。如果下面 for 已停止读取数据，上面 for 循环还在写入，就会造成内存泄漏。

### 15.如何跳出for select 循环

通常在for循环中，使用break可以跳出循环，但是注意在go语言中，for select配合时，break 并不能跳出循环。

```
func testSelectFor2(chExit chan bool){
 EXIT:
    for  {
        select {
        case v, ok := <-chExit:
            if !ok {
                fmt.Println("close channel 2", v)
                break EXIT//goto EXIT2
            }

            fmt.Println("ch2 val =", v)
        }
    }

    //EXIT2:
    fmt.Println("exit testSelectFor2")
}
```

### 16.如何在切片中查找

go中使用 sort.searchXXX 方法，在排序好的切片中查找指定的方法，但是其返回是对应的查找元素不存在时，待插入的位置下标(元素插入在返回下标前)。

可以通过封装如下函数，达到目的。

```
func IsExist(s []string, t string) (int, bool) {
    iIndex := sort.SearchStrings(s, t)
    bExist := iIndex!=len(s) && s[iIndex]==t

    return iIndex, bExist
}
```

### 17.如何初始化带嵌套结构的结构体

go 的哲学是组合优于继承，使用 struct 嵌套即可完成组合，内嵌的结构体属性就像外层结构的属性即可，可以直接调用。

注意初始化外层结构体时，必须指定内嵌结构体名称的结构体初始化，如下看到 s1方式报错，s2 方式正确。

```
type stPeople struct {
    Gender bool
    Name string
}

type stStudent struct {
    stPeople
    Class int
}

//尝试4 嵌套结构的初始化表达式
//var s1 = stStudent{false, "JimWen", 3}
var s2 = stStudent{stPeople{false, "JimWen"}, 3}
fmt.Println(s2.Gender, s2.Name, s2.Class)
```

### 19.new和make的区别

new 的作用是初始化一个指向类型的指针 (*T) 。new 函数是内建函数，函数定义：func new(Type) *Type。使用 new 函数来分配空间。传递给 new 函数的是一个类型，不是一个值。返回值是指向这个新分配的零值的指针。

make 的作用是为 slice，map 或 chan 初始化并返回引用 (T)。make 函数是内建函数，函数定义：func make(Type, size IntegerType) Type；第一个参数是一个类型，第二个参数是长度；返回值是一个类型。

make(T, args) 函数的目的与 new(T) 不同。它仅仅用于创建 Slice, Map 和 Channel，并且返回类型是 T（不是T*）的一个初始化的（不是零值）的实例。

### 20.Printf()、Sprintf()、Fprintf()函数的区别用法是什么

都是把格式好的字符串输出，只是输出的目标不一样。

Printf()，是把格式字符串输出到标准输出（一般是屏幕，可以重定向）。Printf() 是和标准输出文件 (stdout) 关联的，Fprintf 则没有这个限制。
Sprintf()，是把格式字符串输出到指定字符串中，所以参数比printf多一个char*。那就是目标字符串地址。

Fprintf()，是把格式字符串输出到指定文件设备中，所以参数比 printf 多一个文件指针 FILE*。主要用于文件操作。Fprintf() 是格式化输出到一个stream，通常是到文件。

### 21.说说go语言中的for循环

for 循环支持 continue 和 break 来控制循环，但是它提供了一个更高级的break，可以选择中断哪一个循环 for 循环不支持以逗号为间隔的多个赋值语句，必须使用平行赋值的方式来初始化多个变量。

### 22.Array 类型的值作为函数参数

在 C/C++ 中，数组（名）是指针。将数组作为参数传进函数时，相当于传递了数组内存地址的引用，在函数内部会改变该数组的值。

在 Go 中，数组是值。作为参数传进函数时，传递的是数组的原始值拷贝，此时在函数内部是无法更新该数组的。

```
// 数组使用值拷贝传参
func main() {
 x := [3]int{1,2,3}

 func(arr [3]int) {
  arr[0] = 7
  fmt.Println(arr) // [7 2 3]
 }(x)
 fmt.Println(x)   // [1 2 3] // 并不是你以为的 [7 2 3]
}
```

想改变数组，直接传递指向这个数组的指针类型。

```
// 传址会修改原数据
func main() {
 x := [3]int{1,2,3}

 func(arr *[3]int) {
  (*arr)[0] = 7 
  fmt.Println(arr) // &[7 2 3]
 }(&x)
 fmt.Println(x) // [7 2 3]
}
```

直接使用 slice：即使函数内部得到的是 slice 的值拷贝，但依旧会更新 slice 的原始数据（底层 array）

```
// 错误示例
func main() {
 x := []string{"a", "b", "c"}
 for v := range x {
  fmt.Println(v) // 1 2 3
 }
}


// 正确示例
func main() {
 x := []string{"a", "b", "c"}
 for _, v := range x { // 使用 _ 丢弃索引
  fmt.Println(v)
 }
}
```

说。go语言中的for循

### 23.说说go语言中的switch语句

单个 case 中，可以出现多个结果选项。只有在 case 中明确添加 fallthrough关键字，才会继续执行紧跟的下一个 case。

### 24.说说go语言中有没有隐藏的this指针

方法施加的对象显式传递，没有被隐藏起来。

golang 的面向对象表达更直观，对于面向过程只是换了一种语法形式来表达方法施加的对象不需要非得是指针，也不用非得叫 this。

### 25.go语言中的引用类型包含哪些

数组切片、字典(map)、通道（channel）、接口（interface）。

### 26.go语言中指针运算有哪些

可以通过“&”取指针的地址；可以通过“*”取指针指向的数据。

26.说说go语言的main函数
main 函数不能带参数；main 函数不能定义返回值。main 函数所在的包必须为 main 包；main 函数中可以使用 flag 包来获取和解析命令行参数。

### 27.go语言触发异常的场景有哪些

- 空指针解析
- 下标越界
- 除数为0
- 调用 panic 函数

### 28.说说go语言的beego框架

- beego 是一个 golang 实现的轻量级HTTP框架
- beego 可以通过注释路由、正则路由等多种方式完成 url 路由注入
- 可以使用 bee new 工具生成空工程，然后使用 bee run 命令自动热编译

### 29.说说go语言的goconvey框架

- goconvey 是一个支持 golang 的单元测试框架
- goconvey 能够自动监控文件修改并启动测试，并可以将测试结果实时输出到web界面
- goconvey 提供了丰富的断言简化测试用例的编写

### 30.GoStub的作用是什么

- GoStub 可以对全局变量打桩
- GoStub 可以对函数打桩
- GoStub 不可以对类的成员方法打桩
- GoStub 可以打动态桩，比如对一个函数打桩后，多次调用该函数会有不同的行为

### 31.go语言编程的好处是什么

- 编译和运行都很快。
- 在语言层级支持并行操作。
- 有垃圾处理器。
- 内置字符串和 maps。
- 函数是 go 语言的最基本编程单位。

### 32.说说go语言的select机制

- select 机制用来处理异步 IO 问题
- select 机制最大的一条限制就是每个 case 语句里必须是一个 IO 操作
- golang 在语言级别支持 select 关键字

### 33.解释一下go语言中的静态类型声明

静态类型声明是告诉编译器不需要太多的关注这个变量的细节。

静态变量的声明，只是针对于编译的时候, 在连接程序的时候，编译器还要对这个变量进行实际的声明。

### 34.go的接口是什么

- 在 go 语言中，interface 也就是接口，被用来指定一个对象。接口具有下面的要素:
- 一系列的方法
- 具体应用中并用来表示某个数据类型
- 在 go 中使用 interface 来实现多态

### 35.Go语言里面的类型断言是怎么回事

类型断言是用来从一个接口里面读取数值给一个具体的类型变量。类型转换是指转换两个不相同的数据类型。

### 36.go语言中局部变量和全局变量的缺省值是什么

全局变量的缺省值是与这个类型相关的零值。

### 37.go语言编程的好处是什么

- 编译和运行都很快。
- 在语言层级支持并行操作。
- 有垃圾处理器。
- 内置字符串和 maps。
- 函数是 go 语言的最基本编程单位。

### 38.解释一下go语言中的静态类型声明

静态类型声明是告诉编译器不需要太多的关注这个变量的细节。
静态变量的声明，只是针对于编译的时候, 在连接程序的时候，编译器还要对这个变量进行实际的声明。

### 39.模块化编程是怎么回事

模块化编程是指把一个大的程序分解成几个小的程序。这么做的目的是为了减少程序的复杂度，易于维护，并且达到最高的效率。

码字不易，请不吝点赞，随手关注，更多精彩，自动送达。

### 40.Golang的方法有什么特别之处

函数的定义声明没有接收者。
方法的声明和函数类似，他们的区别是：方法在定义的时候，会在func和方法名之间增加一个参数，这个参数就是接收者，这样我们定义的这个方法就和接收者绑定在了一起，称之为这个接收者的方法。
Go语言里有两种类型的接收者：值接收者和指针接收者。使用值类型接收者定义的方法，在调用的时候，使用的其实是值接收者的一个副本，所以对该值的任何操作，不会影响原来的类型变量。——-相当于形式参数。

如果我们使用一个指针作为接收者，那么就会其作用了，因为指针接收者传递的是一个指向原值指针的副本，指针的副本，指向的还是原来类型的值，所以修改时，同时也会影响原来类型变量的值。

### 41.Golang可变参数

函数方法的参数，可以是任意多个，这种我们称之为可以变参数，比如我们常用的fmt.Println()这类函数，可以接收一个可变的参数。可以变参数，可以是任意多个。我们自己也可以定义可以变参数，可变参数的定义，在类型前加上省略号…即可。

```
func main() {
 print("1","2","3")
}


func print (a ...interface{}){
 for _,v:=range a{
  fmt.Print(v)
 }
 fmt.Println()
}
```

例子中我们自己定义了一个接受可变参数的函数，效果和fmt.Println()一样。可变参数本质上是一个数组，所以我们向使用数组一样使用它，比如例子中的 for range 循环。



### 45. JSON 标准库对 nil slice 和 空 slice 的处理是一致的吗

首先 JSON 标准库对 nil slice 和 空 slice 的处理是不一致。

通常错误的用法，会报数组越界的错误，因为只是声明了slice，却没有给实例化的对象。

```
var slice []int
slice[1] = 0
```

此时slice的值是nil，这种情况可以用于需要返回slice的函数，当函数出现异常的时候，保证函数依然会有nil的返回值。

empty slice 是指slice不为nil，但是slice没有值，slice的底层的空间是空的，此时的定义如下：

```
slice := make([]int,0）
slice := []int{}
```

当我们查询或者处理一个空的列表的时候，这非常有用，它会告诉我们返回的是一个列表，但是列表内没有任何值。总之，nil slice 和 empty slice是不同的东西,需要我们加以区分的。

### 46.Golang的内存模型，为什么小对象多了会造成gc压力

通常小对象过多会导致 GC 三色法消耗过多的GPU。优化思路是，减少对象分配。

### 47.Data Race问题怎么解决？能不能不加锁解决这个问题

同步访问共享数据是处理数据竞争的一种有效的方法。

golang在 1.1 之后引入了竞争检测机制，可以使用 go run -race 或者 go build -race来进行静态检测。其在内部的实现是,开启多个协程执行同一个命令， 并且记录下每个变量的状态。

竞争检测器基于C/C++的ThreadSanitizer 运行时库，该库在Google内部代码基地和Chromium找到许多错误。这个技术在2012年九月集成到Go中，从那时开始，它已经在标准库中检测到42个竞争条件。现在，它已经是我们持续构建过程的一部分，当竞争条件出现时，它会继续捕捉到这些错误。

竞争检测器已经完全集成到Go工具链中，仅仅添加-race标志到命令行就使用了检测器。

```
$ go test -race mypkg    // 测试包
$ go run -race mysrc.go  // 编译和运行程序 $ go build -race mycmd 
// 构建程序 $ go install -race mypkg // 安装程序
```

要想解决数据竞争的问题可以使用互斥锁sync.Mutex,解决数据竞争(Data race),也可以使用管道解决,使用管道的效率要比互斥锁高。

### 48.在 range 迭代 slice 时，你怎么修改值的

在 range 迭代中，得到的值其实是元素的一份值拷贝，更新拷贝并不会更改原来的元素，即是拷贝的地址并不是原有元素的地址。

```
func main() {
 data := []int{1, 2, 3}
 for _, v := range data {
  v *= 10  // data 中原有元素是不会被修改的
 }
 fmt.Println("data: ", data) // data:  [1 2 3]
}
```

如果要修改原有元素的值，应该使用索引直接访问。

```
func main() {
 data := []int{1, 2, 3}
 for i, v := range data {
  data[i] = v * 10 
 }
 fmt.Println("data: ", data) // data:  [10 20 30]
}
```

如果你的集合保存的是指向值的指针，需稍作修改。依旧需要使用索引访问元素，不过可以使用 range 出来的元素直接更新原有值。

```
func main() {
 data := []*struct{ num int }{{1}, {2}, {3},}
 for _, v := range data {
  v.num *= 10 // 直接使用指针更新
 }
 fmt.Println(data[0], data[1], data[2]) // &{10} &{20} &{30}
}
```

### 49.nil interface 和 nil interface 的区别

虽然 interface 看起来像指针类型，但它不是。interface 类型的变量只有在类型和值均为 nil 时才为 nil如果你的 interface 变量的值是跟随其他变量变化的，与 nil 比较相等时小心。如果你的函数返回值类型是 interface，更要小心这个坑：

```
func main() {
   var data *byte
   var in interface{}

   fmt.Println(data, data == nil) // <nil> true
   fmt.Println(in, in == nil) // <nil> true

   in = data
   fmt.Println(in, in == nil) // <nil> false // data 值为 nil，但 in 值不为 nil
}

// 正确示例
func main() {
  doIt := func(arg int) interface{} {
  var result *struct{} = nil

  if arg > 0 {
  result = &struct{}{}
  } else {
  return nil // 明确指明返回 nil
  }

  return result
  }


  if res := doIt(-1); res != nil {
  fmt.Println("Good result: ", res)
  } else {
  fmt.Println("Bad result: ", res) // Bad result: <nil>
  }
}
```

### 50.select可以用于什么

常用语gorotine的完美退出。

golang 的 select 就是监听 IO 操作，当 IO 操作发生时，触发相应的动作每个case语句里必须是一个IO操作，确切的说，应该是一个面向channel的IO操作。

### 51.go map 查找

Go 语言中 map 采用的是哈希查找表，由一个 key 通过哈希函数得到哈希值，64位系统中就生成一个 64bit 的哈希值，由这个哈希值将 key 对应到不同的桶（bucket）中，当有多个哈希映射到相同的的桶中时，使用链表解决哈希冲突。key 经过 hash 后共 64 位，根据 hmap 中 B 的值，计算它到底要落在哪个桶时，桶的数量为 2^B，如 B=5，那么用 64 位最后 5 位表示第几号桶，在用 hash 值的高 8 位确定在 bucket 中的存储位置，当前 bmap 中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。 如果两个不同的 key 落在的同一个桶上，hash 冲突使用链表法接近，遍历 bucket 中的 key 如果当前处于 map 进行了扩容，处于数据搬移状态，则优先从 oldbuckets 查找。

### 52.go与python比较

1、范例

Python是一种基于面向对象编程的多范式，命令式和函数式编程语言。它坚持这样一种观点，即如果一种语言在某些情境中表现出某种特定的方式，理想情况下它应该在所有情境中都有相似的作用。但它又不是纯粹的OOP语言，不支持强封装，这是OOP的主要原则之一。Go是一种基于并发编程范式的过程编程语言，它与C具有表面相似性。实际上，Go更像是C的更新版本。

2、类型化

Python是动态类型语言，而Go是一种静态类型语言，实际上有助于在编译时捕获错误，这可以进一步减少生产后期的严重错误。

3、并发

Python没有提供内置的并发机制，而Go有内置的并发机制。

4、安全性

Python强类型语言，经过编译增加了一层安全性。Go具有分配给每个变量的类型，提供了安全性。如果发生任何错误，用户需要自己运行整个代码。

5、速度：

Go的速度远远超过Python。

6、用法

Python更多地用于Web应用程序，非常适合解决数据科学问题。Go更多地围绕系统编程，即Go更像是一种系统语言。

7、管理内存

Go允许程序员在很大程度上管理内存。而，Python中的内存管理完全自动化并由Python VM管理;它不允许程序员对内存管理负责。

8、库

与Go相比，Python提供的库数量要大得多。然而，Go仍然是新的，并且还没有取得很大进展。

9、语法

Python的语法使用缩进来指示代码块。Go的语法基于打开和关闭括号。

10、详细程度

为了获得相同的功能，Golang代码通常需要编写比Python代码更多的字符。

Go语言和Python学哪个好?

Python 可以很好地集成到企业级应用中，可用于机器语言和 AI 应用。Go 语言的特点表明它具备轻量级线程实现(Goroutine)、智能标准库、强大的内置安全性，且可使用最简语法进行编程。Go 在大部分案例中领先，被认为是 Python 的有效替代方案。开发者在选择编程语言时，应考虑开发项目的性质和规模，以及所需的技能组合。

放下个人偏见和喜好，从优点和功能的角度来评价两种语言。不管选择了哪种语言，Go 和 Python 都在持续演进。尽管在大多数情况下 Golang 可能是更好的选择，但Python语言也是不断更新迭代的。

### 53.什么叫静态语言和动态语言

动态类型语言：是指在运行期间才去做数据类型检查的语言。在用动态语言编程时，不用给变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。

静态类型语言：与动态类型语言刚好相反，它的数据类型检查发生在在编译阶段，也就是说在写程序时要声明变量的数据类型。C/C++、C#、JAVA都是静态类型语言的典型代表。

### 54.Golang 协程池的使用

协程池的实现是有入口队列 entryChannel 和任务队列 jobChannel 以及具体做任务的协程 worker 组成。

```go
package main
import (
	"fmt"
	"sync"
	"time"
)
//golang协程池 使用
/* 有关Task任务相关定义及操作 */
//定义任务Task类型,每一个任务Task都可以抽象成一个函数
type Task struct {
	fu func() error //一个无参的函数类型
}
//通过NewTask来创建一个Task
func NewTask(f func() error) *Task {
	t := Task{
		fu: f,
	}
	return &t
}
//执行Task任务的方法
func (t *Task) Execute() {
	_ = t.fu() //调用任务所绑定的函数
}
/* 有关协程池的定义及操作 */
//定义池类型
type Pool struct {
	//对外接收Task的入口
	EntryChannel chan *Task
	//协程池最大worker数量,限定Goroutine的个数
	worker_num int
	//协程池内部的任务就绪队列
	JobsChannel chan *Task
}

//创建一个协程池
func NewPool(cap int) *Pool {
	p := Pool{
		EntryChannel: make(chan *Task),
		worker_num:   cap,
		JobsChannel:  make(chan *Task),
	}
	return &p
}
//协程池创建一个worker并且开始工作
func (p *Pool) worker(work_ID int,wg *sync.WaitGroup) {
	//worker不断的从JobsChannel内部任务队列中拿任务
	for task := range p.JobsChannel {
		//如果拿到任务,则执行task任务
		task.Execute()
		fmt.Println("worker ID ", work_ID, " 执行完毕任务")

	}
	wg.Done()
}
//让协程池Pool开始工作
func (p *Pool) Run() {
	//1,首先根据协程池的worker数量限定,开启固定数量的Worker,
	//  每一个Worker用一个Goroutine承载
	wg := sync.WaitGroup{}
	wg.Add(p.worker_num)
	for i := 0; i < p.worker_num; i++ {

		go p.worker(i,&wg)
	}
	//2, 从EntryChannel协程池入口取外界传递过来的任务
	//   并且将任务送进JobsChannel中
	for task := range p.EntryChannel {
		p.JobsChannel <- task
	}
	//3, 执行完毕需要关闭JobsChannel
	close(p.JobsChannel)
	//4, 执行完毕需要关闭EntryChannel
	close(p.EntryChannel)
	wg.Wait()
}
//主函数
func main() {
	//创建一个Task
	t := NewTask(func() error {
		fmt.Println(time.Now())
		return nil
	})
	//创建一个协程池,最大开启3个协程worker
	p := NewPool(3)
	//开一个协程 不断的向 Pool 输送打印一条时间的task任务
	go func() {
		for {
			p.EntryChannel <- t
		}
	}()
	//启动协程池p

	p.Run()

}
```

### 切片原理

#### Slice数据结构

源码包中`src/runtime/slice.go:slice`定义了Slice的数据结构：

```go
type slice struct {
    array unsafe.Pointer
    len   int
    cap   int
}
```

从数据结构看Slice很清晰, array指针指向底层数组，len表示切片长度，cap表示底层数组容量。

#### 切片扩容

使用append向Slice追加元素时，如果Slice空间不足，将会触发Slice扩容，扩容实际上重新一配一块更大的内存，将原Slice数据拷贝进新Slice，然后返回新Slice，扩容后再将数据追加进去。

扩容操作只关心容量，会把原Slice数据拷贝到新Slice，追加数据由append在扩容结束后完成。上图可见，扩容后新的Slice长度仍然是5，但容量由5提升到了10，原Slice的数据也都拷贝到了新Slice指向的数组中。

扩容容量的选择遵循以下规则：

- 如果原Slice容量小于1024，则新Slice容量将扩大为原来的2倍；
- 如果原Slice容量大于等于1024，则新Slice容量将扩大为原来的1.25倍；

使用append()向Slice添加一个元素的实现步骤如下：

1. 假如Slice容量够用，则将新元素追加进去，Slice.len++，返回原Slice
2. 原Slice容量不够，则将Slice先扩容，扩容后得到新Slice
3. 将新元素追加进新Slice，Slice.len++，返回新的Slice。

如果新容量两倍小于需求cap，则新容量直接为需求容量

##### 扩容注意点

情况一：原数组还有容量可以扩容（实际容量没有填充完），这种情况下，扩容以后的数组还是指向原来的数组，对一个切片的操作可能影响多个指针指向相同地址的Slice。

情况二：原来数组的容量已经达到了最大值，再想扩容， Go 默认会先开一片内存区域，把原来的值拷贝过来，然后再执行 append() 操作。这种情况丝毫不影响原数组。

#### 切片的内存对齐策略

```
func growslice(et *_type, old slice, cap int) slice {
    // ……
    newcap := old.cap
	doublecap := newcap + newcap
	if cap > doublecap {
		newcap = cap
	} else {
		if old.len < 1024 {
			newcap = doublecap
		} else {
			for newcap < cap {
				newcap += newcap / 4
			}
		}
	}
	// ……
	
	capmem = roundupsize(uintptr(newcap) * ptrSize)
	newcap = int(capmem / ptrSize)
}
```



```golang
package main

import "fmt"

func main() {
	s := []int{1,2}
	s = append(s,4,5,6)
	fmt.Printf("len=%d, cap=%d",len(s),cap(s))
}
```

例子中 `s` 原来只有 2 个元素，`len` 和 `cap` 都为 2，`append` 了三个元素后，长度变为 5，容量最小要变成 5，即调用 `growslice` 函数时，传入的第三个参数应该为 5。即 `cap=5`。而一方面，`doublecap` 是原 `slice`容量的 2 倍，等于 4。满足第一个 `if` 条件，所以 `newcap` 变成了 5。

接着调用了 `roundupsize` 函数，传入 40。（代码中ptrSize是指一个指针的大小，在64位机上是8）

```golang
func roundupsize(size uintptr) uintptr {
	if size < _MaxSmallSize {
		if size <= smallSizeMax-8 {
			return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]])
		} else {
			//……
		}
	}
    //……
}

const _MaxSmallSize = 32768
const smallSizeMax = 1024
const smallSizeDiv = 8
```

很明显，我们最终将返回这个式子的结果：

| `1 ` | `class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]] ` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

这是 `Go` 源码中有关内存分配的两个 `slice`。`class_to_size`通过 `spanClass`获取 `span`划分的 `object`大小。而 `size_to_class8` 表示通过 `size` 获取它的 `spanClass`。

| `1 2 3 ` | `var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31} var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} ` |
| -------- | ------------------------------------------------------------ |
|          |                                                              |

我们传进去的 `size` 等于 40。所以 `(size+smallSizeDiv-1)/smallSizeDiv = 5`；获取 `size_to_class8` 数组中索引为 `5` 的元素为 `4`；获取 `class_to_size` 中索引为 `4` 的元素为 `48`。

最终，新的 slice 的容量为 `6`：

| `1 ` | `newcap = int(capmem / ptrSize) // 6` |
| ---- | ------------------------------------- |
|      |                                       |

#### 切片和数组的区别

数组是具有固定长度，且拥有零个或者多个，相同数据类型元素的序列。数组的长度是数组类型的一部分，所以[3]int 和 [4]int 是两种不同的数组类型。数组需要指定大小，不指定也会根据初始化的自动推算出大小，不可改变；数组是值传递。数组是内置类型，是一组同类型数据的集合，它是值类型，通过从0开始的下标索引访问元素值。在初始化后长度是固定的，无法修改其长度。

当作为方法的参数传入时将复制一份数组而不是引用同一指针。数组的长度也是其类型的一部分，通过内置函数len(array)获取其长度。数组定义：

```
var array [10]int

var array =[5]int{1,2,3,4,5}
```

切片表示一个拥有相同类型元素的可变长度的序列。切片是一种轻量级的数据结构，它有三个属性：指针、长度和容量。切片不需要指定大小；切片是地址传递；切片可以通过数组来初始化，也可以通过内置函数make()初始化 。初始化时len=cap,在追加元素时如果容量cap不足时将按len的2倍扩容。切片定义：

```
var slice []type = make([]type, len)
```

#### 切片作为函数参数

不管传的是 slice 还是 slice 指针，如果改变了 slice 底层数组的数据，会反应到实参 slice 的底层数据。为什么能改变底层数组的数据？很好理解：底层数据在 slice 结构体里是一个指针，尽管 slice 结构体自身不会被改变，也就是说底层数据地址不会被改变。 但是通过指向底层数据的指针，可以改变切片的底层数据，没有问题。

通过 slice 的 array 字段就可以拿到数组的地址。在代码里，是直接通过类似 `s[i]=10` 这种操作改变 slice 底层数组元素值。

另外，值得注意的是，Go 语言的函数参数传递，只有值传递，没有引用传递。



### 什么是反射

Go 语言提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。它的本质是程序在运行期探知对象的类型信息和内存结构。

#### 什么情况下需要使用反射

使用反射的常见场景有以下两种：

1. 不能明确接口调用哪个函数，需要根据传入的参数在运行时决定。
2. 不能明确传入函数的参数类型，需要在运行时处理任意对象。

#### 反射缺点

1. 与反射相关的代码，经常是难以阅读的。在软件工程中，代码可读性也是一个非常重要的指标。
2. Go 语言作为一门静态语言，编码过程中，编译器能提前发现一些类型错误，但是对于反射代码是无能为力的。所以包含反射相关的代码，很可能会运行很久，才会出错，这时候经常是直接 panic，可能会造成严重的后果。
3. 反射对性能影响还是比较大的，比正常代码运行速度慢一到两个数量级。所以，对于一个项目中处于运行效率关键位置的代码，尽量避免使用反射特性。

#### Go 语言中反射的应用

IDE 中的代码自动补全功能、对象序列化（encoding/json）、fmt 相关函数的实现、ORM（全称是：Object Relational Mapping，对象关系映射）……

#### 如何比较两个对象完全相同

`DeepEqual` 函数的参数是两个 `interface`，实际上也就是可以输入任意类型，输出 true 或者 flase 表示输入的两个变量是否是“深度”相等。

比如 func 类型是不可比较的类型，只有在两个 func 类型都是 nil 的情况下，才是“深度”相等；float 类型，由于精度的原因，也是不能使用 == 比较的；包含 func 类型或者 float 类型的 struct， interface， array 等

```golang
func DeepEqual(x, y interface{}) bool {
	if x == nil || y == nil {
		return x == y
	}
	v1 := ValueOf(x)
	v2 := ValueOf(y)
	if v1.Type() != v2.Type() {
		return false
	}
	return deepValueEqual(v1, v2, make(map[visit]bool), 0)
}
```

首先查看两者是否有一个是 nil 的情况，这种情况下，只有两者都是 nil，函数才会返回 true

接着，使用反射，获取x，y 的反射对象，并且立即比较两者的类型，根据前面的内容，这里实际上是动态类型，如果类型不同，直接返回 false。

最后，最核心的内容在子函数 `deepValueEqual` 中。

代码比较长，思路却比较简单清晰：核心是一个 switch 语句，识别输入参数的不同类型，分别递归调用 deepValueEqual 函数，一直递归到最基本的数据类型，比较 int，string 等可以直接得出 true 或者 false，再一层层地返回，最终得到“深度”相等的比较结果。

#### 反射的基本函数

reflect 包里定义了一个接口和一个结构体，即 `reflect.Type` 和 `reflect.Value`，它们提供很多函数来获取存储在接口里的类型信息。

`reflect.Type` 主要提供关于类型相关的信息，所以它和 `_type` 关联比较紧密；`reflect.Value` 则结合 `_type` 和 `data` 两者，因此程序员可以获取甚至改变类型的值。

reflect 包中提供了两个基础的关于反射的函数来获取上述的接口和结构体：

```golang
func TypeOf(i interface{}) Type 
func ValueOf(i interface{}) Value
```

`TypeOf` 函数用来提取一个接口中值的类型信息。由于它的输入参数是一个空的 `interface{}`，调用此函数时，实参会先被转化为 `interface{}`类型。这样，实参的类型信息、方法集、值信息都存储到 `interface{}` 变量里了。

```golang
func TypeOf(i interface{}) Type {
	eface := *(*emptyInterface)(unsafe.Pointer(&i))
	return toType(eface.typ)
}
```

讲完了 `TypeOf` 函数，再来看一下 `ValueOf` 函数。返回值 `reflect.Value` 表示 `interface{}` 里存储的实际变量，它能提供实际变量的各种信息。相关的方法常常是需要结合类型信息和值信息。例如，如果要提取一个结构体的字段信息，那就需要用到 _type (具体到这里是指 structType) 类型持有的关于结构体的字段信息、偏移信息，以及 `*data` 所指向的内容 —— 结构体的实际值。

```golang
func ValueOf(i interface{}) Value {
	if i == nil {
		return Value{}
	}
	
   // ……
	return unpackEface(i)
}

// 分解 eface
func unpackEface(i interface{}) Value {
	e := (*emptyInterface)(unsafe.Pointer(&i))

	t := e.typ
	if t == nil {
		return Value{}
	}
	
	f := flag(t.Kind())
	if ifaceIndir(t) {
		f |= flagIndir
	}
	return Value{t, e.word, f}
}
```

将先将 `i` 转换成 `*emptyInterface` 类型， 再将它的 `typ` 字段和 `word` 字段以及一个标志位字段组装成一个 `Value` 结构体，而这就是 `ValueOf` 函数的返回值，它包含类型结构体指针、真实数据的地址、标志位。

#### 反射的三大定律

第一条是最基本的：反射是一种检测存储在 `interface` 中的类型和值机制。这可以通过 `TypeOf` 函数和 `ValueOf` 函数得到。

第二条实际上和第一条是相反的机制，它将 `ValueOf` 的返回值通过 `Interface()` 函数反向转变成 `interface` 变量。

前两条就是说 `接口型变量` 和 `反射类型对象` 可以相互转化，反射类型对象实际上就是指的前面说的 `reflect.Type` 和 `reflect.Value`。

第三条不太好懂：如果需要操作一个反射变量，那么它必须是可设置的。反射变量可设置的本质是它存储了原变量本身，这样对反射变量的操作，就会反映到原变量本身；反之，如果反射变量不能代表原变量，那么操作了反射变量，不会对原变量产生任何影响，这会给使用者带来疑惑。所以第二种情况在语言层面是不被允许的。

如果想要操作原变量，反射变量 `Value` 必须要 hold 住原变量的地址才行。

### Go指针和unsafe.Pointer有什么区别

Go 的指针不能进行数学运算

不同类型的指针不能相互转换

不同类型的指针不能使用 == 或 != 比较

不同类型的指针变量不能相互赋值

unsafe 包提供了 2 点重要的能力：

> 1. 任何类型的指针和 unsafe.Pointer 可以相互转换。
> 2. uintptr 类型和 unsafe.Pointer 可以相互转换。

pointer 不能直接进行数学运算，但可以把它转换成 uintptr，对 uintptr 类型进行数学运算，再转换成 pointer 类型。
### go交替打印100以内奇偶数
```
package main
 
import (
	"fmt"
	"time"
)
 
func main() {
	c := make(chan int)
	go func() {
		for i := 1; i < 101; i++ {
			c <- 1
			//奇数
			if i%2 == 1 {
				fmt.Println("线程1打印:",i)
			}
		}
	}()
	go func() {
		for i := 1; i < 101; i++ {
			<- c
			//偶数
			if i%2 == 0 {
				fmt.Println("线程2打印:",i)
			}
		}
	}()
	time.Sleep(3 * time.Second)
}
```
### golang互斥锁的两种实现
#### 1.用Mutex实现
```
package main
import (
    "fmt"
    "sync"
)
var num int
var mtx sync.Mutex
var wg sync.WaitGroup
func add() {
    mtx.Lock()
    defer mtx.Unlock()
    defer wg.Done()
    num += 1
}
func main() {
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go add()
    }
    wg.Wait()
    fmt.Println("num:", num)
}
```
#### 2.使用chan实现
```
package main
import (
    "fmt"
    "sync"
)
var num int
func add(h chan int, wg *sync.WaitGroup) {
    defer wg.Done()
    h <- 1
    num += 1
    <-h
}
func main() {
    ch := make(chan int, 1)
    wg := &sync.WaitGroup{}
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go add(ch, wg)
    }
    wg.Wait()
    fmt.Println("num:", num)
}
```
### net/http使用包执行流程

首先调用Http.HandleFunc注册路由 按顺序做了几件事:
1 调用了DefaultServeMux的HandleFunc 

2 调用了DefaultServeMux的Handle

3 往DefaultServeMux的map[string]muxEntry中增加对应的handler和路由规则

其次调用http.ListenAndServe(“:9090”, nil)
 按顺序做了几件事情:

1 实例化Server

2 调用Server的ListenAndServe()

3 调用net.Listen(“tcp”, addr)监听端口

4 启动一个for循环，在循环体中Accept请求

5 对每个请求实例化一个Conn，并且开启一个goroutine为这个请求进行服务go c.serve()

6 读取每个请求的内容w, err := c.readRequest()
 7 判断handler路由器是否为空，如果没有设置handler(这个例子就没有设置handler)，

handler就设置为DefaultServeMux
 8 调用handler的ServeHttp
 9 在这个例子中，下面就进入到DefaultServeMux.ServeHttp
 10 根据request选择handler，并且进入到这个handler的ServeHTTP

11 选择handler:
 A 判断是否有路由能满足这个request(循环遍历ServeMux的muxEntry) 

B 如果有路由满足，调用这个路由handler的ServeHTTP
 C 如果没有路由满足，调用NotFoundHandler的ServeHTTP

### gogin框架

如果不是下面的问题就点开这个https://blog.csdn.net/pythonstrat/article/details/121423122

#### Gogin处理http请求流程

找到对应实现接口的方法： ServeHTTP：

	// ServeHTTP conforms to the http.Handler interface.
	func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) {
		// SYNC Pool对象池的概念： 减少内存申请，并 类型断言，转换为 Context类型指针。
		c := engine.pool.Get().(*Context)
		// 拿到对象后，下面三步才进行对象的初始化。
		c.writermem.reset(w)
		c.Request = req
		//因为是结构体并且sync.pool机制不会主动重置`Context`，所以手动重置`Context`
		c.reset()
		// 关键一步，调用handleHTTPRequest函数，处理请求。
		engine.handleHTTPRequest(c)
	
		engine.pool.Put(c)
	}

关键的一步就是处理http请求的函数： handleHTTPRequest ，传递进去初始化好的上下文。

```
func (engine *Engine) handleHTTPRequest(c *Context) {
	// 1. 获取相关数据 和 设置
	httpMethod := c.Request.Method//获取请求方法
	rPath := c.Request.URL.Path//获取请求路径
	unescape := false
	if engine.UseRawPath && len(c.Request.URL.RawPath) > 0 {
		rPath = c.Request.URL.RawPath
		unescape = engine.UnescapePathValues
	}

	if engine.RemoveExtraSlash {
		rPath = cleanPath(rPath)
	}

	// Find root of the tree for the given HTTP method
	// 找到路由树
	// 执行请求对应的函数，写入Response
	t := engine.trees
	for i, tl := 0, len(t); i < tl; i++ {
		if t[i].method != httpMethod {
			continue
		}
		root := t[i].root
		// Find route in tree
		//通过请求方法和路由找到相对应的树节点,获取储存的[]HandlerFunc列表,通过调用c.Next()处理请求
		value := root.getValue(rPath, c.params, unescape)//找到路径对应树
		if value.params != nil {
			c.Params = *value.params
		}
		if value.handlers != nil {
			c.handlers = value.handlers//处理函数
			c.fullPath = value.fullPath//绝对路径
			c.Next()
			c.writermem.WriteHeaderNow()
			return
		}
		if httpMethod != "CONNECT" && rPath != "/" {
			if value.tsr && engine.RedirectTrailingSlash {
				redirectTrailingSlash(c)
				return
			}
			if engine.RedirectFixedPath && redirectFixedPath(c, root, engine.RedirectFixedPath) {
				return
			}
		}
		break
	}

	if engine.HandleMethodNotAllowed {
		for _, tree := range engine.trees {
			if tree.method == httpMethod {
				continue
			}
			if value := tree.root.getValue(rPath, nil, unescape); value.handlers != nil {
				c.handlers = engine.allNoMethod
				serveError(c, http.StatusMethodNotAllowed, default405Body)
				return
			}
		}
	}
	c.handlers = engine.allNoRoute
	serveError(c, http.StatusNotFound, default404Body)
}
//这里挺巧妙的,通过不停的移动下标递归,最后完成处理返回结果
func (c *Context) Next() {
	c.index++
	for c.index < int8(len(c.handlers)) {
		c.handlers[c.index](c)
		c.index++
	}
}

```

（1） 首先获得 请求方法等数据，信息，进行相关操作。
（2）获取 gin.trees, 路由方法树。

对应的是 Engine里面的 trees methodTrees 类型。 而methodTrees 类型是这样定义的： type methodTrees []methodTree

methodTree 是这样定义的：

```
//  记录当前的路由字符 和 对应的 radix或前缀树的根节点！
type methodTree struct {
	method string
	root   *node
}
```

**(3)** 遍历找到对应方法，gin中是采用slice实现的，并没有使用map结构！`

（4） 通过不停的移动下标递归,最后完成处理返回结果



### gohttprouter

httprouter和众多衍生router使用的数据结构被称为压缩字典树（Radix Tree）。读者可能没有接触过压缩字典树，但对字典树（Trie Tree）应该有所耳闻

<img src="https://www.topgoer.cn/uploads/advancedgoprogramming/images/ch6-02-trie.png" alt="trie tree" style="zoom:50%;" />

字典树常用来进行字符串检索，例如用给定的字符串序列建立字典树。对于目标字符串，只要从根节点开始深度优先搜索，即可判断出该字符串是否曾经出现过，时间复杂度为`O(n)`，n可以认为是目标字符串的长度。为什么要这样做？字符串本身不像数值类型可以进行数值比较，两个字符串对比的时间复杂度取决于字符串长度。如果不用字典树来完成上述功能，要对历史字符串进行排序，再利用二分查找之类的算法去搜索，时间复杂度只高不低。可认为字典树是一种空间换时间的典型做法。

普通的字典树有一个比较明显的缺点，就是每个字母都需要建立一个孩子节点，这样会导致字典树的层数比较深，压缩字典树相对好地平衡了字典树的优点和缺点。

<img src="https://www.topgoer.cn/uploads/advancedgoprogramming/images/ch6-02-radix.png" alt="radix tree" style="zoom:33%;" />

每个节点上不只存储一个字母了，这也是压缩字典树中“压缩”的主要含义。使用压缩字典树可以减少树的层数，同时因为每个节点上数据存储也比通常的字典树要多，所以程序的局部性较好（一个节点的path加载到cache即可进行多个字符的对比），从而对CPU缓存友好。

#### 压缩字典树创建过程

#### root 节点创建

httprouter的Router结构体中存储压缩字典树使用的是下述数据结构：

```go
// 略去了其它部分的 Router struct
type Router struct {
    // ...
    trees map[string]*node
    // ...
}
```

`trees`中的`key`即为HTTP 1.1的RFC中定义的各种方法，具体有：

```shell
GET
HEAD
OPTIONS
POST
PUT
PATCH
DELETE
```

每一种方法对应的都是一棵独立的压缩字典树，这些树彼此之间不共享数据。具体到我们上面用到的路由，`PUT`和`GET`是两棵树而非一棵。

简单来讲，某个方法第一次插入的路由就会导致对应字典树的根节点被创建

radix的节点类型为`*httprouter.node`，为了说明方便，我们留下了目前关心的几个字段：

```
path: 当前节点对应的路径中的字符串

wildChild: 子节点是否为参数节点，即 wildcard node，或者说 :id 这种类型的节点

nType: 当前节点类型，有四个枚举值: 分别为 static/root/param/catchAll。
    static                   // 非根节点的普通字符串节点
    root                     // 根节点
    param                    // 参数节点，例如 :id
    catchAll                 // 通配符节点，例如 *anyway

indices：子节点索引，当子节点为非参数类型，即本节点的wildChild为false时，会将每个子节点的首字母放在该索引数组。说是数组，实际上是个stri
```

#### 子节点插入

当插入`GET /marketplace_listing/plans`时,因为第一个路由没有参数，path都被存储到根节点上了。所以只有一个节点。然后插入`GET /marketplace_listing/plans/:id/accounts`，新的路径与之前的路径有共同的前缀，且可以直接在之前叶子节点后进行插入.

<img src="https://www.topgoer.cn/uploads/advancedgoprogramming/images/ch6-02-radix-get-2.png" alt="get radix step 2" style="zoom:50%;" />

由于`:id`这个节点只有一个字符串的普通子节点，所以indices还依然不需要处理。

#### 边分裂

插入`GET /search`，这时会导致树的边分裂

原有路径和新的路径在初始的`/`位置发生分裂，这样需要把原有的root节点内容下移，再将新路由 `search`同样作为子节点挂在root节点之下。这时候因为子节点出现多个，root节点的indices提供子节点索引，这时候该字段就需要派上用场了。”ms”代表子节点的首字母分别为m（marketplace）和s（search）。

#### 子节点冲突处理

在路由本身只有字符串的情况下，不会发生任何冲突。只有当路由中含有wildcard（类似 :id）或者catchAll的情况下才可能冲突。这一点在前面已经提到了。

子节点的冲突处理很简单，分几种情况：

1. 在插入wildcard节点时，父节点的children数组非空且wildChild被设置为false。例如：`GET /user/getAll`和`GET /user/:id/getAddr`，或者`GET /user/*aaa`和`GET /user/:id`。
2. 在插入wildcard节点时，父节点的children数组非空且wildChild被设置为true，但该父节点的wildcard子节点要插入的wildcard名字不一样。例如：`GET /user/:id/info`和`GET /user/:name/info`。
3. 在插入catchAll节点时，父节点的children非空。例如：`GET /src/abc`和`GET /src/*filename`，或者`GET /src/:id`和`GET /src/*filename`。
4. 在插入static节点时，父节点的wildChild字段被设置为true。
5. 在插入static节点时，父节点的children非空，且子节点nType为catchAll。

只要发生冲突，都会在初始化的时候panic。例如，在插入我们臆想的路由`GET /marketplace_listing/plans/ohyes`时，出现第4种冲突情况：它的父节点`marketplace_listing/plans/`的wildChild字段为true。




### string 和 []byte 的高效转换

强转换
通过unsafe和reflect包，可以实现另外一种转换方式，我们将之称为强转换（也常常被人称作黑魔法）。

```
type slice struct {
    array unsafe.Pointer
    len   int
    cap   int
}
type stringStruct struct {
    str unsafe.Pointer
    len int
}
```

```func String2Bytes(s string) []byte {
    sh := (*reflect.StringHeader)(unsafe.Pointer(&s))
    bh := reflect.SliceHeader{
        Data: sh.Data,
        Len:  sh.Len,
        Cap:  sh.Len,
    }
    return *(*[]byte)(unsafe.Pointer(&bh))
}//错误的，sh.data本身是uintptr类型，goroutine的栈空间可能会发生移动，因此不能将其作为中间态复制到bh，再转换为【】byte
应该直接return *(*[]byte)(unsafe.Pointer(&s))

func Bytes2String(b []byte) string {
    return *(*string)(unsafe.Pointer(&b))
}
```
#### 为啥强转换性能会比标准转换？
对于标准转换，无论是从[]byte转string还是string转[]byte都会涉及底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。这样，当然后者的性能会更好。
#### 为啥在上述测试中，当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？
标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针指向。所以，当转换数据较大时，两者性能差距会愈加明显。
#### 为什么通常使用标准转化，而不用强转换？
Go是一门类型安全的语言，而安全的代价就是性能的妥协。但是，性能的对比是相对的，这点性能的妥协对于现在的机器而言微乎其微。另外强转换的方式，会给我们的程序带来极大的安全隐患。
#### 为啥string要设计为不可修改的？
string不可修改，意味它是只读属性，这样的好处就是：在并发场景下，我们可以在不加锁的控制下，多次使用同一字符串，在保证高效共享的情况下而不用担心安全问题

### unsafe包
golang是一种静态的强类型的语言，所有的类型都是不能随意转换的，Go语言是不允许两个指针类型进行转换的。go官方是不推荐使用unsafe的操作因为它是不安全的，它绕过了golang的内存安全原则，容易使你的程序出现莫名其妙的问题，不利于程序的扩展与维护。但是在很多地方却是很实用。在一些go底层的包中unsafe包被很频繁的使用。
#### unsafe 定义
```
//ArbitraryType仅用于文档目的，实际上并不是unsafe包的一部分,它表示任意Go表达式的类型。
type ArbitraryType int
//任意类型的指针，类似于C的*void
type Pointer *ArbitraryType
//确定结构在内存中占用的确切大小
func Sizeof(x ArbitraryType) uintptr
//返回结构体中某个field的偏移量
func Offsetof(x ArbitraryType) uintptr
//返回结构体中某个field的对其值（字节对齐的原因）
func Alignof(x ArbitraryType) uintptr
```
任何类型的指针都可以被转化为Pointer
Pointer可以被转化为任何类型的指针
uintptr可以被转化为Pointer
Pointer可以被转化为uintptr

这三个方法返回的都是uintptr类型，这个目的就是可以和unsafe.poniter类型相互转换，因为*T是不能计算偏移量的，也不能进行计算，但是uintptr是可以的，所以可以使用uintptr类型进行计算，这样就可以可以访问特定的内存了，达到对不同的内存读写的目的。三个方法的入参都是ArbitraryType类型，代表着任意类型的意思，同时还提供了一个Pointer指针类型，即像void *一样的通用型指针。
unsafe.Pointer其实就是类似C的void *，在Go 语言中是用于各种指针相互转换的桥梁，也即是通用指针。它可以让任意类型的指针实现相互转换，也可以将任意类型的指针转换为 uintptr 进行指针运算。

uintptr是Go 语言的内置类型，是能存储指针的整型， uintptr 的底层类型是int，它和unsafe.Pointer可相互转换。

uintptr和unsafe.Pointer的区别就是：

unsafe.Pointer只是单纯的通用指针类型，用于转换不同类型指针，它不可以参与指针运算；

而uintptr是用于指针运算的，GC 不把 uintptr 当指针，也就是说 uintptr 无法持有对象， uintptr 类型的目标会被回收；

unsafe.Pointer 可以和 普通指针 进行相互转换；

unsafe.Pointer 可以和 uintptr 进行相互转换。

### 请求校验

需要进行字段校验判断的情况有很多，Web系统的Form或JSON提交只是一个典型的例子

这里我们引入一个新的validator库:

https://github.com/go-playground/validator

#### validator请求校验

从结构上来看，每一个结构体都可以看成是一棵树。

从字段校验的需求来讲，无论我们采用深度优先搜索还是广度优先搜索来对这棵结构体树来进行遍历，都是可以的。

写一个递归的深度优先搜索方式的遍历

```go
package main

import (
    "fmt"
    "reflect"
    "regexp"
    "strconv"
    "strings"
)

type Nested struct {
    Email string `validate:"email"`
}
type T struct {
    Age    int `validate:"eq=10"`
    Nested Nested
}

func validateEmail(input string) bool {
    if pass, _ := regexp.MatchString(
        `^([\w\.\_]{2,10})@(\w{1,}).([a-z]{2,4})$`, input,
    ); pass {
        return true
    }
    return false
}

func validate(v interface{}) (bool, string) {
    validateResult := true
    errmsg := "success"
    vt := reflect.TypeOf(v)
    vv := reflect.ValueOf(v)
    for i := 0; i < vv.NumField(); i++ {
        fieldVal := vv.Field(i)
        tagContent := vt.Field(i).Tag.Get("validate")
        k := fieldVal.Kind()

        switch k {
        case reflect.Int:
            val := fieldVal.Int()
            tagValStr := strings.Split(tagContent, "=")
            tagVal, _ := strconv.ParseInt(tagValStr[1], 10, 64)
            if val != tagVal {
                errmsg = "validate int failed, tag is: "+ strconv.FormatInt(
                    tagVal, 10,
                )
                validateResult = false
            }
        case reflect.String:
            val := fieldVal.String()
            tagValStr := tagContent
            switch tagValStr {
            case "email":
                nestedResult := validateEmail(val)
                if nestedResult == false {
                    errmsg = "validate mail failed, field val is: "+ val
                    validateResult = false
                }
            }
        case reflect.Struct:
            // 如果有内嵌的 struct，那么深度优先遍历
            // 就是一个递归过程
            valInter := fieldVal.Interface()
            nestedResult, msg := validate(valInter)
            if nestedResult == false {
                validateResult = false
                errmsg = msg
            }
        }
    }
    return validateResult, errmsg
}

func main() {
    var a = T{Age: 10, Nested: Nested{Email: "abc@abc.com"}}

    validateResult, errmsg := validate(a)
    fmt.Println(validateResult, errmsg)
}
```

原理很简单，就是用反射对结构体进行树形遍历

### 常见的流量限制手段/限流

流量限制的手段有很多，最常见的：漏桶、令牌桶两种：

1. 漏桶是指我们有一个一直装满了水的桶，每过固定的一段时间即向外漏一滴水。如果你接到了这滴水，那么你就可以继续服务请求，如果没有接到，那么就需要等待下一滴水。
2. 令牌桶则是指匀速向桶中添加令牌，服务请求时需要从桶中获取令牌，令牌的数目可以按照需要消耗的资源进行相应的调整。如果没有令牌，可以选择等待，或者放弃。

漏桶流出的速率固定，而令牌桶只要在桶中有令牌，那就可以拿。也就是说令牌桶是允许一定程度的并发的，比如同一个时刻，有100个用户请求，只要令牌桶中有100个令牌，那么这100个请求全都会放过去。令牌桶在桶中没有令牌的情况下也会退化为漏桶模型。

实际应用中令牌桶应用较为广泛，开源界流行的限流器大多数都是基于令牌桶思想的。并且在此基础上进行了一定程度的扩充，比如`github.com/juju/ratelimit`提供了几种不同特色的令牌桶填充方式：

```go
func NewBucket(fillInterval time.Duration, capacity int64) *Bucket
```

默认的令牌桶，`fillInterval`指每过多长时间向桶里放一个令牌，`capacity`是桶的容量，超过桶容量的部分会被直接丢弃。桶初始是满的。

```go
func NewBucketWithQuantum(fillInterval time.Duration, capacity, quantum int64) *Bucket
```

和普通的`NewBucket()`的区别是，每次向桶中放令牌时，是放`quantum`个令牌，而不是一个令牌。

```go
func NewBucketWithRate(rate float64, capacity int64) *Bucket
```

这个就有点特殊了，会按照提供的比例，每秒钟填充令牌数。例如`capacity`是100，而`rate`是0.1，那么每秒会填充10个令牌。

从桶中获取令牌也提供了几个API：

```go
func (tb *Bucket) Take(count int64) time.Duration {}
func (tb *Bucket) TakeAvailable(count int64) int64 {}
func (tb *Bucket) TakeMaxDuration(count int64, maxWait time.Duration) (
    time.Duration, bool,
) {}
func (tb *Bucket) Wait(count int64) {}
func (tb *Bucket) WaitMaxDuration(count int64, maxWait time.Duration) bool {}
```

#### ratelimit原理

从功能上来看，令牌桶模型就是对全局计数的加减法操作过程，但使用计数需要我们自己加读写锁，有小小的思想负担。如果我们对Go语言已经比较熟悉的话，很容易想到可以用buffered channel来完成简单的加令牌取令牌操作：

```go
var tokenBucket = make(chan struct{}, capacity)
```

每过一段时间向`tokenBucket`中添加`token`，如果`bucket`已经满了，那么直接放弃：

```go
fillToken := func() {
    ticker := time.NewTicker(fillInterval)
    for {
        select {
        case <-ticker.C:
            select {
            case tokenBucket <- struct{}{}:
            default:
            }
            fmt.Println("current token cnt:", len(tokenBucket), time.Now())
        }
    }
}
```

把代码组合起来：

```go
package main

import (
    "fmt"
    "time"
)

func main() {
    var fillInterval = time.Millisecond * 10
    var capacity = 100
    var tokenBucket = make(chan struct{}, capacity)

    fillToken := func() {
        ticker := time.NewTicker(fillInterval)
        for {
            select {
            case <-ticker.C:
                select {
                case tokenBucket <- struct{}{}:
                default:
                }
                fmt.Println("current token cnt:", len(tokenBucket), time.Now())
            }
        }
    }

    go fillToken()
    time.Sleep(time.Hour)
}
```

令牌桶的取令牌操作实现起来也比较简单，简化问题，我们这里只取一个令牌：

```go
func TakeAvailable(block bool) bool{
    var takenResult bool
    if block {
        select {
        case <-tokenBucket:
            takenResult = true
        }
    } else {
        select {
        case <-tokenBucket:
            takenResult = true
        default:
            takenResult = false
        }
    }

    return takenResult
}
```

令牌桶每隔一段固定的时间向桶中放令牌，如果我们记下上一次放令牌的时间为 t1，和当时的令牌数k1，放令牌的时间间隔为ti，每次向令牌桶中放x个令牌，令牌桶容量为cap。现在如果有人来调用`TakeAvailable`来取n个令牌，我们将这个时刻记为t2。在t2时刻，令牌桶中理论上应该有多少令牌呢？伪代码如下：

```go
cur = k1 + ((t2 - t1)/ti) * x
cur = cur > cap ? cap : cur
```

我们用两个时间点的时间差，再结合其它的参数，理论上在取令牌之前就完全可以知道桶里有多少令牌了。那劳心费力地像本小节前面向channel里填充token的操作，理论上是没有必要的。只要在每次`Take`的时候，再对令牌桶中的token数进行简单计算，就可以得到正确的令牌数。是不是很像`惰性求值`的感觉？

在得到正确的令牌数之后，再进行实际的`Take`操作就好，这个`Take`操作只需要对令牌数进行简单的减法即可，记得加锁以保证并发安全。`github.com/juju/ratelimit`这个库就是这样做的

### go实现生产者消费者模型

```
package main
 
import "fmt"
 
func Producer(ch chan int) {
	for i := 1; i <= 10; i++ {
		ch <- i
	}
	close(ch)
}
 
func Consumer(id int, ch chan int, done chan bool) {
	for {
		value, ok := <-ch
		if ok {
			fmt.Printf("id: %d, recv: %d\n", id, value)
		} else {
			fmt.Printf("id: %d, closed\n", id)
			break
		}
	}
	done <- true
}
 
func main() {
	ch := make(chan int, 3)
 
	coNum := 2
	done := make(chan bool, coNum)
	for i := 1; i <= coNum; i++ {
		go Consumer(i, ch, done)
	}
 
	go Producer(ch)
 
	for i := 1; i <= coNum; i++ {
		<-done
	}
}
```



## 计算机网络

### 1.OSI 的七层模型分别是？各自的功能是什么？

简要概括 物理层：底层数据传输，如网线；网卡标准。 数据链路层：定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。 网络层：定义IP编址，定义路由功能；如不同设备的数据转发。 传输层：端到端传输数据的基本功能；如 TCP、UDP。 会话层：控制应用程序之间会话能力；如不同软件数据分发给不同软件。 表示层：数据格式标识，基本压缩加密功能。 应用层：各种应用软件，包括 Web 应用。 

说明： 在四层，既传输层数据被称作段（Segments）； 三层网络层数据被称做包（Packages）； 二层数据链路层时数据被称为帧（Frames）； 一层物理层时数据被称为比特流（Bits）。

 总结 网络七层模型是一个标准，而非实现。 网络四层模型是一个实现的应用模型。 网络四层模型由七层模型简化合并而来。

### 四层网络模型

**应用层：**

应用层位于传输层之上，主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输。

应用层协议：HTTP、DNS、DHCP、SSH、FTP、SMTP、IMAP

**传输层：**

传输层的主要任务就是负责向两台终端设备进程之间的通信提供通用的数据传输服务。

传输层主要协议：TCP（面向连接、提供可靠的数据传输服务）、UDP（无连接、提供尽可能交付传输服务）

**网络层：**

网络层负责为分组交换网上的不同主机提供通信服务。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报，简称数据报。

网络层的还有一个任务就是选择合适的路由，使源主机运输层所传下来的分组，能通过网络层中的路由器找到目的主机。

网络层主要协议：IP、ARP（地址解析协议，根据IP地址获取物理地址的一个TCP/IP协议）、NAT（网络地址转换协议，将在本地网络中使用的私有地址，在连接互联网的同时转换成为公共 IP 地址的技术）

**网络接口层：**

包括两个部分：

- 数据链路层(data     link layer)通常简称为链路层（ 两台主机之间的数据传输，总是在一段一段的链路上传送的）。数据链路层的作用是将网络层交下来的 IP     数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。
- 物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异

#### 为什么还需要传输层，光靠网络层不是可以将数据包进行传输，传输层作用？

能提供应用的多路复用/分用服务、可靠数据传送、带宽保证及延迟保证等。网络层提供的是“best effort”尽力而为的服务，网络层提供的无连接服务不可靠(丢包、重复)，并且路由器可能崩溃，或者传输线路中断，所以传输层必须足够健壮来解决网络层不可靠，不稳定的问题，比如说传输层可检测到包丢失、损坏、乱序等差错情况，采取相应措施；或者当数据传输过程中网络连接中断，传输层可与远程传输实体建立一新的网络连接，在中断处继续数据的传输。
复用：当传输层从应用程序接收报文后要封装在传输层的段中再交给网络层发送。

分用：当传输层从网络层接收数据后，必须将数据正确递交给某个应用程序。也就是传输层曾能够区分不同进程的数据并且加以区分处理。可靠数据传输，比如传输层的TCP协议，提供了面向连接的，可靠的，具有拥塞控制的协议，这是为了弥补网络层不足所建立的。

传输层还有寻址的功能，定位应用程序在哪里。以及流量的控制，防止接收端速度太慢造成溢出和丢包的现象。流量控制和拥塞控制的区别是：流量控制只是端端之间，只需要管理两个端之间的流量传输即可，也就是局部的。但是拥塞控制是全局的，是整个网络所做的事情，需要所有的路由器主机一起努力完成的事情。在传输层，既有流量控制也有拥塞控制。



### 2.为什么需要三次握手？两次不行？

第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。  第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。  第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

为了防止旧的重复连接引起连接混乱问题
client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。
### 设计一个基于udp的可靠连接算法？
针对数据完整性 –> 加上一个16或者32位的CRC验证字段
针对乱序 –> 加上一个数据包序列号SEQ
针对丢包 –> 需要确认和重传机制，就是和Tcp类似的Ack机制
针对协议字段 –> protol 字段，标识当前使用协议
添加发送和接收缓冲区，主要是用户超时重传
添加超时重传机制。
送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。
基于UDP的数据传输协议（UDP-basedData Transfer Protocol，简称UDT）是一种互联网数据传输协议。UDT的主要目的是支持高速广域网上的海量数据传输，而互联网上的标准数据传输协议TCP在高带宽长距离网络上性能很差。

顾名思义，UDT建于UDP之上，并引入新的拥塞控制和数据可靠性控制机制。UDT是面向连接的双向的应用层协议。它同时支持可靠的数据流传输和部分可靠的数据报传输。由于UDT完全在UDP上实现，它也可以应用在除了高速数据传输之外的其它应用领域，例如点到点技术（P2P），防火墙穿透，多媒体数据传输等等。

### 3.TCP三次握手过程

刚开始客户端处于 closed 的状态，服务端处于 listen 状态。然后 1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端处于 SYN_Send 状态。 2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_RCVD 的状态。 3、第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 established 状态。 4、服务器收到 ACK 报文之后，也处于 established 状态，此时，双方以建立起了链接



### 4.三次握手的作用

 1、确认双方的接受能力、发送能力是否正常。 

2、指定自己的初始化序列号，为后面的可靠传送做准备。 



#### 4.1（ISN）是固定的吗 ?

三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。 如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。 

#### 4.2、什么是半连接队列 

服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

### 5、三次握手过程中可以携带数据吗 

很多人可能会认为三次握手都不能携带数据，其实第三次握手的时候，是可以携带数据的。也就是说，第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。

 为什么这样呢？大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，其中一个简单的原因就是会让服务器更加容易受到攻击了。 

而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。

### 6.为什么需要四次挥手？三次不行？

刚开始双方都处于+establised+状态，假如是客户端先发起关闭请求，则：

+1、第一次挥手：客户端发送一个+FIN+报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。

+2、第二次挥手：服务端收到+FIN+之后，会发送+ACK+报文，且把客户端的序列号值+%2B+1+作为+ACK+报文的序列号值，表明已经收到客户端的报文了，此时服务端处于+CLOSE_WAIT状态。

+3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给+FIN+报文，且指定一个序列号。此时服务端处于+LAST_ACK+的状态。

+4、第四次挥手：客户端收到+FIN+之后，一样发送一个+ACK+报文作为应答，且把服务端的序列号值+%2B+1+作为自己+ACK+报文的序列号值，此时客户端处于+TIME_WAIT+状态。需要过一阵子以确保服务端收到自己的+ACK+报文之后才会进入+CLOSED+状态
+5、服务端收到+ACK+报文之后，就处于关闭连接了，处于+CLOSED+状态。

#### 为什么要time_wait/timewait

1.防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）
2.可靠的关闭TCP连接。在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。另外这么设计TIME_WAIT 会定时的回收资源，并不会占用很大资源的，除非短时间内接受大量请求或者受到攻击。



### **HTTP请求报文**

一个HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据4个部分组成。

**请求头**

请求行由请求方法字段、URL字段和HTTP协议版本字段3个字段组成，它们用空格分隔。例如，GET /index.html HTTP/1.1。

HTTP协议的请求方法有GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT。

**2.请求头部**

请求头部由关键字/值对组成，每行一对，关键字和值用英文冒号“:”分隔。请求头部通知服务器有关于客户端请求的信息，典型的请求头有：

User-Agent：产生请求的浏览器类型。

Accept：客户端可识别的内容类型列表。

Host：请求的主机名，允许多个域名同处一个IP地址，即虚拟主机。

 

**3.空行**

最后一个请求头之后是一个空行，发送回车符和换行符，通知服务器以下不再有请求头。

 

**4.请求数据**

请求数据不在GET方法中使用，而是在POST方法中使用。POST方法适用于需要客户填写表单的场合。与请求数据相关的最常使用的请求头是Content-Type和Content-Length。

### **HTTP响应报文**

HTTP响应也由三个部分组成，分别是：状态行、消息报头、响应正文。

状态行由三部分组成：**服务器HTTP协议版本**，**响应状态码**，**状态码的文本描述**

### 响应首部（首部行）：位于响应报文状态行之后

Date标头：消息产生的时间

Age标头:（从最初创建开始）响应持续时间

Server标头: 向客户端标明服务器程序名称和版本

ETage标头：不透明验证者

Location标头：URL备用的位置

Content-Length标头：实体的长度

Content-Tyep标头：实体的媒体类型

### 响应实体：位于响应首部（首部行）之后

实体包含了Web客户端请求的对象。Content-Length标头及Content-Type标头用于计算实体的位置、数据类型和数据长度。当Web服务器接收到Web客户端的请求报文后，对HTTP请求报文进行解析，并将Web客户端的请求的对象取出打包，通过HTTP响应报文将数据传回给Web客户端，如果出现错误则返回包含对应错误的错误代码和错误原因的HTTP响应报文。

### 7.POST和GET有哪些区别？

`GET`请求方法指定资源的表示形式，使用GET的请求应该只用于被获取数据

`POST`方法将实体提交到指定的资源，通常会导致在服务器上的状态变化或**受到影响**

复上都是`TCP`链接，并无赋予

由于`HTTP`规定的规定和服务器的限制，导致他们在应用程序中会宣传/出出一些类别

你的标准答案的区别如下：

- GET在浏览器返回的时候是无害的，而POST会再次提交请求。
- GET 产生的 URL 地址可以被书签，而 POST 不能。
- GET请求会被主动设置，而POST不会，浏览手动设置。
- GET请求只能进行url编码，而POST支持字母编码方式。
- GET请求参数会被完整保留在浏览器历史记录中，而POST中的参数不会被保留。
- GET请求在URL中传递的参数是有长度限制的，而POST没有。
- 对参数的数据类型，GET 只接受 ASCII 字符，而 POST 没有限制。
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能上传敏感信息。
- GET通过URL传递，POST请求正文中提出



### 8.HTTP 状态码

| 100  | Continue                        | 继续。客户端应继续其请求                                     |
| ---- | ------------------------------- | ------------------------------------------------------------ |
| 101  | Switching Protocols             | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
|      |                                 |                                                              |
| 200  | OK                              | 请求成功。一般用于GET与POST请求                              |
| 201  | Created                         | 已创建。成功请求并创建了新的资源                             |
| 202  | Accepted                        | 已接受。已经接受请求，但未处理完成                           |
| 203  | Non-Authoritative Information   | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |
| 204  | No Content                      | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |
| 205  | Reset Content                   | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |
| 206  | Partial Content                 | 部分内容。服务器成功处理了部分GET请求                        |
|      |                                 |                                                              |
| 300  | Multiple Choices                | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| 301  | Moved Permanently               | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |
| 302  | Found                           | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
| 303  | See Other                       | 查看其它地址。与301类似。使用GET和POST请求查看               |
| 304  | Not Modified                    | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 305  | Use Proxy                       | 使用代理。所请求的资源必须通过代理访问                       |
| 306  | Unused                          | 已经被废弃的HTTP状态码                                       |
| 307  | Temporary Redirect              | 临时重定向。与302类似。使用GET请求重定向                     |
|      |                                 |                                                              |
| 400  | Bad Request                     | 客户端请求的语法错误，服务器无法理解                         |
| 401  | Unauthorized                    | 请求要求用户的身份认证                                       |
| 402  | Payment Required                | 保留，将来使用                                               |
| 403  | Forbidden                       | 服务器理解请求客户端的请求，但是拒绝执行此请求               |
| 404  | Not Found                       | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |
| 405  | Method Not Allowed              | 客户端请求中的方法被禁止                                     |
| 406  | Not Acceptable                  | 服务器无法根据客户端请求的内容特性完成请求                   |
| 407  | Proxy Authentication Required   | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |
| 408  | Request Time-out                | 服务器等待客户端发送的请求时间过长，超时                     |
| 409  | Conflict                        | 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 |
| 410  | Gone                            | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |
| 411  | Length Required                 | 服务器无法处理客户端发送的不带Content-Length的请求信息       |
| 412  | Precondition Failed             | 客户端请求信息的先决条件错误                                 |
| 413  | Request Entity Too Large        | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |
| 414  | Request-URI Too Large           | 请求的URI过长（URI通常为网址），服务器无法处理               |
| 415  | Unsupported Media Type          | 服务器无法处理请求附带的媒体格式                             |
| 416  | Requested range not satisfiable | 客户端请求的范围无效                                         |
| 417  | Expectation Failed              | 服务器无法满足Expect的请求头信息                             |
|      |                                 |                                                              |
| 500  | Internal Server Error           | 服务器内部错误，无法完成请求                                 |
| 501  | Not Implemented                 | 服务器不支持请求的功能，无法完成请求                         |
| 502  | Bad Gateway                     | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |
| 503  | Service Unavailable             | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |
| 504  | Gateway Time-out                | 充当网关或代理的服务器，未及时从远端服务器获取请求           |
| 505  | HTTP Version not supported      | 服务器不支持请求的HTTP协议的版本，无法完成处理               |

### 9.简单说下 HTTPS 和 HTTP 的区别

**HTTPS和HTTP的主要区别**

https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。

http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl/tls加密传输协议。

http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

https协议需要到ca申请证书，一般免费证书很少，需要交费。http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议http和https使用的是完全不同的连接方式用的端口也不一样,前者是80,后者是443。http的连接很简单,是无状态的HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议。

### 10.HTTPS 的工作过程

在进行通信前，首先会进行 HTTP 的三次握手，握手完成后，再进行 TLS 的握手过程

第一步：客户端向服务端发起请求

 a.  客户端生成随机数R1 发送给服务端

  b.  告诉服务端自己支持哪些加密算法

  第二步：服务器向客户端发送数字证书

  a.  服务端生成随机数R2;

  b.  从客户端支持的加密算法中选择一种双方都支持的加密算法（此算法用于后面的会话密钥生成）;

  c.  服务端生成把证书、随机数R2、会话密钥生成算法，一同发给客户端; 

  第三步：客户端验证数字证书。

  a.  验证证书的可靠性，先用CA的公钥解密被加密过后的证书,能解密则说明证书没有问题，然后通过证书里提供的摘要算法进行对数据进行摘要，然后通过自己生成的摘要与服务端发送的摘要比对。

  b.  验证证书合法性，包括证书是否吊销、是否到期、域名是否匹配，通过后则进行后面的流程

  c.  获得证书的公钥、会话密钥生成算法、随机数R2

  d.  生成一个随机数R3。

  e.  根据会话秘钥算法使用R1、R2、R3生成会话秘钥。

  f.  用服务端证书的公钥加密随机数R3并发送给服务端。

  第四步：服务器得到会话密钥

 a.  服务器用私钥解密客户端发过来的随机数R3

 b.  根据会话秘钥算法使用R1、R2、R3生成会话秘钥

 第五步：客户端与服务端进行加密会话

 1） 客户端发送加密数据给服务端

 发送加密数据：客户端加密数据后发送给服务端。

 2）服务端响应客户端

 解密接收数据：服务端用会话密钥解密客户端发送的数据；

 加密响应数据：用会话密钥把响应的数据加密发送给客户端。

 3）客户端解密服务端响应的数据

 解密数据：客户端用会话密钥解密响应数据；

-----------------------------------
### 11.谈谈你对滑动窗口的了解

TCP 利用滑动窗口实现流量控制的机制。滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。发送端不能疯狂地向接收端发送数据，因为接收端接收不过来的话，接收方只能把处理不过来的数据存在缓存区里。如果缓存区都满了，发送方还在疯狂发送数据的话，接收方只能把收到的数据包丢掉，这就浪费了网络资源啦。

 TCP 中采用滑动窗口来进行传输控制,TCP报文首部有个字段**win**控制窗口大小，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

### 12.session和cookie

HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。

Cookie 主要用于以下三个方面：

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

#### **什么是 Session**

Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。

#### Cookie 和 Session 有什么不同？

- 作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。
- 存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。
- 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
- 隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
- 存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie

用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。

当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。

根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。

既然服务端是根据 Cookie 中的信息判断用户是否登录，那么如果浏览器中禁止了 Cookie，如何保障整个机制的正常运转。

#### 浏览器禁止cookie怎么办？

第一种方案，每次请求中都携带一个 SessionID 的参数，也可以 Post 的方式提交，也可以在请求的地址后面拼接 `xxx?SessionID=123456...`。

第二种方案，Token 机制。Token 机制多用于 App 客户端和服务器交互的模式，也可以用于 Web 端做用户状态管理。

Token 的意思是“令牌”，是服务端生成的一串字符串，作为客户端进行请求的一个标识。Token 机制和 Cookie 和 Session 的使用机制比较类似。

当用户第一次登录后，服务器根据提交的用户信息生成一个 Token，响应时将 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次登录验证。

#### 如何考虑分布式 Session 问题？

在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。

分布式 Session 一般会有以下几种解决方案：

- Nginx ip_hash 策略，服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。
- Session 复制，任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。
- 共享 Session，服务端无状态话，将用户的 Session 等信息使用缓存中间件来统一管理，保障分发到每一个服务器的响应结果都一致。

### 13.TCP异常处理？

#### 三次握手异常情况。

三次握手的正常发包和应答，以及双端的状态扭转我们已经讲了，接下来就来看看在

**(1) 客户端第一个「SYN」包丢了。**

如果客户端第一个「SYN」包丢了，也就是服务端根本就不知道客户端曾经发过包，那么处理流程主要在客户端。

而在 TCP 协议中，某端的一组「请求-应答」中，在一定时间范围内，只要没有收到应答的「ACK」包，无论是请求包对方没有收到，还是对方的应答包自己没有收到，均认为是丢包了，都会触发超时重传机制。

所以此时会进入重传「SYN」包。根据《TCP/IP详解卷Ⅰ：协议》中的描述，此时会尝试三次，间隔时间分别是 5.8s、24s、48s，三次时间大约是 76s 左右，而大多数伯克利系统将建立一个新连接的最长时间，限制为 75s。

也就是说三次握手第一个「SYN」包丢了，会重传，总的尝试时间是 75s。

**(2) 服务端收到「SYN」并回复的「SYN,ACK」包丢了。**

此时服务端已经收到了数据包并回复，如果这个回复的「SYN,ACK」包丢了，站在客户端的角度，会认为是最开始的那个「SYN」丢了，那么就继续重传，就是我们前面说的「错误 1」 的流程。

而对服务端而言，如果发送的「SYN,ACK」包丢了，在超时时间内没有收到客户端发来的「ACK」包，也会触发重传，此时服务端处于 SYN_RCVD 状态，会依次等待 3s、6s、12s 后，重新发送「SYN,ACK」包。

而这个「SYN,ACK」包的重传次数，不同的操作系统下有不同的配置，例如在 Linux 下可以通过 tcp_synack_retries 进行配置，默认值为 5。如果这个重试次数内，仍未收到「ACK」应答包，那么服务端会自动关闭这个连接。

同时由于客户端在没有收到「SYN,ACK」时，也会进行重传，当客户端重传的「SYN」被收到后，服务端会立即重新发送「SYN,ACK」包。

**(3) 客户端最后一次回复「SYN,ACK」的「ACK」包丢了。**

如果最后一个「ACK」包丢了，服务端因为收不到「ACK」会走重传机制，而客户端此时进入 ESTABLISHED 状态。

多数情况下，客户端进入 ESTABLISHED 状态后，则认为连接已建立，会立即发送数据。但是服务端因为没有收到最后一个「ACK」包，依然处于 SYN-RCVD 状态。

那么这里的关键，就在于服务端在处于 SYN-RCVD 状态下，收到客户端的数据包后如何处理?

这也是比较有争议的地方，有些资料里会写到当服务端处于 SYN-RCVD 状态下，收到客户端的数据包后，会直接回复 RTS 包响应，表示服务端错误，并进入 CLOSE 状态。

但是这样的设定有些过于严格，试想一下，服务端还在通过三次握手阶段确定对方是否真实存在，此时对方的数据已经发来了，那肯定是存在的。

所以当服务端处于 SYN-RCVD 状态下时，接收到客户端真实发送来的数据包时，会认为连接已建立，并进入 ESTABLISHED 状态。

那么实际情况，为什么会这样呢?

当客户端在 ESTABLISHED 状态下，开始发送数据包时，会携带上一个「ACK」的确认序号，所以哪怕客户端响应的「ACK」包丢了，服务端在收到这个数据包时，能够通过包内 ACK 的确认序号，正常进入 ESTABLISHED 状态。

**(4) 客户端故意不发最后一次「SYN」包。**

前面一直在说正常的异常逻辑，双方都还算友善，按规矩做事，出现异常主要也是因为网络等客观问题，接下来说一个恶意的情况。

如果客户端是恶意的，在发送「SYN」包后，并收到「SYN,ACK」后就不回复了，那么服务端此时处于一种半连接的状态，虽然服务端会通过 tcp_synack_retries 配置重试的次数，不会无限等待下去，但是这也是有一个时间周期的。

如果短时间内存在大量的这种恶意连接，对服务端来说压力就会很大，这就是所谓的 SYN FLOOD 攻击。

这就属于安全攻防的范畴了，今天就不讨论了，有兴趣可以自行了解。

####  **TCP 挥手的异常情况**

四次挥手的正常发包和应答过程，我们已经简单了解了，接下来就继续看看，四次挥手过程中，出现的异常情况。

**(1) 断开连接的 FIN 包丢了。**

我们前面一直强调过，如果一个包发出去，在一定时间内，只要没有收到对端的「ACK」回复，均认为这个包丢了，会触发超时重传机制。而不会关心到底是自己发的包丢了，还是对方的「ACK」丢了。

所以在这里，如果客户端率先发的「FIN」包丢了，或者没有收到对端的「ACK」回复，则会触发超时重传，直到触发重传的次数，直接关闭连接。

对于服务端而言，如果客户端发来的「FIN」没有收到，就没有任何感知。会在一段时间后，也关闭连接。

**(2) 服务端第一次回复的 ACK 丢了。**

此时因为客户端没有收到「ACK」应答，会尝试重传之前的「FIN」请求，服务端收到后，又会立即再重传「ACK」。

而此时服务端已经进入 CLOSED-WAIT 状态，开始做断开连接前的准备工作。当准备好之后，会回复「FIN,ACK」，注意这个消息是携带了之前「ACK」的响应序号的。

只要这个消息没丢，客户端可以凭借「FIN,ACK」包中的响应序号，直接从 FIN-WAIT-1 状态，进入 TIME-WAIT 状态，开始长达 2MSL 的等待。

**(3) 服务端发送的 FIN,ACK 丢了。**

服务端在超时后会重传，此时客户端有两种情况，要么处于 FIN-WAIT-2 状态(之前的 ACK 也丢了)，会一直等待;要么处于 TIME-WAIT 状态，会等待 2MSL 时间。

也就是说，在一小段时间内客户端还在，客户端在收到服务端发来的「FIN,ACK」包后，也会回复一个「ACK」应答，并做好自己的状态切换。

**(4) 客户端最后回复的 ACK 丢了。**

客户端在回复「ACK」后，会进入 TIME-WAIT 状态，开始长达 2MSL 的等待，服务端因为没有收到「ACK」的回复，会重试一段时间，直到服务端重试超时后主动断开。

或者等待新的客户端接入后，收到服务端重试的「FIN」消息后，回复「RST」消息，在收到「RST」消息后，复位服务端的状态。

**(5) 客户端收到 ACK 后，服务端跑路了。**

客户端在收到「ACK」后，进入了 FIN-WAIT-2 状态，等待服务端发来的「FIN」包，而如果服务端跑路了，这个包永远都等不到。

在 TCP 协议中，是没有对这个状态的处理机制的。但是协议不管，系统来凑，操作系统会接管这个状态，例如在 Linux 下，就可以通过 tcp_fin_timeout 参数，来对这个状态设定一个超时时间。

需要注意的是，当超过 tcp_fin_timeout 的限制后，状态并不是切换到 TIME_WAIT，而是直接进入 CLOSED 状态。

**(6) 客户端收到 ACK 后，客户端自己跑路了。**

客户端收到「ACK」后直接跑路，服务端后续在发送的「FIN,ACK」就没有接收端，也就不会得到回复，会不断的走 TCP 的超时重试的机制，此时服务端处于 LAST-ACK 状态。

那就要分 2 种情况分析：

- 在超过一定时间后，服务端主动断开。
- 收到「RST」后，主动断开连接。

「RST」消息是一种重置消息，表示当前错误了，应该回到初始的状态。如果客户端跑路后有新的客户端接入，会在此发送「SYN」以期望建立连接，此时这个「SYN」将被忽略，并直接回复「FIN,ACK」消息，新客户端在收到「FIN」消息后是不会认的，并且会回复一个「RST」消息。

### 键入网址到网页显示，期间发生了什么？

https://xiaolincoding.com/network/1_base/what_happen_url.html#%E5%AD%A4%E5%8D%95%E5%B0%8F%E5%BC%9F-http

浏览器做的第一步工作是解析 URL

生产 HTTP 请求信息

真实地址查询 —— DNS

浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。

#### 域名解析的工作流程

![域名解析的工作流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/6.jpg)

 指南好帮手 —— 协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/7.jpg" alt="img" style="zoom:50%;" />

应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。

协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。

此外 IP 中还包括 `ICMP` 协议和 `ARP` 协议。

- `ICMP` 用于告知网络包传送过程中产生的错误以及各种控制信息。
- `ARP` 用于根据 IP 地址查询相应的以太网 MAC 地址。

IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。

#### 可靠传输 —— TCP

##### TCP 包头格式

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/8.jpg" alt="TCP 包头格式" style="zoom:50%;" />

##### 如何查看 TCP 的连接状态？

TCP 的连接状态查看，在 Linux 可以通过 `netstat -napt` 命令查看。

远程定位 —— IP

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/14.jpg" alt="IP 包头格式" style="zoom:33%;" />

#### 两点传输 —— MAC

生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 **MAC 头部**。

##### MAC 包头格式

MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/18.jpg" alt="MAC 包头格式" style="zoom: 50%;" />

一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：

- `0800` ： IP 协议
- `0806` ： ARP 协议

##### MAC 发送方和接收方如何确认?

**发送方**的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。

**接收方**的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。

所以先得搞清楚应该把包发给谁，这个只要查一下**路由表**就知道了。在路由表中找到相匹配的条目，然后把包发给 `Gateway` 列中的 IP 地址就可以了。

##### 既然知道要发给谁，按如何获取对方的 MAC 地址呢/ARP协议？

ARP 协议会在以太网中以**广播**的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。

然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。

如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。

##### 查看 ARP 缓存内容

在 Linux 系统中，我们可以使用 `arp -a` 命令来查看 ARP 缓存的内容。

在后续操作系统会把本次查询结果放到一块叫做 **ARP 缓存**的内存空间留着以后用，不过缓存的时间就几分钟。

也就是说，在发包时：

- 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。
- 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。



### 14.grpc

最底层为TCP或Unix Socket协议，在此之上是HTTP/2协议的实现，然后在HTTP/2协议之上又构建了针对Go语言的gRPC核心库。应用程序通过gRPC插件生产的Stub代码和gRPC核心库通信，也可以直接和gRPC核心库通信。

<img src="https://www.topgoer.cn/uploads/advancedgoprogramming/images/ch4-1-grpc-go-stack.png" alt="img" style="zoom: 50%;" />

#### grpc相比于其他rpc区别

RPC是远程函数调用，因此每次调用的函数参数和返回值不能太大，否则将严重影响每次调用的响应时间。因此传统的RPC方法调用对于上传和下载较大数据量场景并不适合。同时传统RPC模式也不适用于对时间不确定的订阅和发布模式。为此，gRPC框架针对服务器端和客户端分别提供了流特性。

grpc有以下特性和优势

支持多语言 

支持双工流 

Protobuf进行数据编码，提高数据压缩率

使用HTTP2.0弥补了HTTP1.1的不足

同样在调用方和服务方使用协议约定文件，提供参数可选，为版本兼容留下缓冲空间

protobuf是一款用C++开发的跨语言、二进制编码的数据序列化协议，以超高的压缩率著称。它和早期的RPC方案一样，需要双方维护一个协议约束文件，以.proto结尾，使用proto命令对文件进行解析，会生成对应的Stub程序，客户端和服务端都需要保存这份Stub程序用来进行编解码。对于这种协议文件导致的升级困难问题，protobuf 3 中定义的字段默认都是可选的(可以不传)，在接口升级时，部分客户端不需要升级自己的Stub程序。

#### 为什么不用restful

1.基于文本的低效消息协议 从本质上来讲，RESTful 服务建立在基于文本的传输协议（如 HTTP 1.x）之上，并且会使用人类可读的文本格式，如 JSON。但 是，在进行服务与服务之间的通信时，通信双方都不需要这种人类 可读的文本化格式，这时使用这种格式非常低效。 客户端应用程序（源）生成需要发送给服务器的二进制内容，然后 需要将二进制结构转换成文本（如果使用 HTTP 1.x，就只能发送文 本化消息），并通过网络以文本的形式（借助 HTTP）发送到另一 台机器上，这台机器需要在服务器端（目标）解析文本并将其转换 回二进制结构。其实，我们也可以很轻松地发送映射服务和消费者 业务逻辑的二进制内容，采用 JSON 格式主要是因为它是“人类可 读的”，相对来说易于使用。

HTTP/2 是 HTTP 协议自 1999 年 HTTP 1.1 发布后的首个更新，主要基于 SPDY 协议。HTTP/2 为了解决HTTP/1.1中仍然存在的效率问题，HTTP/2 采用了**多路复用**。即在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应。能这样做有一个前提就是HTTP/2进行了**二进制分帧**，即 HTTP/2 会将所有传输的信息分割为更小的消息和帧（frame）,并对它们采用二进制格式的编码.

2.应用程序之间缺乏强类型接口 随着越来越多的服务要通过网络进行交互，而且这些服务使用完全 不同的语言来构建，缺乏明确定义和强类型的服务接口成了使用 RESTful 服务的主要阻碍。RESTful 中现有的各种服务定义技术 （如 OpenAPI/Swagger 等）都是事后的补救措施，并没有与底层的 架构风格或消息协议紧密集成在一起。

3.REST 架构风格难以强制实施 REST 架构风格有很多“好的实践”，只有遵循这些实践，才能构建 出真正的 RESTful 服务。但是，由于它们并没有作为实现协议（比 如 HTTP）的一部分进行强制的要求，因此在实现阶段，这些实践 很难实施。事实上，大多数自称 RESTful 的服务并没有遵循基础的 REST 架构风格，也就是说，这些所谓的 RESTful 服务不过是通过 网络公开的 HTTP 服务。因此，开发团队必须花费大量时间来维护 RESTful 服务的一致性和纯度。

#### 为什么用grpc/grpc优点？

##### 提供高效的进程间通信 

gRPC 没有使用 JSON 或 XML 这样的文本化格式，而是使用 一个基于 protocol buffers 的二进制协议与 gRPC 服务和客户端通 信。同时，gRPC 在 HTTP/2 之上实现了 protocol buffers，从而能够 更快地处理进程间通信。这样一来，gRPC 就变成了最高效的进程 间通信技术之一。 具有简单且定义良好的服务接口和模式 gRPC 为应用程序开发提供了一种契约优先的方式。也就是 说，首先必须定义服务接口，然后才能去处理实现细节。因此，与 RESTful 服务定义中的 OpenAPI/Swagger 和 SOAP Web 服务中的 WSDL 不同，gRPC 提供了简单但一致、可靠且可扩展的应用程序 开发体验。 

##### 属于强类型 

因为使用 protocol buffers 来定义 gRPC 服务，所以 gRPC 服务 契约清晰定义了应用程序间进行通信所使用的类型。这样一来，在 构建跨多个团队和技术类型的云原生应用程序时，对于其所产生的 大多数运行时错误和互操作错误，可以通过静态类型来克服，因此 分布式应用程序的开发更加稳定。 

##### 支持多语言 

gRPC 支持多种编程语言。基于 protocol buffers 的服务定义是 语言中立的。因此，我们可以选择任意一种语言，它们都能与现有 的 gRPC 服务或客户端进行互操作。 

##### 支持双工流 

gRPC 在客户端和服务器端都提供了对流的原生支持，这些功 能都被整合到了服务定义本身之中。因此，开发流服务或流客户端 变得非常容易。与传统的 RESTful 服务消息风格相比，gRPC 的关 键优势就是能够同时构建传统的请求–响应风格的消息以及客户端 流和服务器端流。 

##### 具备内置的商业化特性 

gRPC 提供了对商业化特性的内置支持，如认证、加密、弹性 （截止时间和超时）、元数据交换、压缩、负载均衡、服务发现等 。

#####  与云原生生态系统进行了集成 

gRPC 是 CNCF 的一部分大多数现代框架和技术对 gRPC 提 供了原生支持。例如，CNCF 下的很多项目（如 Envoy）支持使用 gRPC 作为通信协议。另外，对于横切性的特性，比如度量指标和 监控，gRPC 也得到了大多数工具的支持，比如使用 Prometheus 来 监控 gRPC 应用程序。 

##### 业已成熟并被广泛采用

 通过在谷歌进行的大量实战测试，gRPC 已发展成熟。许多大 型科技公司采用了 gRPC，如 Square、Lyft、Netflix、Docker、 CoreOS 和思科等。 与其他技术一样，gRPC 也存在一定的劣势。在开发应用程序时， 了解这些方面非常有用。

#### gRPC 的劣势/缺点

##### gRPC 可能不太适合面向外部的服务 

大多数的外部消费者可能对 gRPC、REST 或 HTTP 等协议很 陌生。因此，如果希望将应用程序或服务通过互联网暴露给外部客 户端，gRPC 可能不是最适合的协议。

##### 巨大的服务定义变更是复杂的开发流程

在现代的服务间通信场景中，模式修改很常见。如果出现巨大 的 gRPC 服务定义变更，通常需要重新生成客户端代码和服务器端 代码。这需要整合到现有的持续集成过程中，可能会让整个开发生 命周期复杂化。但是，大多数 gRPC 服务定义的变更可以在不破坏 服务契约的情况下完成，而且只要不引入破坏性的变更，gRPC 就 可以与使用不同版本 proto 的客户端和服务器端进行交互。因此， 大多数情况并不需要重新生成代码。

##### gRPC 生态系统相对较小

与传统的 REST 或 HTTP 等协议相比，gRPC 的生态系统依然 相对较小。浏览器和移动应用程序对 gRPC 的支持依然处于初级阶 段。 在开发应用程序时，必须注意这些方面的问题。由此可以看到， gRPC 并不是适用于所有进程间通信需求的万能技术。相反，你需 要评估业务场景和需求，选择适当的消息协议。

#### grpc定义

RPC 框架的目标就是让远程服务调用更加简单、透明，**RPC 框架负责屏蔽底层的传输方式（TCP 或者 UDP）、序列化方式（XML/Json/ 二进制）和通信细节\**。\****服务调用者可以像调用本地接口一样调用远程的服务提供者，而不需要关心底层通信细节和调用过程。

gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计，HTTP/2 是一个高性能的二进制消息协议，支持双向的消息传递。

gRPC 是一项进程间通信技术，可以用来连接、调用、操作和调试分布式异构应用程序。就像调用本地函数一样，整个过程操作起来很简单。

gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特性。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。

#### grpc使用

##### 服务定义

gRPC 使用 protocol buffers 作为 IDL 来定义服务接口。protocol buffers 是语言中立、平台无关、实现结构化数据序列化的可扩展机制 。服务 接口定义在 proto 文件中指定，也就是在扩展名为“.proto”的普通文本文 件中。我们要按照普通的 protocol buffers 格式来定义 gRPC 服务，并将 RPC 方法参数和返回类型指定为 protocol buffers 消息。因为服务定义是 protocol buffers 规范的扩展，所以可以借助特殊的 gRPC 插件来根据 proto 文件生成代码。涉及远程方法调用、相关输入参数和输出 5 5 参数以及这些参数的类型定义。

##### gRPC服务器端

一旦服务定义准备就绪，就可以使用 protocol buffers 编译器 protoc 来生成服务器端和客户端的代码了。借助 gRPC 的 protocol buffers 插件，可 以生成 gRPC 服务器端代码、客户端代码以及常规的 protocol buffers 代 码，从而填充、序列化和检索消息类型。 在服务器端，需要实现该服务定义，并运行 gRPC 服务器来处理客户端 的调用。

因此，为了让服务器端的服务完成其任务，需 要先做以下两件事情。 

1. 通过重载服务基类，实现所生成的服务器端骨架的逻辑。 
2.  运行 gRPC 服务器，监听来自客户端的请求并返回服务响应。 要实现服务逻辑，首先要根据服务定义生成服务器端骨架。

##### gRPC客户端

与服务器端类似，可以使用服务定义生成客户端存根。客户端存根提供 了与服务器端类似的方法，供客户端代码进行调用。客户端存根会将这 些方法转换成对服务器端的远程函数网络调用。由于 gRPC 服务定义是 语言中立的，能够为所支持的任意语言（通过第三方实现）生成客户端 和服务器端，因此对于 ProductInfo 服务用例来说，虽然我们的服务 器端使用 Go 语言来实现，但是仍可以生成使用 Java 语言的客户端存 根。

##### 调用模型/调用过程/客户端–服务器端的消息流

在 RPC 系统中，服务器端会实现一组可以远程调用的方法。客户端会 生成一个存根，该存根为服务器端的方法提供抽象。这样一来，客户端 应用程序可以直接调用存根方法，进而调用服务器端应用程序的远程方 法。

1、客户端（gRPC Stub）调用 A 方法，发起 RPC 调用。（客户端进程通过生成的存根调用 getProduct 方法。客户端存根使用已编码的消息创建 HTTP POST 请求。在 gRPC 中，所有的请求都是 HTTP POST 请求，并且 content-type 前缀为 application/grpc。要调用的远程方法 （/ProductInfo/getProduct）是以单独的 HTTP 头信息的形式 发送的。）

2、对请求信息使用 Protobuf 进行对象序列化压缩（IDL），然后将其通过 HTTP/2 进行发送。

3、服务端（gRPC Server）接收到请求后，解码请求体，进行业务逻辑处理并返回，对应的 过程调用会使用 protocol buffers 来执行。（当接收到消息后，服务器端检查消息头信息，从而确定需要调用的 服务方法，然后将消息传递给服务器端骨架。）

4、对响应结果使用 Protobuf 进行对象序列化压缩（IDL）。（服务器端骨架将消息字节解析成特定语言的数据结构，借助解析后的消息，服务发起对 getProduct 方法的本地调用）

5、客户端接受到服务端响应，解码请求体。回调被调用的 A 方法，唤醒正在等待响应（阻塞）的客户端调用并返回响应结果。


#### Grpc原理
gRPC 通道代表一个到端点的连接，也就是一个 HTTP/2 连接。当客户端应用程序创建 gRPC 通道的时候，它会在幕后创建一个 到服务器端的 HTTP/2 连接。在通道创建完成之后，就可以重用它来发 送多个到服务器端的远程调用。这些远程调用会映射为 HTTP/2 中的 流。远程调用中的消息以 HTTP/2 帧的形式进行发送，帧可能会携带一 条 gRPC 长度前缀的消息，也可能在 gRPC 消息非常大的情况下，一条 消息跨多帧。
请求消息用于初始化远程调用。在 gRPC 中，请求消息始终由客户端应 用程序来触发，它包含 3 部分:请求头信息、以长度作为前缀的消息以 及流结束标记(end of stream flag，以下简称 EOS 标记)。远程调用在客户端发送请求头信息之后就会初始化，然后其中会发 送以长度作为前缀的消息，最后发送 EOS 标记，通知收件方请求消息 已发送。
响应消息由服务器端生成，用来响应客户端的请求。与请求消息类似， 在大多数场景中，响应消息也包含 3 个主要部分:响应头信息、以长度 作为前缀的消息以及 trailer。如果没有发送以长度作为前缀的消息来响 应客户端，则响应消息只会包含头信息和 trailer
#### 调用方式

##### Unary RPC：一元 RPC

server

- 创建 gRPC Server 对象，你可以理解为它是 Server 端的抽象对象。
- 将 SearchService（其包含需要被调用的服务端接口）注册到 gRPC Server。 的内部注册中心。这样可以在接受到请求时，通过内部的 “服务发现”，发现该服务端接口并转接进行逻辑处理。
- 创建 Listen，监听 TCP 端口。
- gRPC Server 开始 lis.Accept，直到 Stop 或 GracefulStop。

client

- 创建与给定目标（服务端）的连接句柄。
- 创建 SearchService 的客户端对象。
- 发送 RPC 请求，等待同步响应，得到回调后返回响应结果

##### #Server-side streaming RPC：服务端流式 RPC

##### Client-side streaming RPC：客户端流式 RPC

##### Bidirectional streaming RPC：双向流式 RPC

### 15.什么叫无状态、无连接协议

无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。

**Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接**。

HTTP无状态协议，是指协议对于事务处理没有记忆能力。 缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。 另一方面，在服务器不需要先前信息时它的应答就较快。

Cookie可以保持登录信息到用户下次与服务器的会话，换句话说，下次访问同一网站时，用户会发现不必输入用户名和密码就已经登录了，与 Cookie 相对的一个解决方案是 Session，它是通过服务器来保持状态的。

### 16.HTTP原理

HTTP协议（HyperText Transfer Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传送协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。

HTTP由请求和响应构成，是一个标准的客户端服务器模型（B/S）。HTTP协议永远都是客户端发起请求，服务器回送响应。

 HTTP是一个无状态的协议。无状态是指客户机（Web浏览器）和服务器之间不需要建立持久的连接，这意味着当一个客户端向服务器端发出请求，然后服务器返回响应(response)，连接就被关闭了，在服务器端不保留连接的有关信息.HTTP遵循请求(Request)/应答(Response)模型。客户机（浏览器）向服务器发送请求，服务器处理请求并返回适当的应答。所有HTTP连接都被构造成一套请求和应答。

#### Http工作流程

   1 ) 、地址解析，

   如用客户端浏览器请求这个页面：[http://localhost.com:8080/index.htm](http://localhost:8080/simple.htm)

   从中分解出协议名、主机名、端口、对象路径等部分，对于我们的这个地址，解析得到的结果如下：
   协议名：http
   主机名：localhost.com
   端口：8080
   对象路径：/index.htm

   在这一步，需要域名系统DNS解析域名localhost.com,得主机的IP地址。


  2）、封装HTTP请求数据包

   把以上部分结合本机自己的信息，封装成一个HTTP请求数据包


   3）封装成TCP包，建立TCP连接（TCP的三次握手）

​    在HTTP工作开始之前，客户机（Web浏览器）首先要通过网络与服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建Internet，即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。HTTP是比TCP更高层次的应用层协议，根据规则，只有低层协议建立之后才能进行更高层协议的连接，因此，首先要建立TCP连接，一般TCP连接的端口号是80。这里是8080端口

   4）客户机发送请求命令

​    建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URI：Uniform Resource Identifier）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可能的内容。

   5）服务器响应

   服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。

​    实体消息是服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此结束，接着，它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据

   6）服务器关闭TCP连接

   一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码

  Connection:keep-alive

  TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。

### Http请求方法

GET/POST/PUT/DELETE/TRACE/HEAD/OPTIONS

1、GET

GET是最常用的方法，通常用于请求服务器发送某个资源

![img](C:\Users\30839\Nutstore\1\我的坚果云\面试总结.assets\20180611174231275.png)

2、HEAD

HEAD方法和GET方法的行为很类似，但是服务器在响应中**只返回首部，不会返回实体的主体部分**。这就允许客户端在未获取实际资源的情况下，对资源的首部进行检查。

![img](C:\Users\30839\Nutstore\1\我的坚果云\面试总结.assets\20180611174642647.png)

3、PUT方法

PUT方法会向服务器写入文档。PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定

![img](https://img-blog.csdn.net/20180611174833636)

4、POST方法

POST方法期初是用来向服务器输入数据的，实际上，通常会用它来支持HTML的[表单](https://so.csdn.net/so/search?q=表单&spm=1001.2101.3001.7020)。表单中填好的数据通常会被送给服务器，然后由服务器将其发送到它要去的地方。

![img](C:\Users\30839\Nutstore\1\我的坚果云\面试总结.assets\20180612112603718.png)

> GET和POST的区别：
>
> 1、GET请求的数据是放在HTTP包头中的，也就是URL之后，通常是像下面这样定义格式的：login.action?name=hyddd&password=idontknow&verify=%E4%BD%E5%A5%BD其中，以?来分隔URL和数据；以&来分隔参数；如果数据是英文或数字，原样发送；如果数据是中文或其它字符，则进行BASE64编码。而Post是把提交的数据放在HTTP正文中的。
> 2、GET提交的数据比较少，最多1024B，因为GET数据是附在URL之后的，而URL则会受到不同环境的限制的，比如说IE对其限制为2K+35，而POST可以传送更多的数据（理论上是没有限制的，但一般也会受不同的环境，如浏览器、操作系统、服务器处理能力等限制，IIS4可支持80KB，IIS5可支持100KB）。
> 3、Post的安全性要比Get高，因为Get时，参数数据是明文传输的，参数直接暴露在url中，所以不能用来传递敏感信息。而且使用GET的话，还可能造成Cross-site request forgery攻击。而POST数据则可以加密的，但GET的速度可能会快些。
> 4、get请求只能进行url编码，而post支持多种编码方式；get请求会浏览器主动cache，而post支持多种编码方式；get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。
> 5、GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。
> 6、GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。

5、TRACE方法

​		客户端发起一个请求时，这个请求可能要穿过防火墙、代理、网关或者其他一些应用程序。每个中间节点都可能会修改原始的HTTP请求。TRACE方法允许客户端在最终将请求发送给服务器时，看看它变成什么样子了。
​        TRACE请求会在目的服务器端发起一个“环回”诊断。行程最后一站的服务器会弹回一条TRACE响应，并在响应主体中携带它收到的原始请求报文。这样客户端就可以查看在所有中间HTTP应用程序组成的请求/响应链上，原始报文是否被毁坏，以及如何被毁坏或修改过。

![img](https://img-blog.csdn.net/20180612115414980)

https://blog.csdn.net/vikeyyyy/article/details/80655115

### Http中Header的内容

```
GET /access/loadUserByRole?role=bm HTTP/1.1
User-Agent: PostmanRuntime/7.29.0 #用户信息
Accept: */* #指定客户端能够接收的内容类型
Cache-Control: no-cache
Postman-Token: c158f4a3-b7ca-49d8-98b7-1c15c3415f4c
Host: 192.168.31.250:58080 #指定请求的服务器域名和端口号
Accept-Encoding: gzip, deflate, br
Connection: keep-alive # 默认使用长连接

HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked
Date: Sat, 16 Apr 2022 12:23:42 GMT
Keep-Alive: timeout=60
Connection: keep-alive

[{"uid":2,"username":"红"},{"uid":4,"username":"2345"},{"uid":5,"username":"360"},{"uid":7,"username":"蓝"}]
```



### 17.**为什么post是两个tcp包呢？**

post先去检测一下服务器是否能正常应答，然后再把data携带过去，如果应答不了，就没有了第二步数据传输。 就好像送快递的先打个电话给你看看你在不在家，在的话再送过去，以免不必要的资源浪费。

### 19.网络传输的数据流类型有哪些？

字节流和字符流

### 20.Http1.0与2.0区别

**HTTP/1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接**，服务器不跟踪每个客户也不记录过去的请求。

HTTP/1.0中浏览器与服务器只保持短暂的连接，连接无法复用。也就是说每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。

为了解决HTTP/1.0存在的缺陷，HTTP/1.1于1999年诞生。相比较于HTTP/1.0来说，最主要的改进就是引入了持久连接。所谓的持久连接即**TCP连接默认不关闭，可以被多个请求复用**。

HTTP/1.1版还引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。

HTTP/2 是 HTTP 协议自 1999 年 HTTP 1.1 发布后的首个更新，主要基于 SPDY 协议。HTTP/2 为了解决HTTP/1.1中仍然存在的效率问题，HTTP/2 采用了**多路复用**。即在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应。能这样做有一个前提就是HTTP/2进行了**二进制分帧**，即 HTTP/2 会将所有传输的信息分割为更小的消息和帧（frame）,并对它们采用二进制格式的编码.

### HTTP1.0和HTTP1.1差异

- **连接方式** : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。
- **状态响应码** :     HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，100     (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址。
- **缓存处理** : 在 HTTP1.0 中主要使用 header 里的     If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity     tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
- **带宽优化及网络连接的使用** :HTTP1.0     中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1     则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial     Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- **Host头处理** : HTTP/1.1在请求头中加入了Host字段。

### TCP为什么可靠/维持连接稳定性

1、TCP保持首部和数据的校验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

2、流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）

3、拥塞控制：当网络拥塞时，减少数据的发送。

4、ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。

5、超时重传：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### TCP拥塞控制

产生拥塞的原因：在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就会变坏。

注意**拥塞控制**与**流量控制**的区别：拥塞控制是防止过多的数据注入网络中，使得网络中路由器或链路不致于过载，有一个前提是，网络能够承受现有的网络负荷，是一个**全局性**过程；流量控制是指点对点通信的控制，做的是抑制发送端发送数据的速率，便于接收端来得及接收。

##### TCP拥塞控制的方法

主要有四种方法：**慢开始、拥塞避免、快重传、快恢复**

![img](https://img2020.cnblogs.com/blog/1131060/202109/1131060-20210908154428850-491612222.jpg)

慢开始和拥塞避免

在发送方维护一个**拥塞窗口**（cwnd），大小等于发送窗口，通过出现了**超时**来判断网络出现拥塞。慢开始的思路是一开始发送方发送一个字节，在收到接收方的确认，然后发送的字节数量增大一倍（也就是按照**指数**增长的速率），从小到大逐步增大cwnd，直到cwnd 达到**慢开始门限**（ssthresh），停止慢开始算法，使用拥塞避免算法，拥塞避免算法思路是增长速率变为**线性**增长，也就是每经过一个往返时间RTT就把发送方的cwnd加1.

快重传和快恢复

通过上面两个算法可以使得网络传输速率一直增大，直到出现超时，这时候需要将cwnd重新调整到1个字节开始，使用慢开始算法，同时需要将慢开始门限ssthresh调整为cwnd（超时点）的一半，继续执行慢开始、拥塞避免算法。如果收到**3-ACK**（发送方一连接收到3个对同一个报文段的重复确认），这种可能的情况是，并不是发生了拥塞，可能是报文丢失，所以发送方不执行慢开始算法，直接使用快重传算法，立即发送缺失的报文段。同时执行快恢复算法，将门限值（ssthresh）调整为此时cwnd的一半，并执行拥塞避免算法。

### TCP流量控制

TCP流量控制使用的是滑动窗口实现的。滑动窗口就是防止发送方发的太快，耗尽接收方的资源，从而使接收方来不及处理。

在确认应答策略中，对每一个发送的数据段，都要给一个ACK确认应答，收到ACK后再发送下一个数据段，这样做有一个比较大的缺点，就是`性能比较差`，尤其是数据往返的时间长的时候

> 使用滑动窗口，就可以一次发送多条数据，从而就提高了性能

（1）接收端将自己可以接收的缓冲区大小放入TCP首部中的“窗口大小”字段，通过ACK来通知发送端
（2）窗口大小字段越大，说明网络的吞吐率越高
（3）窗口大小指的是无需等待确认应答而可以继续发送数据的最大值，即就是说不需要接收端的应答，可以一次连续的发送数据
（4）操作系统内核为了维护滑动窗口，需要开辟发送缓冲区，来记录当前还有那些数据没有应答，只有确认应答过的数据，才能从缓冲区删掉

（5）接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值通知给发送端，发送端收到这个值后，就会减慢自己的发送速度
（6）如果接收端发现自己的缓冲区满了，就会将窗口的大小设置为0，此时发送端将不再发送数据，但是需要定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端
ps：在TCP的首部中，有一个16为窗口字段，此字段就是用来存放窗口大小信息的

### 服务器状态码

#### **2XX——表明请求被正常处理了**

 

1、200 OK：请求已正常处理。

 

2、204 No Content：请求处理成功，但没有任何资源可以返回给客户端，一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。

 

3、206 Partial Content：是对资源某一部分的请求，该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。响应报文中包含由Content-Range指定范围的实体内容。

 

#### 3XX——表明浏览器需要执行某些特殊的处理以正确处理请求

 

4、301 Moved Permanently：资源的uri已更新，你也更新下你的书签引用吧。永久性重定向，请求的资源已经被分配了新的URI，以后应使用资源现在所指的URI。

 

5、302 Found：资源的URI已临时定位到其他位置了，姑且算你已经知道了这个情况了。临时性重定向。和301相似，但302代表的资源不是永久性移动，只是临时性性质的。换句话说，已移动的资源对应的URI将来还有可能发生改变。

 

6、303 See Other：资源的URI已更新，你是否能临时按新的URI访问。该状态码表示由于请求对应的资源存在着另一个URL，应使用GET方法定向获取请求的资源。303状态码和302状态码有着相同的功能，但303状态码明确表示客户端应当采用GET方法获取资源，这点与302状态码有区别。

 

当301,302,303响应状态码返回时，几乎所有的浏览器都会把POST改成GET，并删除请求报文内的主体，之后请求会自动再次发送。

 

7、304 Not Modified：资源已找到，但未符合条件请求。该状态码表示客户端发送附带条件的请求时（采用GET方法的请求报文中包含If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since中任一首部）服务端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304.。

 

8、307 Temporary Redirect：临时重定向。与302有相同的含义。

 

#### 4XX——表明客户端是发生错误的原因所在。

 

9、400 Bad Request：服务器端无法理解客户端发送的请求，请求报文中可能存在语法错误。

 

10、401 Unauthorized：该状态码表示发送的请求需要有通过HTTP认证（BASIC认证，DIGEST认证）的认证信息。

 

11、403 Forbidden：不允许访问那个资源。该状态码表明对请求资源的访问被服务器拒绝了。（权限，未授权IP等）

 

12、404 Not Found：服务器上没有请求的资源。路径错误等。

 

#### 5XX——服务器本身发生错误

 

13、500 Internal Server Error：貌似内部资源出故障了。该状态码表明服务器端在执行请求时发生了错误。也有可能是web应用存在bug或某些临时故障。

 

14、503 Service Unavailable：抱歉，我现在正在忙着。该状态码表明服务器暂时处于超负载或正在停机维护，现在无法处理请求。

### CLOSE_WAIT状态产生的原因

服务器处于close_wait状态，说明套接字是被动关闭的。

### 单台服务器可以支持并发连接数

如何标识一个链接，操作系统通过四元组标识一个TCP链接

{本地ip，本地port，远程ip，远程port}

当四元组有一个元素不同时，就是不同的链接。

在linux系统中，一个链接占用一个文件句柄，默认链接数目最大为1024，但是真实情况下，一般这个数字都会很大。

**对于链接发起方**

操作系统有65535个端口，其中0~1024为预留端口，不可使用其他都可以使用，也就是说：**在链接发起端，受端口号的限制理论上最多可以创建64000左右链接。**

同时我们可以增加IP地址，一般来说一个网卡只绑定一个IP地址，但是实际上一个网卡可以绑定多个IP地址，就可以是实现超过64000个链接

**对于链接接收端**

**最大的TCP链接数=所有有效ip排列组合的数量\*端口数量64000**

 

**实际情况下，每创建一个链接需要消耗一定的内存，大概是4-10kb，所以链接数也受限于机器的总内存。(链接发起端,活力全开才64000左右链接，内存最多才占用640M，一般客户端都能 满足；内存限制主要还是考虑服务器端)**

### Linux服务器 大量的CLOSE_WAIT、TIME_WAIT解决办法？

https://coolshell.cn/articles/22263.html

#### TIME_WAIT
是主动关闭连接的一方保持的状态，对于服务器来说它本身就是“客户端”，在完成一个爬取任务/被探活检测之后，它就会发起主动关闭连接，从而进入TIME_WAIT的状态，然后在保持这个状态2MSL（max segment lifetime）时间之后，彻底关闭回收资源。为什么要这么做？明明就已经主动关闭连接了为啥还要保持资源一段时间呢？这个是TCP/IP的设计者规定的，主要出于以下两个方面的考虑：

1.防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）。
假设目前连接的通信双方都调用了close(),双方同时进入closed的终结状态，而没有走 time_wait状态。则会出现如下问题：假如现在有一个新的连接建立起来，使用的IP地址与之前的端口完全相同，现在建立的一个连接是之前连接的完全复用，我们还假定之前连接中有数据报残存在网络之中，这样的话现在的连接收到的数据有可能是之前连接的报文。为了防止这一点。TCP不允许新的连接复用time_wait状态下的socket。处于time_wait状态的socket在等待2MSL时间后（之所以是两倍的MSL，是由于MSL是一个数据报在网络中单向发出 到认定丢失的时间，即(Maximum Segment Lifetime)报文最长存活时间，一个数据报有可能在发送途中或是其响应过程中成为残余数据报，确认一个数据报及其响应的丢弃需要两倍的MSL），将会转为closed状态。这就意味着，一个成功建立的连接，必须使得之前网络中残余的数据报都丢失了。

2.可靠的关闭TCP连接。在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。另外这么设计TIME_WAIT 会定时的回收资源，并不会占用很大资源的，除非短时间内接受大量请求或者受到攻击。

解决方案很简单：

- 把这个超时间调小一些，这样就可以把TCP 的端口号回收的快一些。但是也不能太小，如果流量很大的话，TIME_WAIT一样会被耗尽。
- 设置上 `tcp_tw_reuse` 。[RFC 1323](https://tools.ietf.org/html/rfc1323)提出了一组 TCP 扩展来提高高带宽路径的性能。除其他外，它定义了一个新的 TCP 选项，带有两个四字节**时间戳字段**。第一个是发送选项的 TCP 时间戳的当前值，而第二个是从远程主机接收到的最新时间戳。如果新时间戳严格大于为前一个连接记录的最新时间戳。Linux 将重用该状态下的现有 `TIME_WAIT` 连接用于**出站的链接**。也就是说，**这个参数对于入站连接是没有任何用图的。**
- 设置上 `tcp_tw_recycle` 。 这个参数同样依赖于时间戳选项，但会影响进站和出站链接。这个参数会影响NAT环境，也就是一个公司里的所有员工用一个IP地址访问外网的情况。在这种情况下，时间戳条件将禁止在这个公网IP后面的所有设备在一分钟内连接，因为它们不共享相同的时间戳时钟。毫无疑问，禁用此选项要好得多，因为它会导致 **难以检测**和**诊断**问题。（注：从 Linux 4.10 (commit [95a22caee396](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=95a22caee396cef0bb2ca8fafdd82966a49367bb) ) 开始，Linux 将为每个连接随机化时间戳偏移量，从而使该选项完全失效，无论有无NAT。它已从 Linux 4.12中完全删除）

2.**不作死就不会死，也就是说，服务器不要主动断链接，而设置上KeepAlive后，让客户端主动断链接，这样服务端只会有`CLOSE_WAIT`**。

3.在客户端上可以使用 `tcp_tw_reuse` 和 `SO_LINGER(0)`。

4.Socket的参数，叫 <code>SO_LINGER，这个参数主要是为了延尽关闭来用的，也就是说你应用调用 `close()`函数时，如果还有数据没有发送完成，则需要等一个延时时间来让数据发完，但是，如果你把延时设置为 0  时，Socket就丢弃数据，并向对方发送一个 `RST` 来终止连接，因为走的是 RST 包，所以就不会有 `TIME_WAIT` 了。

这个东西在服务器端永远不要设置，不然，你的客户端就总是看到 TCP 链接错误 “connnection reset by peer”，但是这个参数对于 EaseProbe 的客户来说，简直是太完美了，当EaseProbe 探测完后，直接 reset connection， 即不会有功能上的问题，也不会影响服务器，更不会有烦人的 `TIME_WAIT` 问题。

在 Golang的标准库代码里，`net.TCPConn` 有个方法 `SetLinger()`可以完成这个事，使用起来也比较简单

#### CLOSE_WAIT
TCP协议规定，对于已经建立的连接，网络双方要进行四次握手才能成功断开连接，如果缺少了其中某个步骤，将会使连接处于假死状态，连接本身占用的资源不会被释放。网络服务器程序要同时管理大量连接，所以很有必要保证无用连接完全断开，否则大量僵死的连接会浪费许多服务器资源.

TIME_WAIT状态可以通过优化服务器参数得到解决，因为发生TIME_WAIT的情况是服务器自己可控的，要么就是对方连接的异常，要么就是自己没有迅速回收资源，总之不是由于自己程序错误导致的。

但是CLOSE_WAIT就不一样了，如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。个人觉得这种情况，通过服务器内核参数也没办法解决，服务器对于程序抢占的资源没有主动回收的权利，除非终止程序运行。

解决方法：

关闭正在运行的程序，这个需要视业务情况而定。
尽快的修改程序里的bug，然后测试提交到线上服务器
#### 什么情况下，连接处于CLOSE_WAIT状态呢？
在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。通常来讲，CLOSE_WAIT状态的持续时间应该很短，正如SYN_RCVD状态。但是在一些特殊情况下，就会出现连接长时间处于CLOSE_WAIT状态的情况。

出现大量close_wait的现象，主要原因是某种情况下对方关闭了socket链接，但是我方忙与读或者写，没有关闭连接。代码需要判断socket，一旦读到0，断开连接，read返回负，检查一下errno，如果不是AGAIN，就断开连接。

### csrf与xss
#### CSRF
基本概念、缩写、全称：CSRF(Cross-site request forgery)：跨站请求伪造。
#### CSRF的攻击原理

用户是网站A的注册用户，且登录进去，于是网站A就给用户下发cookie。从上图可以看出，要完成一次CSRF攻击，受害者必须满足两个必要的条件：
（1）登录受信任网站A，并在本地生成Cookie。（如果用户没有登录网站A，那么网站B在诱导的时候，请求网站A的api接口时，会提示你登录）
（2）在不登出A的情况下，访问危险网站B（其实是利用了网站A的漏洞）。
注意cookie保证了用户可以处于登录状态，但网站B其实拿不到cookie。

#### CSRF的危害?-发消息(蠕虫)+转账(丢钱)+盗号
攻击者能够欺骗受害用户完成该受害者所允许的任一状态改变的操作，CRSF能做的事情包括利用你的身份发邮件、发短信、进行交易转账等，甚至盗取你的账号，更新账号细节，完成购物，注销甚至登录等操作，获取用户的隐私数据，配合其他漏洞攻击CSRF蠕虫指产生蠕虫效果，会将 CSRF 攻击一传十，十传百。
#### CSRF如何防御
（1）方法1、将cookie设置为HttpOnly
CRSF攻击很大程度上是利用了浏览器的cookie，为了防止站内的XSS漏洞盗取cookie,需要在cookie中设置“HttpOnly”属性，这样通过程序（如JavaScript脚本、Applet等）就无法读取到cookie信息，避免了攻击者伪造cookie的情况出现。设置cookie为HttpOnly的代码如下：response.setHeader( "Set-Cookie", "cookiename=cookievalue;HttpOnly");

（2）方法2、Token 验证(用的最多)：攻击者可以伪造用户的请求，该请求中所有的用户验证信息都存在于cookie中，因此攻击者可以在不知道用户验证信息的情况下直接利用用户的cookie来通过安全验证。在请求中放入攻击者所不能伪造的信息，并且该信总不存在于cookie之中。服务器发送给客户端一个token；客户端提交的表单中带着这个token；如果这个token不合法，那么服务器拒绝这个请求。
（3）方法3、隐藏令牌：把token隐藏在http的head头中。方法二和方法一有点像，本质上没有太大区别，只是使用方式上有区别。
（4）方法4、Referer验证：
#### XSS
XSS的基本概念：XSS（Cross Site Scripting）：跨域脚本攻击。
XSS攻击原理：不需要你做任何的登录认证，它会通过合法的操作（比如在url中输入、在评论框中输入），向你的页面注入脚本（可能是js、hmtl代码块等）
XSS攻击后果：盗用Cookie破坏页面的正常结构，插入广告等恶意内容D-doss攻击

XSS的攻击方式，具体详见：反射型XSS漏洞的条件+类型+危害+解决
a. 反射型：发出请求时，XSS代码出现在url中，作为输入提交到服务器端，服务器端解析后响应，XSS代码随响应内容一起传回给浏览器，最后浏览器解析执行XSS代码。这个过程像一次反射，所以叫反射型XSS。
b.存储型：存储型XSS和反射型XSS的差别在于，提交的代码会存储在服务器端（数据库、内存、文件系统等），下次请求时目标页面时不用再提交XSS代码。

XSS的防范措施（encode+过滤）
XSS的防范措施主要有三个：编码、过滤、校正
1、编码：对用户输入的数据进行HTML Entity 编码。把字符转换成 转义字符。Encode的作用是将$var等一些字符进行转化，使得浏览器在最终输出结果上是一样的。
比如说这段代码：<script>alert(1)</script>
若不进行任何处理，则浏览器会执行alert的js操作，实现XSS注入。进行编码处理之后，L在浏览器中的显示结果就是这个文本，将变量作为纯文本进行输出，且不引起JavaScript的执行。

2、过滤：移除用户输入的和事件相关的属性。如onerror可以自动触发攻击，还有onclick等。（总而言是，过滤掉一些不安全的内容）移除用户输入的Style节点、Script节点、Iframe节点。（尤其是Script节点，它可是支持跨域的呀，一定要移除）。

3、校正：避免直接对HTML Entity进行解码。使用DOM Parse转换，校正不配对的DOM标签。(DOM Parse：它的作用是把文本解析成DOM结构)
常见2种方法：a.第一步的编码转成文本，然后第三步转成DOM对象，然后经过第二步的过滤。 b.还有一种更简洁：首先是encode，如果是富文本，就白名单。
#### CSRF 和 XSS 的区别
1、CSRF是跨站请求伪造;  XSS是跨域脚本攻击。
2、CSRF需要用户先登录网站A,获取cookie;  XSS不需要登录。
3、CSRF是利用网站A本身的漏洞,去请求网站A的api;  XSS是向网站A注入JS代码,然后执行JS里的代码,篡改网站A的内容。（XSS利用的是站点内的信任用户，而CSRF则是通过伪装来自受信任用户的请求来利用受信任的网站。你可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义向第三方网站发送恶意请求。）

### TCP粘包

#### 为什么要将数据切片

网络比喻为一个水管，是有一定的**粗细**的，这个粗细由**网络接口层（数据链路层）**提供给**网络层**，一般认为是的`MTU`（1500），直接传入整个消息，会超过水管的最大承受范围，那么，就需要进行切片，成为一个个数据包，这样消息才能正常通过“水管”。

#### MTU 和 MSS 有什么区别

- **MTU: Maximum Transmit Unit**，最大传输单元。 由**网络接口层（数据链路层）**提供给**网络层**最大一次传输数据的大小；一般 MTU=**1500 Byte**。 假设IP层有 <= 1500 byte 需要发送，只需要一个 IP 包就可以完成发送任务；假设 IP 层有> 1500 byte 数据需要发送，需要分片才能完成发送，分片后的 IP Header ID 相同。
- **MSS：Maximum Segment Size** 。 TCP 提交给 IP 层最大分段大小，不包含 TCP Header 和 TCP Option，只包含 TCP Payload ，MSS 是 TCP 用来限制应用层最大的发送字节数。 假设 MTU= 1500 byte，那么 **MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte**，如果应用层有 **2000 byte** 发送，那么需要两个切片才可以完成发送，第一个 TCP 切片 = 1460，第二个 TCP 切片 = 540。

#### 什么是粘包

那么当李东在手机上键入"李东""亚健康终结者"的时候，在 TCP 中把消息分成 MSS 大小后，消息顺着网线顺利发出。网络稳得很，将消息分片传到了对端手机 B 上。经过 TCP 层消息重组。变成"李东亚健康终结者"这样的**字节流（stream）**。经过他的代码，在处理**字节流**的时候消息从"李东"，"亚健康终结者"变成了"李东亚"，"健康终结者"。"李东"作为上一个包的内容与下一个包里的"亚"粘在了一起被错误地当成了一个数据包解析了出来。这就是所谓的**粘包**。

#### 为什么会出现粘包

**TCP，Transmission Control Protocol**。传输控制协议，是一种面向连接的、可靠的、基于**字节流**的传输层通信协议。字节流可以理解为一个双向的通道里流淌的数据，这个**数据**其实就是我们常说的二进制数据，简单来说就是一大堆 01 串。这些 01 串之间**没有任何边界**。应用层传到 TCP 协议的数据，不是以**消息报为单位**向目的主机发送，而是以**字节流**的方式发送到下游，这些数据可能被**切割和组装**成各种数据包，接收端收到这些数据包后没有正确还原原来的消息，因此出现粘包现象。

#### 怎么处理粘包

粘包出现的根本原因是不确定**消息的边界**。接收端在面对**"无边无际"的二进制流**的时候，根本不知道收了多少 01 才算**一个消息**。一不小心拿多了就说是**粘包**。其实粘包根本不是 TCP 的问题，是使用者对于 TCP 的理解有误导致的一个问题。只要在发送端每次发送消息的时候给消息**带上识别消息边界的信息**，接收端就可以根据这些信息识别出消息的边界，从而区分出每个消息。

##### 加入特殊标志

可以通过特殊的标志作为头尾，比如当收到了`0xfffffe`或者回车符，则认为收到了新消息的头，此时继续取数据，直到收到下一个头标志`0xfffffe`或者尾部标记，才认为是一个完整消息。类似的像 HTTP 协议里当使用 **chunked 编码** 传输时，使用若干个 chunk 组成消息，最后由一个标明长度为 0 的 chunk 结束。

##### 加入消息长度信息

在收到头标志时，里面还可以带上消息长度，以此表明在这之后多少 byte 都是属于这个消息的。如果在这之后正好有符合长度的 byte，则取走，作为一个完整消息给应用层使用。在实际场景中，HTTP 中的`Content-Length`就起了类似的作用，当接收端收到的消息长度小于 Content-Length 时，说明还有些消息没收到。那接收端会一直等，直到拿够了消息或超时

#### UDP 会粘包吗

UDP 是基于数据报的传输协议，不会有粘包问题。

基于**数据报**是指无论应用层交给 UDP 多长的报文，UDP 都照样发送，即一次发送一个报文。至于如果数据包太长，需要分片，那也是IP层的事情，大不了效率低一些。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。而接收方在接收数据报的时候，也不会像面对 TCP 无穷无尽的二进制流那样不清楚啥时候能结束

##### 为什么长度字段冗余还要加到 UDP 首部中

如果这时候 UDP 头不含 UDP 长度信息，那么应用层应该取多少数据才算完整的一个数据报呢？

因此 UDP 头的这个长度其实跟 TCP 为了防止粘包而在消息体里加入的边界信息是起一样的作用的。

#### IP 层有粘包问题吗

IP 层也切片，但是因为不关心消息里有啥，因此有不会有粘包问题。

- 如果消息过长，`IP层`会按 **MTU 长度**把消息分成 **N 个切片**，每个切片带有自身在**包里的位置（offset）**和**同样的IP头信息**。
- 各个切片在网络中进行传输。每个数据包切片可以在不同的路由中流转，然后**在最后的终点汇合后再组装**。
- 在接收端收到第一个切片包时会申请一块新内存，创建IP包的数据结构，等待其他切片分包数据到位。
- 等消息全部到位后就把整个消息包给到上层（传输层）进行处理。

可以看出整个过程，`IP 层`从按长度切片到把切片组装成一个数据包的过程中，都只管运输，都不需要在意消息的边界和内容，都不在意消息内容了，那就不会有粘包一说了。

`IP 层`表示：我只管把发送端给我的数据传到接收端就完了，我也不了解里头放了啥东西。

### TCP保活功能

如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：

1. 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。
2. 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。
3. 客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。
4. 客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。

TCP保活功能主要为探测长连接的存活状况，不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。

#### TCP中已有SO_KEEPALIVE选项，为什么还要在应用层加入心跳包机制?

因为TCP协议中的SO_KEEPALIVE有几个致命的缺陷：

1. keepalive只能检测连接是否存活，不能检测连接是否可用。比如服务器因为负载过高导致无法响应请求但是连接仍然存在，此时keepalive无法判断连接是否可用。
2. 如果TCP连接中的另一方因为停电突然断网，我们并不知道连接断开，此时发送数据失败会进行重传，由于重传包的优先级要高于keepalive的数据包，因此keepalive的数据包无法发送出去。只有在长时间的重传失败之后我们才能判断此连接断开了。

### TCP心跳检测

所谓的心跳包就是客户端定时发送简单的信息给服务器端告诉它我还在而已。代码就是每隔几分钟发送一个固定信息给服务端，服务端收到后回复一个固定信息如果服务端几分钟内没有收到客户端信息则视客户端断开。比如有些通信软件长时间不使用，要想知道它的状态是在线还是离线就需要心跳包，定时发包收包。发包方：可以是客户也可以是服务端，看哪边实现方便合理。一般是客户端。服务器也可以定时轮询发心跳下去。[心跳包](https://baike.baidu.com/item/心跳包)之所以叫心跳包是因为：它像心跳一样每隔固定时间发一次，以此来告诉服务器，这个客户端还活着。事实上这是为了保持[长连接](https://baike.baidu.com/item/长连接)，至于这个包的内容，是没有什么特别规定的，不过一般都是很小的包，或者只包含包头的一个空包。

在TCP的机制里面，本身是存在有心跳包的机制的，也就是TCP的选项。系统默认是设置的是2小时的心跳频率。但是它检查不到机器断电、网线拔出、防火墙这些断线。而且逻辑层处理断线可能也不是那么好处理。一般，如果只是用于保活还是可以的。心跳包一般来说都是在逻辑层发送空的包来实现的。下一个定时器，在一定时间间隔下发送一个空包给客户端，然后客户端反馈一个同样的空包回来，服务器如果在一定时间内收不到客户端发送过来的反馈包，那就只有认定说掉线了。只需要[send](https://baike.baidu.com/item/send/13483552)或者recv一下，如果结果为零，则为掉线。

但是，在[长连接](https://baike.baidu.com/item/长连接)下，有可能很长一段时间都没有数据往来。理论上说，这个连接是一直保持连接的，但是实际情况中，如果中间节点出现什么故障是难以知道的。更要命的是，有的节点（[防火墙](https://baike.baidu.com/item/防火墙)）会自动把一定时间之内没有数据交互的连接给断掉。在这个时候，就需要我们的[心跳包](https://baike.baidu.com/item/心跳包)了，用于维持长连接，保活。在获知了断线之后，服务器逻辑可能需要做一些事情，比如断线后的[数据清理](https://baike.baidu.com/item/数据清理)呀，重新连接呀当然，这个自然是要由逻辑层根据需求去做了。总的来说，心跳包主要也就是用于长连接的保活和断线处理。一般的应用下，判定时间在30-40秒比较不错。如果实在要求高，那就在6-9秒。

## 操作系统

https://www.iamshuaidi.com/1346.html

### Linux故障排查之CPU占用率过高

首先我们需要先top确定一下那个进程占用CPU最高。执行命令top

然后我们需要知道这个进程有哪些线程，又是哪个线程在占用大量CPU（科普一下：线程是进程的单位，一个进程是由若干线程组成的）。执行命令top -Hp 8104

还需要知道这个线程的ID转换为16进制的线程是多少

接着我们再使用jstack 8104|grep "1fdb" -A 30查看具体的进程信息。解释一下jstack是Prints Java thread stack traces for a Java process, core file, or remote debug server。至于grep -A 30则是显示(上下文，也就是上下行)下文30条相关的语句

### Linux 查看端口占用情况

```
lsof -i:端口号
```

**netstat -tunlp** 用于显示 tcp，udp 的端口和进程等相关情况。

```
netstat -n tlp   //查看当前所有tcp端口
netstat -n tulp | grep 80   //查看所有80端口使用情况
netstat -n tulp | grep 3306   //查看所有3306端口使用情况
```

### 多进程与多线程应用场景？

#### 原则

1）需要频繁创建销毁的优先用线程

这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的

2）需要进行大量计算的优先使用线程
多线程模型适用于I/O密集型的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。

所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。

这种原则最常见的是图像处理、算法处理。

3）强相关的处理用线程，弱相关的处理用进程

什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。

一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。

当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。

4）可能要扩展到多机分布的用进程，多核分布的用线程

同时，多线程模型也适用于单机多核分布式场景。

多进程模型，适用于CPU密集型。同时，多进程模型也适用于多机分布式场景中，易于多机扩展。
5）都满足需求的情况下，用你最熟悉、最拿手的方式
#### 多进程应用场景
nginx主流的工作模式是多进程模式（也支持多线程模型）
几乎所有的web server服务器服务都有多进程的，至少有一个守护进程配合一个worker进程，例如apached,httpd等等以d结尾的进程包括init.d本身就是0级总进程，所有你认知的进程都是它的子进程；
chrome浏览器也是多进程方式。 （原因：①可能存在一些网页不符合编程规范，容易崩溃，采用多进程一个网页崩溃不会影响其他网页；而采用多线程会。②网页之间互相隔离，保证安全，不必担心某个网页中的恶意代码会取得存放在其他网页中的敏感信息。）
redis也可以归类到“多进程单线程”模型（平时工作是单个进程，涉及到耗时操作如持久化或aof重写时会用到多个进程）

#### 多线程应用场景
线程间有数据共享，并且数据是需要修改的（不同任务间需要大量共享数据或频繁通信时）。
提供非均质的服务（有优先级任务处理）事件响应有优先级。
单任务并行计算，在非CPU Bound的场景下提高响应速度，降低时延。
与人有IO交互的应用，良好的用户体验（键盘鼠标的输入，立刻响应）

#### 多进程的优点：
①编程相对容易；通常不需要考虑锁和同步资源的问题。
②更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。
③有内核保证的隔离：数据和错误隔离。 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。

#### 多线程的优点：
①创建速度快，方便高效的数据共享
共享数据：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术。
②较轻的上下文切换开销 - 不用切换地址空间，不用更改寄存器，不用刷新TLB。
③提供非均质的服务。如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降低“简单任务被复杂任务压住”的概率。

### 硬链接和软连接
硬链接和源文件的inode节点号相同，两者互为硬链接。软连接和源文件的inode节点号不同，进而指向的block也不同，软连接block中存放了源文件的路径名。 实际上，硬链接和源文件是同一份文件，而软连接是独立的文件，类似于快捷方式，存储着源文件的位置信息便于指向。 使用限制上，不能对目录创建硬链接，不能对不同文件系统创建硬链接，不能对不存在的文件创建硬链接；可以对目录创建软连接，可以跨文件系统创建软连接，可以对不存在的文件创建软连接。
### 堆和栈的区别
  1、栈区（stack）—   由编译器自动分配释放   ，存放函数的参数值，局部变量的值等。其 
  操作方式类似于数据结构中的栈。 
  2、堆区（heap）   —   一般由程序员分配释放，   若程序员不释放，程序结束时可能由OS回 
  收   。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。 
  3、全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的 
  全局变量和静态变量在一块区域，   未初始化的全局变量和未初始化的静态变量在相邻的另 
  一块区域。   -   程序结束后由系统释放。 
  4、文字常量区   —常量字符串就是放在这里的。   程序结束后由系统释放 
  5、程序代码区—存放函数体的二进制代码。
#### 申请方式    
  stack:    
  由系统自动分配。   例如，声明在函数中一个局部变量   int   b;   系统自动在栈中为b开辟空间    
  heap:    
  需要程序员自己申请，并指明大小，在c中malloc函数    
  如p1   =   (char   *)malloc(10);    
  在C++中用new运算符    
  如p2   =   new   char[10];    
  但是注意p1、p2本身是在栈中的。    
     
#### 申请后系统的响应    
  栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢  
  出。    
  堆：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，  
  会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表  
  中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的  
  首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。  
  另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部  
  分重新放入空闲链表中。    

#### 申请大小的限制    
  栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意  
  思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有  
  的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将  
  提示overflow。因此，能从栈获得的空间较小。    
  堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储  
  的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小  
  受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。    

#### 申请效率的比较：    
  栈由系统自动分配，速度较快。但程序员是无法控制的。    
  堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.    
  另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是  
  直接在进程的地址空间中保留一块内存，虽然用起来最不方便。但是速度快，也最灵活。  

#### 堆和栈中的存储内容    
  栈：   在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可  
  执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈  
  的，然后是函数中的局部变量。注意静态变量是不入栈的。    
  当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地  
  址，也就是主函数中的下一条指令，程序由该点继续运行。    
  堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容由程序员安排。    

#### 存取效率的比较    

  char   s1[]   =   "aaaaaaaaaaaaaaa";    
  char   *s2   =   "bbbbbbbbbbbbbbbbb";    
  aaaaaaaaaaa是在运行时刻赋值的；    
  而bbbbbbbbbbb是在编译时就确定的；    
  但是，在以后的存取中，在栈上的数组比指针所指向的字符串(例如堆)快。    
  比如：    
  #include    
  void   main()    
  {    
  char   a   =   1;    
  char   c[]   =   "1234567890";    
  char   *p   ="1234567890";    
  a   =   c[1];    
  a   =   p[1];    
  return;    
  }    
  对应的汇编代码    
  10:   a   =   c[1];    
  00401067   8A   4D   F1   mov   cl,byte   ptr   [ebp-0Fh]    
  0040106A   88   4D   FC   mov   byte   ptr   [ebp-4],cl    
  11:   a   =   p[1];    
  0040106D   8B   55   EC   mov   edx,dword   ptr   [ebp-14h]    
  00401070   8A   42   01   mov   al,byte   ptr   [edx+1]    
  00401073   88   45   FC   mov   byte   ptr   [ebp-4],al    
  第一种在读取时直接就把字符串中的元素读到寄存器cl中，而第二种则要先把指针值读到  
  edx中，再根据edx读取字符，显然慢了。    

#### 小结：    
  堆和栈的区别可以用如下的比喻来看出：    
  使用栈就象我们去饭馆里吃饭，只管点菜（发出申请）、付钱、和吃（使用），吃饱了就  
  走，不必理会切菜、洗菜等准备工作和洗碗、刷锅等扫尾工作，他的好处是快捷，但是自  
  由度小。    
  使用堆就象是自己动手做喜欢吃的菜肴，比较麻烦，但是比较符合自己的口味，而且自由  
  度大。   (经典！) 

### 文件和目录的区别
普通文件：存储普通数据，一般就是字符串。

目录文件：存储了一张表，该表就是该目录文件下，所有文件名和索引（inode）的映射关系。
通常父目录会存储有它目录下文件的索引映射，说白了就是一张对应关系的索引表。
### 1.守护进程、僵尸进程和孤儿进程

守护进程 指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等 创建守护进程要点： （1）让程序在后台执行。方法是调用fork（）产生一个子进程，然后使父进程退出。 （2）调用setsid（）创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid（）使进程成为一个会话组长。setsid（）调用成功后，进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。 （3）禁止进程重新打开控制终端。经过以上步骤，进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过fork（）创建新的子进程，使调用fork的进程退出。 （4）关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符。 （5）将当前目录更改为根目录。 （6）子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，使用unmask（0）将屏蔽字清零。 （7）处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程（zombie），从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，子进程结束时不会产生僵尸进程。 

孤儿进程 如果父进程先退出，子进程还没退出，那么子进程的父进程将变为init进程。（注：任何一个进程都必须有父进程）。 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

 僵尸进程 如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。 设置僵尸进程的目的是维护子进程的信息，以便父进程在以后某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用wait或waitpid时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）。

### 2.如何避免僵尸进程？

通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN);表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。 

父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回。 

如果父进程很忙可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出。 

通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，孙进程结束后，init会等待回收。

 第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。

### 3.什么是内存泄漏？内存溢出？

**内存溢出 out of memory**，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。

内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。

内存泄漏是指你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。

\1. 常发性内存泄漏。发生内存泄漏的代码会被多次执行到，每次被执行的时候都会导致一块内存泄漏。

\2. 偶发性内存泄漏。发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。

\3. 一次性内存泄漏。发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，所以内存泄漏只会发生一次。

\4. 隐式内存泄漏。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。

从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终消耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到。

**内存溢出的原因以及解决方法**

引起内存溢出的原因：

1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据；

2.集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；

3.代码中存在死循环或循环产生过多重复的对象实体；

4.使用的第三方软件中的BUG；

5.启动参数内存值设定的过小

重点排查以下几点：

1.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。

2.检查代码中是否有死循环或递归调用。

3.检查是否有大循环重复产生新对象实体。

4.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。

5.检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。

第四步，使用内存查看工具动态查看内存使用情况

#### go内存泄漏情况及解决方案

https://blog.csdn.net/m0_37290103/article/details/116493163

##### 基本解决方案：pprof排查

https://darjun.github.io/2021/06/09/youdontknowgo/pprof/

Go 有非常多好用的工具，pprof 可以用来分析一个程序的性能。pprof 有以下 4 种类型：

- CPU profiling（CPU 性能分析）：这是最常使用的一种类型。用于分析函数或方法的执行耗时；
- Memory profiling：这种类型也常使用。用于分析程序的内存占用情况；
- Block profiling：这是 Go 独有的，用于记录 goroutine 在等待共享资源花费的时间；
- Mutex profiling：与 Block profiling 类似，但是只记录因为锁竞争导致的等待或延迟。

###### CPU profiling

pprof 使用非常简单。首先调用`pprof.StartCPUProfile()`启用 CPU profiling。它接受一个`io.Writer`类型的参数，`pprof`会将分析结果写入这个`io.Writer`中。为了方便事后分析，我们写到一个文件中。

在要分析的代码后调用`pprof.StopCPUProfile()`。那么`StartCPUProfile()`和`StopCPUProfile()`之间的代码执行情况都会被分析。方便起见可以直接在`StartCPUProfile()`后，用`defer`调用`StopCPUProfile()`，即分析这之后的所有代码。

###### Memory profiling

内存分析有所不同，我们可以在程序运行过程中随时查看堆内存情况

这里在循环结束后，通过`pprof.Lookup("heap")`查看堆内存的占用情况，并将结果写到文件`mem.profile`中。

运行`go run main.go`生成`mem.profile`文件，然后使用`go tool pprof mem.profile`来分析

当然也可以使用`list`命令查看，内存在哪一行分配的

###### net/http/pprof

如果线上遇到 CPU 或内存占用过高，该怎么办呢？总不能将上面的 Profile 代码编译到生产环境吧，这无疑会极大地影响性能。`net/http/pprof`提供了一个方法，不使用时不会造成任何影响，遇到问题时可以开启 profiling 帮助我们排查问题。我们只需要使用`import`这个包，然后在一个新的 goroutine 中调用`http.ListenAndServe()`在某个端口启动一个默认的 HTTP 服务器即可：

##### 字符串截取

func main() {
	var str0 = "12345678901234567890"
	str1 := str0[:10]
}
以上代码，会有10字节的内存泄漏，我们知道，str0和str1底层共享内存，只要str1一直活跃，str0 就不会被回收，10字节的内存被使用，剩下的10字节内存就造成了临时性的内存泄漏，直到str1不再活跃

如果str0足够大，str1截取足够小，或者在高并发场景中频繁使用，那么可想而知，会造成临时性内存泄漏，对性能产生极大影响。
解决方案1：string to []byte， []byte to string
func main() {
	var str0 = "12345678901234567890"
	str1 := string([]byte(str0[:10]))
}
将需要截取的部分先转换成[]byte，再转换成string，但是这种方式会产生两个10字节的临时变量，string转换[]byte时产生一个10字节临时变量，[]byte转换string时产生一个10字节的临时变量
解决方案3：strings.Builder
func main() {
	var str0 = "12345678901234567890"
	var builder strings.Builder
	builder.Grow(10)
	builder.WriteString(str0[:10])
	str1 := builder.String()
}
这种方式的缺点就是代码量过多

解决方案4：strings.Repeat
func main() {
	var str0 = "12345678901234567890"
	str1 := strings.Repeat(str0[:10], 1)
}
这种方式底层还是用到了strings.Builder，优点就是将方案3进行了封装，代码量得到了精简

切片截取引起子切片内存泄漏

```Go
func main() {
	var s0 = []int{1, 2, 3, 4, 5, 6, 7, 8, 9}
	s1 := s0[:5]
}
```

这种情况与字符串截取引起的内存泄漏情况类似，s1活跃情况下，造成s0中部分内存泄漏

## ***解决方案***：append

##### 函数[数组](https://so.csdn.net/so/search?q=数组&spm=1001.2101.3001.7020)传参

Go数组是值类型，赋值和函数传参都会复制整个数组

如果我们在函数传参的时候用到了数组传参，且这个数组够大（我们假设数组大小为100万，64位机上消耗的内存约为800w字节，即8MB内存），或者该函数短时间内被调用N次，那么可想而知，会消耗大量内存，对性能产生极大的影响，如果短时间内分配大量内存，而又来不及GC，那么就会产生临时性的内存泄漏，对于高并发场景相当可怕。
解决方案：

采用指针传递

利用切片可以很好的解决

切片本身是一个引用类型，arrayA和arrayB底层共享内存，不会产生额外内存开销，而且arrayA的指针地址发生改变，arrayB的指针地址也不会改变

##### goroutine导致内存泄漏

“Go里面10次内存泄漏有9次都是goroutine泄漏引起的”

有些编码不当的情况下，goroutine被长期挂住，导致该协程中的内存也无法被释放，就会造成永久性的内存泄漏。例如协程结束时协程中的channel没有关闭，导致一直阻塞；例如协程中有死循环；等

解决方案：

利用context，在break之前cancel，目的就是通知协程退出，这样就避免了goroutine泄漏

##### 定时器

1）time.After

time.After底层实现是一个timer，而定时器未到触发时间，该定时器不会被gc回收，从而导致临时性的内存泄漏，而如果定时器一直在创建，那么就造成了永久性的内存泄漏了。

解决方案：采用timer定时器

 创建timer定时器，每次需要启动定时器的时候，使用Reset方法重置定时器，这样就不用每次都要创建新的定时器了

2）timer、ticker
在高并发、高性能场景中，使用time.NewTimer或者time.NewTicker定时器，都需要注意及时调用Stop方法来及时释放资源，否则可能造成临时性或者永久性的内存泄漏。

### 4.什么是IO多路复用？

- IO 多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；
- 一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；
- 没有文件句柄就绪就会阻塞应用程序，交出CPU。

### 5.为什么有IO多路复用机制？

没有IO多路复用机制时，有BIO、NIO两种实现方式，但它们都有一些问题

#### 同步阻塞（BIO）

- 服务端采用单线程，当 `accept` 一个请求后，在 `recv` 或 `send` 调用阻塞时，将无法 `accept` 其他请求（必须等上一个请求处理 `recv` 或 `send` 完 ）（无法处理并发）
- 服务端采用多线程，当 accept 一个请求后，开启线程进行 recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写实际的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费。

#### 同步非阻塞（NIO）

- 服务器端当 `accept` 一个请求后，加入 `fds` 集合，每次轮询一遍 `fds` 集合 `recv` (非阻塞)数据，没有数据则立即返回错误，每次轮询所有 fd （包括没有发生读写实际的 fd）会很浪费 CPU。

#### IO多路复用

服务器端采用单线程通过 `select/poll/epoll` 等系统调用获取 fd 列表，遍历有事件的 fd 进行 `accept/recv/send` ，使其能支持更多的并发连接请求。

### 6.IO多路复用的三种实现

- select
- poll
- epoll

#### select

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。

#### select调用过程

copy_from_user从用户空间拷贝fd_set到内核空间

（2）注册回调函数__pollwait

（3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）

（4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。

（5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk->sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。

（6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。

（7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。

（8）把fd_set从内核空间拷贝到用户空间。

#### select缺点

select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

- 单个进程所打开的FD是有限制的，通过 `FD_SETSIZE` 设置，默认1024 ;
- 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；

> 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

- 对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发）

> 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

#### poll

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， **但是它没有最大连接数的限制**，原因是它是基于链表来存储的.

poll缺点

**它没有最大连接数的限制**，原因是它是基于链表来存储的，但是同样有缺点：

- 每次调用 poll ，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
- 对 socket 扫描是线性扫描，采用轮询的方法，效率较低（高并发时）

#### epoll

**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）

#### epoll的优点

- 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；
- 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll；
- 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。

#### epoll缺点

- epoll只能工作在 linux 下

select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。 

### 7.查看Linux磁盘及内存占用情况

查看磁盘使用情况：
df -k：以KB为单位显示磁盘使用量和占用率

df -m：以Mb为单位显示磁盘使用量和占用率

df –help：查看更多df命令及使用方法

**查看内存占用情况：**
**1.top**

PID：当前运行进程的ID
USER：进程属主
PR：每个进程的优先级别
NInice：反应一个进程“优先级”状态的值，其取值范围是-20至19，一
　　　　共40个级别。这个值越小，表示进程”优先级”越高，而值越
　　　　大“优先级”越低。一般会把nice值叫做静态优先级
VIRT：进程占用的虚拟内存
RES：进程占用的物理内存
SHR：进程使用的共享内存
S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示
　 该进程优先值为负数
%CPU：进程占用CPU的使用率
%MEM：进程使用的物理内存和总内存的百分比
TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。
COMMAND：进程启动命令名称
**２.free**

total : 总计物理内存的大小。
used : 已使用多大。
free : 可用有多少。
Shared : 多个进程共享的内存总额。
Buffers/cached : 磁盘缓存的大小。
-/+ buffers/cached) :
used:已使用多大;
free:可用有多少。
3.cat /proc/meminfo
查看RAM使用情况最简单的方法是通过命令：cat /proc/meminfo；
这个动态更新的虚拟文件实际上是许多其他内存相关工具(如：free / ps / top)等的组合显示。
/proc/meminfo列出了所有你想了解的内存的使用情况。
进程的内存使用信息也可以通过命令：cat /proc//statm 、 cat /proc//status 来查看。
4.ps aux –sort -rss
ps aux: 列出目前所有的正在内存当中的程序。
a显示终端上地所有进程,包括其他用户地进程(有的进程没有终端)。
-a 显示所有终端机下执行的进程，除了阶段作业领导者之外。
u 　以用户为主的格式来显示进程状况。
x 　显示所有进程，不以终端机来区分。
a会包括其他用户(否则只有用户本身); x会包括其他终端;
aux就可以包括内存所有;

USER：该 process 属于那个使用者账号的
PID ：该 process 的号码
%CPU：该 process 使用掉的 CPU 资源百分比
%MEM：该 process 所占用的物理内存百分比
VSZ ：该 process 使用掉的虚拟内存量 (Kbytes)
RSS ：该 process 占用的固定的内存量 (Kbytes)
TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。
STAT：该程序目前的状态，主要的状态有
R ：该程序目前正在运作，或者是可被运作
S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。
T ：该程序目前正在侦测或者是停止了
Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态
START：该 process 被触发启动的时间
TIME ：该 process 实际使用 CPU 运作的时间
COMMAND：该程序的实际指令

#### 查看某个具体进程资源使用情况

1：
top -p pid 查看程序的情况
2：
ps -aux | grep process_name
3：
cat /proc/pid/status
这里会打印出当前进程详细的情况，其中，内存是 VmRSS。
注：pid是要替换成一个id数字的。

### 8.线程池

**线程池**（英语：thread pool）：一种[线程](https://baike.baidu.com/item/线程)使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。线程池不仅能够保证内核的充分利用，还能防止过分调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。

[服务器](https://baike.baidu.com/item/服务器)程序利用线程技术响应客户请求已经司空见惯,可能您认为这样做效率已经很高，但您有没有想过优化一下使用线程的方法。该文章将向您介绍服务器程序如何利用线程池来优化性能并提供一个简单的线程池实现。

1、线程池管理器（ThreadPoolManager）:用于创建并管理线程池

2、工作线程（WorkThread）: 线程池中线程

3、任务接口（Task）:每个任务必须实现的接口，以供工作线程调度任务的执行。

4、任务队列:用于存放没有处理的任务。提供一种缓冲机制。

#### 线程池的应用

mysql连接池，redis连接池

### 系统调用

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1. 用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。
2. 系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能就需要使用系统调用

### 进程和线程

#### 进程间的通信方式

1、匿名管道

##### 2、有名管道

3、信号

4、消息队列

5、信号量

6、共享内存

7、套接字
1. 管道 管道也叫无名（匿名）管道,它是是 UNIX 系统 IPC（进程间通信）的最古老形式,所有的 UNIX 系统都支持这种通信机制。管道本质其实是内核中维护的一块内存缓冲区,Linux 系统中通过 pipe() 函数创建管道,会生成两个文件描述符,分别对应管道的读端和写端。无名管道只能用于具有亲缘关系的进程间的通信。 
2. 命名管道 匿名管道,由于没有名字,只能用于亲缘关系的进程间通信。为了克服这个缺点,提出了有名管道（FIFO）,也叫命名管道、FIFO文件。有名管道（FIFO）不同于匿名管道之处在于它提供了一个路径名与之关联,以 FIFO 的文件形式存在于文件系统中,并且其打开方式与打开一个普通文件是一样的,这样即使与 FIFO 的创建进程不存在亲缘关系的进程,只要可以访问该路径,就能够彼此通过 FIFO 相互通信,因此,通过 FIFO 不相关的进程也能交换数据。 
3. 信号 信号是 Linux 进程间通信的最古老的方式之一,是事件发生时对进程的通知机制,有时也称之为软件中断,它是在软件层次上对中断机制的一种模拟,是一种异步通信的方式。信号可以导致一个正在运行的进程被另一个正在运行的异步进程中断,转而处理某一个突发事件。 
4. 消息队列 消息队列就是一个消息的链表,可以把消息看作一个记录,具有特定的格式以及特定的优先级,对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息,对消息队列有读权限的进程则可以从消息队列中读走消息,消息队列是随内核持续的。 
5. 共享内存 共享内存允许两个或者多个进程共享物理内存的同一块区域（通常被称为段）。由于一个共享内存段会称为一个进程用户空间的一部分,因此这种 IPC 机制无需内核介入。所有需要做的就是让一个进程将数据复制进共享内存中,并且这部分数据会对其他所有共享同一个段的进程可用。与管道等要求发送进程将数据从用户空间的缓冲区复制进内核内存和接收进程将数据从内核内存复制进用户空间的缓冲区的做法相比,这种 IPC 技术的速度更快。 
6. 内存映射 内存映射（Memory-mapped I/O）是将磁盘文件的数据映射到内存,用户通过修改内存就能修改磁盘文件。
7. 信号量 信号量主要用来解决进程和线程间并发执行时的同步问题,进程同步是并发进程为了完成共同任务采用某个条件来协调它们的活动。对信号量的操作分为 P 操作和 V 操作,P 操作是将信号量的值减 1,V 操作是将信号量的值加 1。当信号量的值小于等于 0 之后,再进行 P 操作时,当前进程或线程会被阻塞,直到另一个进程或线程执行了 V 操作将信号量的值增加到大于 0 之时。 8. Socket 套接字（Socket）,就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象。一个套接字就是网络上进程通信的一端,提供了应用层进程利用网络协议交换数据的机制。Socket 一般用于网络中不同主机上的进程之间的通信。

#### Goroutine同步机制
Goroutine提供了一种传统的同步机制——对共享资源加锁。

（1）原子函数能够以很底层的加锁机制来同步访问整型变量和指针。
atomic.AddInt64(&counter, 1)，强制同一时刻只能有一个 goroutine 运行并完成这个加法操作，还有LoadInt、StoreInt等。
（2）互斥锁用于在代码上创建一个临界区，保证同一时间只有一个 goroutine 可以
执行这个临界区里的代码。

var mutex sync.Mutex   
mutex.Lock()｛
xxx
｝
mutex.Unlock()
（3）通道
使用原子函数和互斥锁能够保证对共享资源的安全访问以及消除竞争状态；
使用通道，通过发送和接收需要共享的资源，在goroutine 之间进行同步。
无缓冲的通道（unbuffered channel）：指在接收前没有能力保存任何值的通道。这种类型的通
道要求发送goroutine 和接收goroutine 同时准备好，才能完成发送和接收操作，如果两个goroutine
没有同时准备好，通道会导致先执行发送或接收操作的goroutine阻塞等待。
有缓冲的通道（buffered channel）：是一种在被接收前能存储一个或者多个值的通道。不强制要求goroutine 之间必须同时完成发送和接收。只有在通道没有可用缓冲区容纳被发送的值时，发送动作才会阻塞；只有在通道中没有要接收的值时，接收动作才会阻塞。

#### 线程间的同步方式

1、互斥量（锁机制）

2、信号量

3、事件
##### 互斥量的实现方式
互斥量的具体实现方式为：每个线程在对共享资源操作前都尝试先加锁，成功加锁后才可以对共享资源进行读写操作，操作结束后解锁。
##### 信号量的实现方式
可以直接理解成计数器（当然其实加锁的时候肯定不能这么简单，不只只是信号量了），信号量会有初值（>0），每当有进程申请使用信号量，通过一个P操作来对信号量进行-1操作，当计数器减到0的时候就说明没有资源了，其他进程要想访问就必须等待（具体怎么等还有说法，比如忙等待或者睡眠），当该进程执行完这段工作（我们称之为临界区）之后，就会执行V操作来对信号量进行+1操作。
1.系统首先要检测该资源的信号量；

2.若该资源的信号量值大于0，则进程可以使用该资源，此时，进程将该资源的信号量值减1；

3.若该资源的信号量值为0，则进程进入休眠状态，直到信号量值大于0时进程被唤醒，访问该资源；

当进程不再使用由一个信号量控制的共享资源时，该信号量值增加1，如果此时有进程处于休眠状态等待此信号量，则该进程会被唤醒。


#### 进程的调度算法

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

#### 死锁

##### 死锁产生的四个条件：

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

##### 死锁的解决方法：

1、预防（破坏死锁产生的条件就不可能会产生死锁了）

2、避免（系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**）

3、检测（系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源）

4、解除（是与检测相配套的一种措施，用于**将进程从死锁状态下解脱出来**）

#### 虚拟内存

https://xiaolincoding.com/os/3_memory/vmem.html#tlb

为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套**虚拟地址空间**，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。

每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过**内存交换**技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。

那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。

进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。

于是，这里就引出了两种地址的概念：

- 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
- 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）。

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：

![img](https://img-blog.csdnimg.cn/72ab76ba697e470b8ceb14d5fc5688d9.png)

> 操作系统是如何管理虚拟地址与物理地址之间的关系？

主要有两种方式，分别是**内存分段和内存分页**，分段是比较早提出的，我们先来看看内存分段。

##### 虚拟内存作用

- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

##### 内存分段

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段（\*Segmentation\*）的形式把这些段分离出来。**

> 分段机制下，虚拟地址和物理地址是如何映射的？

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。

![img](https://img-blog.csdnimg.cn/a9ed979e2ed8414f9828767592aadc21.png)

段选择因子和段内偏移量：

- **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

在上面，知道了虚拟地址是通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：

![img](https://img-blog.csdnimg.cn/c5e2ab63e6ee4c8db575f3c7c9c85962.png)

如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

###### 分段缺点

- 第一个就是**内存碎片**的问题。
- 第二个就是**内存交换的效率低**的问题。

内存碎片主要分为，内部内存碎片和外部内存碎片。

内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以**不会出现内部内存碎片**。

但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以**会出现外部内存碎片**的问题。

解决「外部内存碎片」的问题就是**内存交换**。

###### 分段为什么会导致内存交换效率低的问题？

对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。

所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**

为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页

##### 内存分页

分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是**内存分页**（*Paging*）。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。

虚拟地址与物理地址之间通过**页表**来映射，如下图：

![img](https://img-blog.csdnimg.cn/08a8e315fedc4a858060db5cb4a654af.png)

页表是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。



###### 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？

内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

###### 分页缺点

1.但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对**内存分页机制会有内部内存碎片**的现象。

2.有空间上的缺陷。

因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。

在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。

这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。

那么，`100` 个进程的话，就需要 `400MB` 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。

更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

###### 分页映射过程

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

![img](https://img-blog.csdnimg.cn/7884f4d8db4949f7a5bb4bbd0f452609.png)

总结一下，对于一个内存地址转换，其实就是这样三个步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

##### 多级页表

要解决分页上面的问题，就需要采用一种叫作**多级页表**（*Multi-Level Page Table*）的解决方案。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。

![img](https://img-blog.csdnimg.cn/19296e249b2240c29f9c52be70f611d5.png)

##### TLB

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

![img](https://img-blog.csdnimg.cn/edce58534d9342ff89f5261b1929c754.png)

我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（*Translation Lookaside Buffer*） ，通常称为页表缓存、转址旁路缓存、快表等。

![img](https://img-blog.csdnimg.cn/a3cdf27646b24614a64cfc5d7ccffa35.png)

在 CPU 芯片里面，封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。

有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个

##### 段页式内存管理

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

![img](https://img-blog.csdnimg.cn/f19ebd6f70f84083b0d87cc5e9dea8e3.png)

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。

用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：

![img](https://img-blog.csdnimg.cn/8904fb89ae0c49c4b0f2f7b5a0a7b099.png)

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。

##### Linux内存管理

**Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制**。

Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。

在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，不同位数的系统，地址空间的范围也不同

内核空间与用户空间的区别：

- 进程在用户态时，只能访问用户空间内存；
- 只有进入内核态后，才可以访问内核空间的内存

虽然每个进程都各自有独立的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。

###### 用户空间内存内容

从**低到高**分别是 6 种不同的内存段：

- 程序文件段（.text），包括二进制可执行代码；
- 已初始化数据段（.data），包括静态常量；
- 未初始化数据段（.bss），包括未初始化的静态变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（[跟硬件和内核版本有关 (opens new window)](http://lishiwen4.github.io/linux/linux-process-memory-location)）；
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

在这 7 个内存段中，堆和文件映射段的内存是动态分配的。

### 请你说说多线程

线程是操作系统调度的最小单元,它可以让一个进程并发地处理多个任务,也叫轻量级进程。所以,在一个进程里可以创建多个线程,这些线程都拥有各自的计数器、堆栈、局部变量,并且能够共享进程内的资源。由于共享资源,处理器便可以在这些线程之间快速切换,从而让使用者感觉这些线程在同时执行。 总的来说,操作系统可以同时执行多个任务,每个任务就是一个进程。进程可以同时执行多个任务,每个任务就是一个线程。一个程序运行之后至少有一个进程,而一个进程可以包含多个线程,但至少要包含一个线程。
好处：
1. 更多的CPU核心 现代计算机处理器性能的提升方式,已经从追求更高的主频向追求更多的核心发展,所以处理器的核心数量会越来越多,充分地利用处理器的核心则会显著地提高程序的性能。而程序使用多线程技术,就可以将计算逻辑分配到多个处理器核心上,显著减少程序的处理时间,从而随着更多处理器核心的加入而变得更有效率。
2. 更快的响应时间 我们经常要针对复杂的业务编写出复杂的代码,如果使用多线程技术,就可以将数据一致性不强的操作派发给其他线程处理（也可以是消息队列）,如上传图片、发送邮件、生成订单等。这样响应用户请求的线程就能够尽快地完成处理,大大地缩短了响应时间,从而提升了用户体验。 3. 更好的编程模型 Java为多线程编程提供了良好且一致的编程模型,使开发人员能够更加专注于问题的解决,开发者只需为此问题建立合适的业务模型,而无需绞尽脑汁地考虑如何实现多线程。一旦开发人员建立好了业务模型,稍作修改就可以将其方便地映射到Java提供的多线程编程模型上。
### 请你说说死锁定义及发生的条件
1. 死锁 两个或两个以上的进程在执行过程中,因争夺共享资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。这些永远在互相等待的进程称为死锁进程。 
2. 死锁的发生必须具备以下四个必要条件： - 互斥条件：指进程对所分配到的资源进行排它性使用,即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源,则请求者只能等待,直至占有资源的进程用毕释放； - 请求和保持条件：指进程已经保持至少一个资源,但又提出了新的资源请求,而该资源已被其它进程占有,此时请求进程阻塞,但又对自己已获得的其它资源保持不放； - 不剥夺条件：指进程已获得的资源,在未使用完之前,不能被剥夺,只能在使用完时由自己释放； - 环路等待条件：指在发生死锁时,必然存在一个进程——资源的环形链,即进程集合 {P0,P1,P2,···,Pn} 中的 P0 正在等待一个 P1 占用的资源；P1 正在等待 P2 占用的资源,……,Pn 正在等待已被 P0 占用的资源。
### 物理地址和虚拟地址的区别
物理地址：CPU地址总线传来的地址，由硬件电路控制其具体含义。物理地址中
很大一部分是留给内存条中的内存的，但也常被映射到其他存储器上 （如显存、
BIOS等）。在程序指令中的虚拟地址经过段映射和页面映射后，就生成了物理地址，
这个物理地址被放到CPU的地址线上。
物理地址空间，一部分给物理RAM（内存）用，一部分给总线用，这是由硬件设计来决定的，
因此在32 bits地址线的x86处理器中，物理地址空间是2的32次方，即4GB，但物理RAM一般
不能上到4GB，因为还有一部分要给总线用（总线上还挂着别的 许多设备）。在PC机中，
一般是把低端物理地址给RAM用，高端物理地址给总线用。

虚拟地址：现代操作系统普遍采用虚拟内存管理（Virtual Memory Management）机制，
这需要MMU（Memory Management Unit）的支持。MMU通常是CPU的一部分，如果处理器没有MMU，
或者有MMU但没有启用，CPU执行单元发出的内存地址将直接传到芯片引脚上，被 内存芯片
（物理内存）接收，这称为物理地址（Physical Address），如果处理器启用了MMU，
CPU执行单元发出的内存地址将被MMU截获，从CPU到MMU的地址称为虚拟地址（Virtual Address），
而MMU将这个地址翻译成另一个地址发到CPU芯片的外部地址引脚上，也就是将虚拟地址映射
成物理地址。
程序员只能使用虚拟地址。系统中每个进程有各自的私有用
户空间（0～3G），这个空间对系统中的其他进程是不可见的。
CPU发出取指令请求时的地址是当前上下文的虚拟地址，MMU再从页表中找到这个虚拟地址
的物理地址，完成取指。同样读取数据的也是虚拟地址，比如mov ax, var. 编译时var就
是一个虚拟地址，也是通过MMU从也表中来找到物理地址，再产生总线时序，完成取数据的。

### 虚拟内存，共享内存，常驻内存
虚拟内存、物理内存、共享内存。它们分别对应top输出中的VIRT、RES、SHR三列。

虚拟内存会为每个进程提供一个一致的，私有的地址空间，它让每个进程都拥有一片连续完整的内存空间，这样能更加有效管理内存并减少出错，可以让程序拥有超过系统实际物理内存大小的可用内存空间，是一个假象的内存空间，在程序运行过程中虚拟内存空间中需要被访问的部分会被映射到物理内存空间中。虚拟内存空间大只能表示程序运行过程中可访问的空间比较大，不代表物理内存空间占用也大。
常驻内存，顾名思义是指那些被映射到进程虚拟内存空间的物理内存
共享内存，进程在运行过程中，会加载许多操作系统的动态库，比如 libc.so、libld.so等。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。如上图中的A4和B3部分即为共享内存，实际都映射到同一块物理内存。


### 怎么在指定的路径里找所有文本文件中带有“abc”的内容
grep "abc" *

### 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？ 
逐行读取文件a，采用hash函数：Hash(url)%1000将url分割到1000个小文件中，文件即为f1_1,f1_2,f1_3,...,f1_1000。那么理想情况下每个小文件的大小大约为300M左右。再以相同的方法对大文件b进行相同的操作再得到1000个小文件，记为： f2_1,f2_2,f2_3,...,f2_1000。  
        经过一番折腾后我们将大文件进行了分割并且将相同url都分割到了这2组小文件中下标相同的两个文件中,其实我们可以将这2组文件看成一个整体：  
        f1_1&  f2_1，  f1_2&  ,f2_2,  f1_3&  f2_3,...,  f1_1000& f2_1000
        那么我们就可以将问题转化成为求这1000对小文件中相同的url就可以了。接下来，求每对小文件中的相同url，首先将每对对小文件中较小的那个的url放到HashSet结构中，然后遍历对应这对小文件中的另一个文件，看其是否存才刚刚构建的HashSet中，如果存在说明是一样的url，将这url直接存到结果文件就ok了。如果存在大文件接着hash划分即可。 
### 海量日志数据，提取出某日访问百度次数最多的那个IP 
（1）首先，从这些海量数据中过滤出指定一天访问百度的用户IP，并逐个写到一个大文件中。 
       （2）采用“分而治之”的思想用Hash映射将大文件进行分割降低数据规模。
        按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中，其中Hash函数得出值为分割后小文件的编号。 
       （3）逐个读小文件，对于每一个小文件构建一个IP为key，出现次数为value的HashMap。
        对于怎么利用HashMap记录IP出现的次数这个比较简单，因为我们可以通过程序读小文件将IP放到HashMap中key的之后可以先判断此IP是否已经存在如果不存在直接放进去，其出现次数记录为1，如果此IP已经存储则过得其对应的value值也就是出现的次数然后加1就ok。最后，按照IP出现的次数采用排序算法对HashMap中的数据进行排序， 同时记录当前出现次数最多的那个IP地址。
      （4）走到这步，我们可以得到1024个小文件中出现次数最多的IP了，再采用常规的排序算法找出总体上出现次数最多的IP就ok了。  
      
### 100亿条记录的文本文件，取出重复数最多的前10条
1.100万的直接用hash存储key(值),value(次数)。同时建一个10个元素的数组，一个整数记录数据中最小次数，循环一次没有出现过的插入hash表中，value记1，如已存则value加1，value时大于数组中的最小次数则进行替换，改写整数值。
        PS：假设一条记录64字节，100万应该为64MB（10亿字节=1GB，1000换算时），内存此时肯定够用；而100亿条此时需要640GB内存，显然分治实现。
2.100亿类似100万时的处理方法，对数据进行切片，可以都切为100万的记录，对100万最前10，不同在于这前10也存入hash，如果key相同则合并value，显然100亿的数据分割完后的处理结果也要再进行类似的处理，hash表不能过长，原理其实也就是map和reduce。

### 如何看 Linux 程序是多进程还是多线程
根据 /proc/PID/task 下子目录个数来判断一个程序进程是否是多线程
ps -ef | grep xxx查看端口
## 数据库

https://www.iamshuaidi.com/1402.html

https://www.zhihu.com/column/c_1104074839660294144
### 请你说说MySQL索引,以及它们的好处和坏处
索引就像指向表行的指针,是一种允许查询操作快速确定哪些行符合WHERE子句中的条件,并检索到这些行的其他列值的数据结构；

 索引主要有普通索引、唯一索引、主键索引、外键索引、全文索引、复合索引几种；

 在大数据量的查询中,合理使用索引的优点非常明显,不仅能大幅提高匹配where条件的检索效率,还能用于排序和分组操作的加速。 当时索引如果使用不当也有比较大的坏处：比如索引必定会增加存储资源的消耗；同时也增大了插入、更新和删除操作的维护成本,因为每个增删改操作后相应列的索引都必须被更新。而且索引不一定会走，在使用组合索引的时候,如果没有遵从“最左前缀”的原则进行搜索,则索引是不起作用的。

### 聚簇索引和非聚簇索引
两者主要区别是数据和索引是否分离。聚簇索引是将数据与索引存储到一起,找到索引也就找到了数据；而非聚簇索引是将数据和索引存储分离开,索引树的叶子节点存储了数据行的地址。 在InnoDB中,一个表有且仅有一个聚簇索引（因为原始数据只留一份,而数据和聚簇索引在一起）,并且该索引是建立在主键上的,即使没有指定主键,也会特殊处理生成一个聚簇索引；其他索引都是辅助索引,使用辅助索引访问索引外的其他字段时都需要进行二次查找。 而在MyISAM中,所有索引都是非聚簇索引,叶子节点存储着数据的地址,对于主键索引和普通索引在存储上没有区别。 

在InnoDB存储引擎中,可以将B+树索引分为聚簇索引和辅助索引（非聚簇索引）。无论是何种索引,每个页的大小都为16KB,且不能更改。 聚簇索引是根据主键创建的一棵B+树,聚簇索引的叶子节点存放了表中的所有记录。辅助索引是根据索引键创建的一棵B+树,与聚簇索引不同的是,其叶子节点仅存放索引键值,以及该索引键值指向的主键。也就是说,如果通过辅助索引来查找数据,那么当找到辅助索引的叶子节点后,很有可能还需要根据主键值查找聚簇索引来得到数据,这种查找方式又被称为书签查找。因为辅助索引不包含行记录的所有数据,这就意味着每页可以存放更多的键值,因此其高度一般都要小于聚簇索引。
### 1.索引下推

- 索引下推（index condition pushdown ）简称ICP，在Mysql5.6的版本上推出，用于优化查询。
- 在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。
- 在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。
- 索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数

索引下推在**非主键索引**上的优化，可以有效减少回表的次数，大大提升了查询的效率。

### **2.什么是事务？**

在数据库系统里而言，事务是代表一个或者一系列操作的最小逻辑单元，所有在这个逻辑单元内的操作要么全部成功，要么就全部失败，不存在任何中间状态，一旦事务失败那么所有的更改都会被撤消，一旦事务成功所有的操作结果都会被保存。

### **3.为什么要有事务？**

如果无法直观的从概念上理解事务的话，那我们可以尝试从它解决问题的出发点来了解它，事务机制存在的目的就是无论我们的操作过程中是成功、失败、异常、或是受到干扰的情况下，事务都能保证我们数据最终的一致性。

### **4,事务的特性（ACID）**

要实现事务的最终目的，需要几种机制组合才能实现，这几种机制就是事务的几个特性，分别原子性、隔离性、一致性、持久性。 用一句话总结来总结这几个特性之间的关系，那就是“一致性是事务的最终目的，而原子性、隔离性、持久性其实都是为了实现一致性的手段”。

#### **1、原子性（Atomicity）**

概念：一个事务必须是一系列操作的最小单元，这系列操作的过程中，要么整个执行，要么整个回滚，不存在只执行了其中某一个或者某几个步骤。（redolog和undo log）

对应到上面的转账操作中，原子性就代表（检查余额、转账、到账）三个步骤就是一个整体，少了任何一个都不能称为一次转账，整个过程中检查余额、转账、到账要么整体都执行，要么一个失败就整体失败，绝对不会出现某一个执行成功其它的都执行失败，或者某一个执行失败其它的操作执行成功的情况。

#### **2、隔离性（Isolation）**（锁，mvcc）

概念：隔离性是说两个事务的执行都是独立隔离开来的，事务之前不会相互影响，多个事务操作一个对象时会以串行等待的方式保证事务相互之间是隔离的：

小明和小芳各自有一本作业本，如果他们同时去写作业，这时他们都可以在各自作业本上写作业是相互不影响的。但是如果他们两个人只有一本作业本，但是他们都想去写作业怎么办，那么就这个时候就只能等一个人先写完作业后，另外一个人才能写，要不然两个人同时在同一个作业本上写作业，那么肯定会乱套。所以这种两个事物操作同一个对象必须隔离开来不能相互影响的特性称为事务的隔离性。

#### **3、一致性（Consistency）**

概念：事务要保证数据库整体数据的完整性和业务的数据的一致性，事务成功提交整体数据修改，事务错误则回滚到数据回到原来的状态；

如上面转账的案例，如果事务提交成功则A账户减金额，B账户则加对应的金额，数据库总体金额不变只是载体变了。如果事务出错则整体回滚，无论到了上面的哪个步骤A和B的数据都会回到最事务开启前的状态保证数据的始终一致;

#### **4、D(Durability）持久性：**

概念：持久性是指一旦事务成功提交后，只要修改的数据都会进行持久化，不会因为异常、宕机而造成数据错误或丢失。

### **5.什么是事务的隔离性？**

两个人同时在一个画本上画画，过程中你一笔我一笔，那么最后最后画出来的一定是一个四不像，多个事务同时操作一个数据也会和上面的情况类似，所以为了让不同的事务之间相互不存在干扰，就需要对事务的操作进行隔离，事务的隔离性也就是将操作同一个数据的事务相互分离，让操作之间分开有序的执行。

### 6.**用什么方式实现事务的隔离性**

通常数据库里都是采用锁的机制，保证事务之间的隔离性，在一个事务对数据进行修改的时候，首先会对该数据进行加锁，在当前事务没有释放锁之前，后续的事务是无法对该数据再次进行加锁的，所以其它事务只能等待，只有前一个事务释放了锁之后，后面的事务才能进行加锁。通过加锁的方式来保证这种先来后到的顺序，以隔离多个事务对数据的操作，从而实现事务的隔离性。

### **7.事务并发问题与事务隔离级别**

在事务并发执行的时候，如果不进行事务隔离，那么就会产生脏写、脏读、重复读、幻读的问题。  为了解决这些问题，数据库也针对不同的场景通过加锁的形式进行了不同程度的隔离，下面我们了解下产生这些问题的根源，然后不同的事务隔离级别是通过什么方式解决这些问题的。

#### **1、脏写问题**

在事务并发的时候，一个事务可以修改另外一个正在进行中的事务的数据，这可能会导致一个写的事务会覆盖另外一个写的事务数据，这也就是脏写问题。

**案例：**以存取款为例，假设A与B同用一张银行卡，银行卡内余额为1000，如果两个事务可以对同一个数据进行修改时，可能会产下面 事务B 把事务A的数据覆盖了，导致事务A写入的数据丢失了。

![img](https://pic1.zhimg.com/v2-5077064131284076719d3fc2db1751b7_720w.jpg?source=d16d100b)





#### **如何解决脏写问题**

在事务隔离级别**READ_UNCOMMITTED** 解决了脏写的问题，其原理是在READ_UNCOMMITTED事务隔离级别下，当事务对数据进行修改时，首先会对数据加写锁，加写锁成功后只有等事务提交或者回滚后才会释放，所以已经有一个事务对数据加了写锁，那么其他事务就会因为无法获取对应数据的锁而阻塞，所以在READ_UNCOMMITTED事务隔离级别下，多个事务是无法对同一个数据同时进行修改。

#### **2、脏读问题**

在事务并发的时候，一个事务可以读取到另外一个正在进行中的事务数据，这产生了脏读问题。

**案例：** 以存取款为例，假设A与B同用一张银行卡，银行卡内余额为1000，此时事务B进行取款，事务A进行存款，如果一个事务可以读取到另外一个正在进行中的事务数据，那么可能产生下面问题。

**操作：** 

1、事务B：进行取款1000，此时余额为0，但未提交事务。

2、事务A：此时事务A对银行卡余额进行查询，查询到账户余额为0。

3、事务B：撤销事务，余额恢复为1000.

4、事务A：进行存款500，余额=0+500。

5、事务A：提交事务，最后账户余额为500。

![img](https://pic1.zhimg.com/v2-b32fbf6d7f0d635c17650be9be5085c2_720w.jpg?source=d16d100b)





#### **如何解决脏读问题**

在事务隔离级别**READ_COMMITTED**（读提交）解决了脏读的问题，其原理是在READ_COMMITTED的事务隔离级别下，当事务对数据进行修改时，得先要对数据加写锁，当事务读取数据时，首先需要对数据加读锁。 因为写锁与读锁不能共存，所以在修改数据的时候，其它事务会因为无法成功加读锁而阻塞，所以READ_COMMITTED 的事务隔离级别下，一个事务就无法读取另外一个未完成的事务所修改的数据了。

#### **3、不可重复读问题**

在事务并发的时候，一个事务里多次对同一个数据进行读取，但是读取到的结果是不一样的，这种问题称为不可重复读问题。

#### **如何解决不可重复读**

不可重复读产生的核心问题是，在一个事务第1次读取和第2次读取数据的间隔过程中可以被另外一个事务修改，因为在READ_COMMITTED的事务隔离级别下，事务中每次读取数据结束后（事务未结束）就会释放读锁，而一旦读锁释放后另外一个事务就可以加写锁，最终导致事务中多次读取该数据的间隙中可以被其它事务修改。

而**REPEATABLE_READ** **（可重复读）**的事务隔离级别下，一个事务中的读取操作会对数据加读锁（并且在当前事务结束之前不会释放），此时另外一个事务对该数据修改之前会尝试加写锁（此时不会成功，因为读写锁冲突），所以就避免了一个事务多次读取的数据的间隔可以被另外一个事务修改。

不过实际实现的过程中，数据库解决不可重复读的方式会有所不同，在Mysql innodb引擎中，解决不可重复读的问题并不是通过加锁实现，而是通过MVCC机制实现，使用MVCC后读取数据的时候不会加读锁，而是读取的历史版本数据，在RR事务隔离级别里，MVCC保证了在一个事务里多次读取的数据历史版本是一致的，所以就无法看到最新修改的数据，这样也就保证了一个事务里多次读取到的数据肯定是一致的。

#### **4、幻读问题**

在事务并发的时候，一个事务可以往另外一个正在读取的事务查询范围内插入新数据，导致另外一个事务在第二次查询数据里，要比前一次查询的数据要多，同样的SQL后面一次查询凭空多出了数据，像幻觉一样所以称为幻读。

### **8.解决幻读的两种方式**

#### **1、设置事务隔离级别为SERIALIZABLE** 

在SERIALIZABLE事务隔离级别下，所有的事务都串行化执行，一个事务的执行必须等前面的事务结束，这样的话查询的时候就无法有其他事务查询新的数据，所以不会产生幻读问题。

#### **2、加间隙锁**

幻读问题的本质在于，没有对查询范围内的所有数据进 (包括不存在的数据）进行加锁，而导致改查询范围内可以被插入新的数据，所以使用间隙锁，对查询的范围进行加锁，此时新插入的数据的事务会因为无法加锁成功而阻塞，所以就避免了幻读。

为解决不同场景的并发事务问题，事务定义了四种隔离级别，每个隔离级别都针对事务并发问题中的一种或几种进行解决，事务级别越高，解决的并发事务问题也就越多，同时也意味着加的锁就越多，所以性能也会越差。不同的隔离级别下它们加锁的情况如下：

### 9.隔离级别mysql

MySQL用mvcc实现

#### **READ_UNCOMMITTED**

事务读取：相当于不加锁

事务写入：相当于加写锁

解决问题：脏写

存在问题：脏读，不可重复读、幻读。



#### **READ_COMMITTED**

事务读取：相当于加读锁（每次select完成都会释放读锁）

事务写入：相当于加写锁

解决问题：脏写、脏读

存在问题：不可重复读、幻读。



#### **REPEATABLE_READ**

事务读取：相当于加读锁（每次select完不会释放锁，而是事务结束后才释放）（如果是Mysql的innodb还会加间隙锁）。

事务写入：相当于加写锁

解决问题：脏写、脏读、不可重复读，幻读（如果是Mysql的innodb则已解决）

存在问题：幻读 （如果是Mysql的innodb则不存在）。

#### **SERIALIZABLE**

不管读取还是修改所有的事务串行化执行，一个事务的执行必须等其他事务结束。

### 10.mysql锁
#### 乐观锁和悲观锁
乐观锁：乐观锁总是假设最好的情况,每次去拿数据的时候都认为别人不会修改,所以不会上锁,但是在更新的时候会判断一下在此期间别人有没有去更新这个数据,可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型,这样可以提高吞吐量**,像数据库提供的类似于write_condition机制,其实都是提供的乐观锁。 
悲观锁：悲观锁总是假设最坏的情况,每次去拿数据的时候都认为别人会修改,所以每次在拿数据的时候都会上锁,这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用,其它线程阻塞,用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制,比如行锁,表锁等,读锁,写锁等,都是在做操作之前先上锁。
乐观锁： GIT,SVN,CVS等代码版本控制管理器,就是一个乐观锁使用很好的场景,例如：A、B程序员,同时从SVN服务器上下载了code.html文件,当A完成提交后,此时B再提交,那么会报版本冲突,此时需要B进行版本处理合并后,再提交到服务器。这其实就是乐观锁的实现全过程。如果此时使用的是悲观锁,那么意味者所有程序员都必须一个一个等待操作提交完,才能访问文件,这是难以接受的。 
悲观锁： 悲观锁的好处在于可以减少并发,但是当并发量非常大的时候,由于锁消耗资源、锁定时间过长等原因,很容易导致系统性能下降,资源消耗严重。因此一般我们可以在并发量不是很大,并且出现并发情况导致的异常用户和系统都很难以接受的情况下,会选择悲观锁进行。



#### *3.*加锁的目的是什么？**

在了解数据库锁之前，首先我们必须要明白加锁的是为了解决什么问题，如果你还不清楚的话，那么从现在开始你就知道了，对数据加锁是为了解决事务的隔离性问题，让事务之间相互不影响，每个事务进行操作的时候都必须先对数据加上一把锁，防止其他事务同时操作数据。如果你想一个人静一静，不被别人打扰，那么请在你的房门上加上一把锁。

#### 4.Redis**锁实是基于什么实现的?**

为了后面大家后面对锁理解的更透彻，所以必须要先解决这个问题，现实生活中家里的锁是锁在门上的，那么数据库的锁又是加在了哪里呢？我在这里可以告诉你，数据库里面的锁是基于索引实现的，在Innodb中我们的锁都是作用在索引上面的，当我们的SQL命中索引时，那么锁住的就是命中条件内的索引节点(行锁)，如果没有命中索引的话，那我们锁的就是整个索引树（表锁），如下图一下锁住的是整棵树还是某几个节点，完全取决于你的条件是否有命中到对应的索引节点。

#### **5.锁的分类。**

数据库里有的锁有很多种，为了方面理解，所以我根据其相关性"人为"的对锁进行了一个分类，分别如下

基于锁的属性分类：共享锁、排他锁。

基于锁的粒度分类：表锁、行锁、记录锁、间隙锁、临键锁。

基于锁的状态分类：意向共享锁、意向排它锁。

##### **共享锁(Share Lock)**

共享锁又称读锁，简称S锁。当一个事务对数据加上读锁之后，其他事务只能对该数据加读锁，而无法对数据加写锁，直到所有的读锁释放之后其他事务才能对其进行加持写锁。 加了共享锁之后，无法再加排它锁，这也就可以避免读取数据的时候会被其它事务修改，从而导致重复读问题。

##### **排他锁（eXclusive Lock）**

排他锁又称写锁，简称X锁；当一个事务对数据加上写锁之后，其他事务将不能再为数据加任何锁，直到该锁释放之后，其他事务才能对数据进行加锁。加了排他锁之后，其它事务就无法再对数进行读取和修改，所以也就出现脏写和脏读的问题。

##### **表锁**

表锁是指上锁的时候锁住的是整个表，当下一个事务访问该表的时候，必须等前一个事务释放了锁才能进行对表进行访问；

特点： 粒度大，加锁简单，容易冲突；

##### **行锁**

行锁是对所有行级别锁的一个统称，比如下面说的记录锁、间隙锁、临键锁都是属于行锁， 行锁是指加锁的时候锁住的是表的某一行或多行记录，多个事务访问同一张表时，只有被锁住的记录不能访问，其他的记录可正常访问；

特点：粒度小，加锁比表锁麻烦，不容易冲突，相比表锁支持的并发要高；

##### **记录锁(Record Lock)**

记录锁属于行锁中的一种，记录锁的范围只是表中的某一条记录，记录锁是说事务在加锁后锁住的只是表的某一条记录。

**触发条件：**精准条件命中，并且命中索引；

**例如：**update user_info set name=’张三’ where id=1 ,这里的id是索引。

**记录锁的作用：**加了记录锁之后数据可以避免数据在查询的时候被修改的重复读问题，也避免了在修改的事务未提交前被其他事务读取的脏读问题。

##### **间隙锁(Gap Lock)**

间隙锁属于行锁中的一种，间隙锁是在事务加锁后其锁住的是表记录的某一个区间，当表的相邻ID之间出现空隙则会形成一个区间，遵循左开右闭原则。

**触发条件：**范围查询，查询条件必须命中索引、间隙锁只会出现在REPEATABLE_READ（重复读)的事务级别中。

**例如**：对应上图的表执行select * from user_info where id>1 and id<4(这里的id是唯一索引) ，这个SQL查询不到对应的记录，那么此时会使用间隙锁。

**间隙锁作用**：防止幻读问题，事务并发的时候，如果没有间隙锁，就会发生如下图的问题，在同一个事务里，A事务的两次查询出的结果会不一样。

##### **临键锁(Next-Key Lock)**

临键锁也属于行锁的一种，并且它是INNODB的行锁默认算法，总结来说它就是记录锁和间隙锁的组合，临键锁会把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住。

**触发条件：**范围查询，条件命中了索引。

**临键锁的作用：**结合记录锁和间隙锁的特性，临键锁避免了在范围查询时出现脏读、重复读、幻读问题。加了临键锁之后，在范围区间内数据不允许被修改和插入。

##### **状态锁**

状态锁包括意向共享锁和意向排它锁，把他们区分为状态锁的一个核心逻辑，是因为这两个锁都是都是描述是否可以对某一个表进行加表锁的状态。

**意向锁的解释**：当一个事务试图对**整个表**进行加锁（共享锁或排它锁）之前，首先需要获得对应类型的意向锁（意向共享锁或意向共享锁）

##### **意向共享锁**

当一个事务试图对**整个表**进行加共享锁之前，首先需要获得这个表的意向共享锁。

##### **意向排他锁**

当一个事务试图对**整个表**进行加排它锁之前，首先需要获得这个表的意向排它锁。

在A事务的操作过程中，后面的每个需要对user_info加持表锁的事务都需要遍历整个索引树才能知道自己是否能够进行加锁，这种方式是不是太浪费时间和损耗数据库性能了？

**所以就有了意向锁的概念：**如果当事务A加锁成功之后就设置一个状态告诉后面的人，已经有人对表里的行加了一个排他锁了，你们不能对整个表加共享锁或排它锁了，那么后面需要对整个表加锁的人只需要获取这个状态就知道自己是不是可以对表加锁，避免了对整个索引树的每个节点扫描是否加锁，而这个状态就是我们的意向锁。

### 11.MVCC

#### **一、什么是MVCC？**

MVCC是在并发访问数据库时，通过对数据做多版本管理，避免因为写锁的阻塞而造成读数据的并发阻塞问题。

通俗的讲就是MVCC通过保存数据的历史版本，根据比较版本号来处理数据的是否显示，从而达到读取数据的时候不需要加锁就可以保证事务隔离性的效果



#### **二、Innodb MVCC实现的核心知识点**

1、事务版本号

2、表的隐藏列。

3、undo log

4、 read view



##### **2-1、事务版本号**

每次事务开启前都会从数据库获得一个自增长的事务ID，可以从事务ID判断事务的执行先后顺序。



##### **2-2、表格的隐藏列**

**DB_TRX_ID:** 记录操作该数据事务的事务ID；

**DB_ROLL_PTR：**指向上一个版本数据在undo log 里的位置指针；

**DB_ROW_ID:** 隐藏ID ，当创建表没有合适的索引作为聚集索引时，会用该隐藏ID创建聚集索引;



##### **2-3、Undo log**

Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。

**Undo log 的用途**

（1）保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。

（2）用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。



##### **2-4、事务版本号、表格的隐藏列、undo log的关系**

我们模拟一次数据修改的过程来让我们了解下事务版本号、表格隐藏的列和undo log他们之间的使用关系。

**（1）首先准备一张原始原始数据表**

![img](https://pic3.zhimg.com/80/v2-aebde29dc2e7b2dc76d5e6a42698f3b2_720w.jpg)



**（2）开启一个事务A：** 对user_info表执行 update user_info set name =“李四”where id=1 会进行如下流程操作

1、首先获得一个事务编号 104

2、把user_info表修改前的数据拷贝到undo log

3、修改user_info表 id=1的数据

4、把修改后的数据事务版本号改成 当前事务版本号，并把DB_ROLL_PTR 地址指向undo log数据地址。



**（3）最后执行完结果如图：**

![img](https://pic1.zhimg.com/80/v2-1daaeab59495ff3378dae24ea21dc158_720w.jpg)

##### **2-5、Read view**

在innodb 中每个事务开启后都会得到一个read_view。副本主要保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号，其实简单的说这个副本中保存的是系统中当前不应该被本事务看到的其他事务id列表。



#### **Read view 的几个重要属性**

**trx_ids:** 当前系统活跃(未提交)事务版本号集合。

**low_limit_id:** 创建当前read view 时“当前系统最大**事务版本号**+1”。

**up_limit_id:** 创建当前read view 时“系统正处于**活跃事务**最小版本号”

**creator_trx_id:** 创建当前read view的事务版本号；



#### **Read view 匹配条件**



**（1）数据事务ID <up_limit_id 则显示**

如果数据事务ID小于read view中的最小活跃事务ID，则可以肯定该数据是在当前事务启之前就已经存在了的,所以可以显示。

**（2）数据事务ID>=low_limit_id 则不显示**

如果数据事务ID大于read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不予显示。

**（3） up_limit_id <=**数据事务ID<**low_limit_id 则与活跃事务集合**trx_ids**里匹配**

如果数据的事务ID大于最小的活跃事务ID,同时又小于等于系统最大的事务ID，这种情况就说明这个数据有可能是在当前事务开始的时候还没有提交的。

所以这时候我们需要把数据的事务ID与当前read view 中的活跃事务集合trx_ids 匹配:

**情况1:** 如果事务ID不存在于trx_ids 集合（则说明read view产生的时候事务已经commit了），这种情况数据则可以显示。

**情况2：** 如果事务ID存在trx_ids则说明read view产生的时候数据还没有提交，但是如果数据的事务ID等于creator_trx_id ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。

**情况3：** 如果事务ID既存在trx_ids而且又不等于creator_trx_id那就说明read view产生的时候数据还没有提交，又不是自己生成的，所以这种情况下此数据不能显示。



**（4）不满足read view条件时候，从undo log里面获取数据**

当数据的事务ID不满足read view条件时候，从undo log里面获取数据的历史版本，然后数据历史版本事务号回头再来和read view 条件匹配 ，直到找到一条满足条件的历史数据，或者找不到则返回空结果；



------

#### **三、Innodb实现MCC的原理**

![img](https://pic3.zhimg.com/80/v2-a086ef515e7d0a023ca3cfcc5759c7f6_720w.jpg)

##### **3-1、模拟MVCC实现流程**

下面我们通过开启两个同时进行的事务来模拟MVCC的工作流程。



**（1）创建user_info表，插入一条初始化数据**

![img](https://pic3.zhimg.com/80/v2-2d342b1506470aeb3d1a37194058d07e_720w.jpg)



**（2）事务A和事务B同时对user_info进行修改和查询操作**

事务A：update user_info set name =”李四”

事务B：select * fom user_info where id=1



**问题：**

先开启事务A ，在事务A修改数据后但未进行commit，此时执行事B。最后返回结果如何。



**执行流程如下图：**

![img](https://pic3.zhimg.com/80/v2-f52d8559ba58256df25735e761fd7ae2_720w.jpg)

**执行流程说明：**

**（1）事务A：开启事务，首先得到一个事务编号102；**

**（2）事务B：开启事务，得到事务编号103；**

**（3）事务A：进行修改操作，首先把原数据拷贝到undolog,然后对数据进行修改，标记事务编号和上一个数据版本在undo log的地址。**

![img](https://pic1.zhimg.com/80/v2-58fbc9a01ce4c9b6e1cd746b2f677288_720w.jpg)



**（4）事务B： 此时事务B获得一个read view ，read view对应的值如下**

![img](https://pic3.zhimg.com/80/v2-e91614af92ca6ff116cfe66ecde57e1e_720w.jpg)

**（5）事务B： 执行查询语句，此时得到的是事务A修改后的数据**

![img](https://pic4.zhimg.com/80/v2-d0d19b3ed3a6bd8c26658441d977534f_720w.jpg)



**（6）事务B： 把数据与read view进行匹配，**

数据事务ID为102 等于up_limit_id （这里不小于up_limit_id）

数据事务ID为102 小于low_limit_id

数据事务ID为102存在于 trx_ids，

数据事务ID为102不等于creator_trx_id

发现不满足read view显示条件，所以从undo lo获取历史版本的数据再和read view进行匹配，最后返回数据如下。

![img](https://pic3.zhimg.com/80/v2-3ba487ad60688eb0ae3cac36e765232a_720w.jpg)

------

#### **四、补充**

##### **各种事务隔离级别下的Read view 工作方式**

RC(read commit) 级别下同一个事务里面的每一次查询都会获得一个新的read view副本。这样就可能造成同一个事务里前后读取数据可能不一致的问题（重复读）

![img](https://pic3.zhimg.com/80/v2-0c77f30980dc7e45f5aaac8a574e8672_720w.jpg)



RR(重复读)级别下的一个事务里只会获取一次read view副本，从而保证每次查询的数据都是一样的。

![img](https://pic1.zhimg.com/80/v2-82eeabba61c97def5d19aeb3cb77182c_720w.jpg)



READ_UNCOMMITTED 级别的事务不会获取read view 副本。

##### **快照读和当前读**



**快照读**

快照读是指读取数据时不是读取最新版本的数据，而是基于历史版本读取的一个快照信息（mysql读取undo log历史版本) ，快照读可以使普通的SELECT 读取数据时不用对表数据进行加锁，从而解决了因为对数据库表的加锁而导致的两个如下问题

1、解决了因加锁导致的修改数据时无法对数据读取问题;

2、解决了因加锁导致读取数据时无法对数据进行修改的问题;



**当前读**

当前读是读取的数据库最新的数据，当前读和快照读不同，因为要读取最新的数据而且要保证事务的隔离性，所以当前读是需要对数据进行加锁的（Update delete insert select ....lock in share mode select for update 为当前读）



------

#### **五、讨论**

##### **MVCC是否有解决幻读问题？**

看到有很多网友对这个话题有讨论，这里补充一下和大家理一理这个问题，首先我通过验证得出来的结论是MVCC不存在幻读问题的，但也并不是说MVCC解决了幻读的问题，经过理论的推断和验证得到的结论是在**快照读的情况下可以避免幻读问题，在当前读的情况下则需要使用间隙锁来解决幻读问题的**。

##### 数据库幻读的解决方案

MySQL幻读可以采用两种方式解决：1、加上锁（Next-Key Lock） 2、将隔离级别提升为序列化

在可重复读的隔离级别下，有两种读：快照度和当前读。在快照读的情况下，MySQL使用的是MVCC使得事务读取的是事务ID小于Read View中的最小ID的数据，不会发生幻读（幻读一定是在事务开始后才添加进去的，ID一定更大），一般情况下select使用的是快照读。但是Update、Delete语句中如果有where语句进行过滤查询或者使用了for update语句，那么使用的就不是快照中的数据，而是当前读，就可能会出现幻读，也即两次查询出来的行数不一致。

这个时候虽然已经锁住了当前行，但是对于Insert进去的数据并没有锁住，因此才会出现幻读。此时可以通过加上间隙锁（Gap-Lock）来避免幻读，对于不存在的数据记录也加上锁。（Next-Key Lock = Gap-Lock（间隙锁）+Record Lock（行锁））



##### **MVCC不存在幻读问题（RR级别的情况下）**

首先确认一点MVCC属于快照读的，在进行快照读的情况下是不会对数据进行加锁，而是基于事务版本号和undo历史版本读取数据，其实上面的文章已经说得很清楚了，我们根据上面的MVCC流程来推导，无论如何在MVCC的情况下都是不会出现幻读的问题的，如下图。

1、开启事务1，获得事务ID为1。

2、事务1执行查询，得到readview。

3、开始事务2。

4、执行insert。

5、提交事务2。

6、执行事务1的第二次查询 (因为这里是RR级别，所以不会再去获得readview,还是使用第一次获得的readview)

7、最后得到的结果是，插入的数据不会显示，因为插入的数据事务ID大于等于 readview里的最大活跃事务ID。

### 12.Mysql 核心日志（redolog、undolog、binlog）

三个核心日志分别是 binlog 、redo log、undo log， 这里面binlog 是server层的日志，而redo log 和undo log都是引擎层（innodb）的日志，要换其他数据引擎那么就未必有redo log和undo log了。

#### ***binlog\***

#### binlog **设计目标**

binlog 是作为mysql操作记录归档的日志，这个日志记录了所有对数据库的数据、表结构、索引等等变更的操作。也就是说只要是对数据库有变更的操作都会记录到binlog里面来， 可以把数据库的数据当成我们银行账户里的余额，而binlog就相当于我们银行卡的流水。账户余额只是一个结果，至于这个结果怎么来的，那就必须得看流水了。而同样在mysql里我们就是通过binlog来归档、验证、恢复、同步数据。

#### binlog **记录内容**

binlog应该说是Mysql里最核心的日志， 它记录了除了查询语句(select、show)之外的所有的 `DDL` 和 `DML` 语句,也就意味着我们基本上所有对数据库的操作变更都会记录到binlog里面。binlog以事件形式记录，不仅记录了操作的语句，同时还记录了语句所执行的消耗的时间。 binlog 有三种记录格式，分别是ROW、STATEMENT、MIXED。

**1、ROW：** 基于变更的数据行进行记录，如果一个update语句修改一百行数据，那么这种模式下就会记录100行对应的记录日志。

**2、STATEMENT：**基于SQL语句级别的记录日志，相对于ROW模式，STATEMENT模式下只会记录这个update 的语句。所以此模式下会非常节省日志空间，也避免着大量的IO操作。

**3、MIXED：** 混合模式，此模式是ROW模式和STATEMENT模式的混合体，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog。

这三种模式需要注意的是：使用 row 格式的 binlog 时，在进行数据同步或恢复的时候不一致的问题更容易被发现，因为它是基于数据行记录的。而使用 mixed 或者 statement 格式的 binlog 时，很多事务操作都是基于SQL逻辑记录，我们都知道一个SQL在不同的时间点执行它们产生的数据变化和影响是不一样的，所以这种情况下，数据同步或恢复的时候就容易出现不一致的情况。



#### binlog **写入策略**

在进行事务的过程中，首先会把binlog 写入到binlog cache中（因为写入到cache中会比较快，一个事务通常会有多个操作，避免每个操作都直接写磁盘导致性能降低），事务最终提交的时候再吧binlog 写入到磁盘中。当然事务在最终commit的时候binlog是否马上写入到磁盘中是由参数 sync_binlog 配置来决定的。

**1、sync_binlog=0** 的时候，表示每次提交事务binlog不会马上写入到磁盘，而是先写到page cache,相对于磁盘写入来说写page cache要快得多,不过在Mysql 崩溃的时候会有丢失日志的风险。

**2、sync_binlog=1** 的时候，表示每次提交事务都会执行 fsync 写入到磁盘 ；

**3、sync_binlog的值大于1** 的时候，表示每次提交事务都 先写到page cach，只有等到积累了N个事务之后才fsync 写入到磁盘，同样在此设置下Mysql 崩溃的时候会有丢失N个事务日志的风险。



很显然三种模式下，sync_binlog=1 是强一致的选择，选择0或者N的情况下在极端情况下就会有丢失日志的风险，具体选择什么模式还是得看系统对于一致性的要求。



------

#### ***redo log\***

#### redo log **设计目标**

redo log 是属于引擎层(innodb)的日志，它的设计目标是支持innodb的“事务”的特性，事务ACID特性分别是原子性、一致性、隔离性、持久性， 一致性是事务的最终追求的目标，隔离性、原子性、持久性是达成一致性目标的手段，根据的文章我们已经知道隔离性是通过锁机制来实现的。 而事务的原子性和持久性则是通过redo log 和undo log来保障的。

redo log 能保证对于已经COMMIT的事务产生的数据变更，即使是系统宕机崩溃也可以通过它来进行数据重做，达到数据的一致性，这也就是事务持久性的特征，一旦事务成功提交后，只要修改的数据都会进行持久化，不会因为异常、宕机而造成数据错误或丢失,所以解决异常、宕机而可能造成数据错误或丢是redo log的核心职责。

#### **redo log记录的内容**

redo log记录的是操作数据变更的日志，听起来好像和binlog有类似的地方，有时候我都会想有了binlog为什么还要redo log，当然从其它地方可以找到很多的理由，但是我认为最核心的一点就是redo log记录的数据变更粒度和binlog的数据变更粒度是不一样的，也正因为这个binlog是没有进行崩溃恢复事务数据的能力的。

以修改数据为例，binlog 是以表为记录主体，在ROW模式下，binlog保存的表的每行变更记录。

比如update tb_user set age =18 where name ='赵白' ，如果这条语句修改了三条记录的话，那么binlog记录就是

```text
 UPDATE `db_test`.`tb_user` WHERE @1=5 @2='赵白' @3=91 @4='1543571201' SET  @1=5 @2='赵白' @3=18 @4='1543571201'
 UPDATE `db_test`.`tb_user` WHERE @1=6 @2='赵白' @3=91 @4='1543571201' SET  @1=5 @2='赵白' @3=18 @4='1543571201'
 UPDATE `db_test`.`tb_user` WHERE @1=7 @2='赵白' @3=91 @4='1543571201' SET  @1=5 @2='赵白' @3=18 @4='1543571201'
```

redo log则是记录着磁盘数据的变更日志，以磁盘的最小单位“页”来进行记录。上面的修改语句，在redo log里面记录得可能就是下面的形式。

```text
 把表空间10、页号5、偏移量为10处的值更新为18。
 把表空间11、页号1、偏移量为2处的值更新为18。
 把表空间12、页号2、偏移量为9处的值更新为18。
```

当我们把数据从内存保存到磁盘的过程中，Mysql是以页为单位进行刷盘的，这里的页并不是磁盘的页，而是Mysql自己的单位，Mysql里的一页数据单位为16K，所以在刷盘的过程中需要把数据刷新到磁盘的多个扇区中去。 而把16K数据刷到磁盘的每个扇区里这个过程是无法保证原子性的，也就意味着Mysql把数据从内存刷到磁盘的过程中，如果数据库宕机，那么就可能会造成一步分数据成功，一部分数据失败的结果。而这个时候通过binlog这种级别的日志是无法恢复的，一个update可能更改了多个磁盘区域的数据，如果根据SQL语句回滚，那么势必会让那些已经刷盘成功的数据造成数据不一致。所以这个时候还是得需要通过redo log这种记录到磁盘数据级别的日志进行数据恢复。

#### **redo log写入策略**

redo lo占用的空间是一定的，并不会无线增大（可以通过参数设置），写入的时候是进顺序写的，所以写入的性能比较高。当redo log空间满了之后又会从头开始以循环的方式进行覆盖式的写入。



在写入redo log的时候也有一个redo log buffer，日志什么时候会刷到磁盘是通过innodb_flush_log_at_trx_commit 参数决定。

innodb_flush_log_at_trx_commit=0 ，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;

innodb_flush_log_at_trx_commit=1，表示每次事务提交时都将 redo log 直接持久化到磁盘；

innodb_flush_log_at_trx_commit=2，表示每次事务提交时都只是把 redo log 写到 page cache。



除了上面几种机制外，还有其它两种情况会把redo log buffer中的日志刷到磁盘。

1、定时处理：有线程会定时(每隔 1 秒)把redo log buffer中的数据刷盘。

2、根据空间处理：redo log buffer 占用到了一定程度( innodb_log_buffer_size 设置的值一半)占，这个时候也会把redo log buffer中的数据刷盘。



------

#### *undo log*

#### **undo log设计目标**

redo log 是也属于引擎层(innodb)的日志，从上面的redo log介绍中我们就已经知道了，redo log 和undo log的核心是为了保证innodb事务机制中的持久性和原子性，事务提交成功由redo log保证数据持久性，而事务可以进行回滚从而保证事务操作原子性则是通过undo log 来保证的。

要对事务数据回滚到历史的数据状态，所以我们也能猜到undo log是保存的是数据的历史版本，通过历史版本让数据在任何时候都可以回滚到某一个事务开始之前的状态。undo log除了进行事务回滚的日志外还有一个作用，就是为数据库提供[MVCC](https://zhuanlan.zhihu.com/p/52977862)多版本数据读的功能。



#### **undo log记录内容**

在Mysql里数据每次修改前，都首先会把修改之前的数据作为历史保存一份到undo log里面的，数据里面会记录操作该数据的事务ID，然后我们可以通过事务ID来对数据进行回滚。

比如我们执行 update user_info set name =“李四”where id=1的时候。整个undo log的记录形式会如下。

**1、首先准备一张原始原始数据表**



![img](https://pic4.zhimg.com/80/v2-4cf022f3cf13d09a7a3a6d6346bbd18f_720w.png)





**2、开启一个事务A：** 对user_info表执行 update user_info set name =“李四”where id=1 会进行如下流程操作

1、首先获得一个事务编号 104

2、把user_info表修改前的数据拷贝到undo log

3、修改user_info表 id=1的数据

4、把修改后的数据事务版本号改成 当前事务版本号，并把DB_ROLL_PTR 地址指向undo log数据地址。



**3、最后执行完结果如图：**



![img](https://pic3.zhimg.com/80/v2-465a2cab930378790017b5bc8ed24b3a_720w.png)

------





#### ***redo、undo、binlog的生成流程与崩溃恢复\***



当我们执行update user_info set name =“李四”where id=1 的时候大致流程如下：

**1、从磁盘读取到id=1的记录，放到内存。**

**2、记录undo log 日志。**

**3、记录redo log (预提交状态)**

**4、修改内存中的记录。**

**5、记录binlog**

**6、提交事务，写入redo log (commit状态)**

![img](https://pic4.zhimg.com/80/v2-346d0dcc7b5e7a3295357e099ad54f7b_720w.jpg)



我们根据上面的流程来看，如果在上面的某一个阶段数据库崩溃，如何恢复数据。

**1、在第一步、第二步、第三步执行时据库崩溃：**因为这个时候数据还没有发生任何变化，所以没有任何影响，不需要做任何操作。

**2、在第四步修改内存中的记录时数据库崩溃**：因为此时事务没有commit，所以这里要进行数据回滚，所以这里会通过undo log进行数据回滚。

**3、第五步写入binlog时数据库崩溃：**这里和第四步一样的逻辑，此时事务没有commit，所以这里要进行数据回滚，会通过undo log进行数据回滚。

**4、执行第六步事务提交时数据库崩溃：**如果数据库在这个阶段崩溃，那其实事务还是没有提交成功，但是这里并不能像之前一样对数据进行回滚，因为在提交事务前,binlog可能成功写入磁盘了，所以这里要根据两种情况来做决定。

如果binlog存在事务记录：那么就**"认为"**事务已经提交了，这里可以根据redo log对数据进行重做。其实你应该有疑问，其实这个阶段发生崩溃了，最终的事务是没提交成功的,这里应该对数据进行回滚。 这里主要的一个考虑是因为binlog已经成功写入了，而binlog写入后，那么依赖于binlog的其它扩展业务（比如：从库已经同步了日志进行数据的变更）数据就已经产生了，如果这里进行数据回滚，那么势必就会造成主从数据的不一致。

另外一种情况就 是binlog不存在事务记录，那么这种情况事务还未提交成功，所以会对数据进行回滚。

### 13.Mysql索引





#### **一、什么是索引**

索引是一种利用某种规则的数据结构与实际数据的关系加快数据查找的功能；索引数据节点中有着实际文件的位置，因为索引是根据特定的规则和算法构建的,在查找的时候遵循索引的规则可以快速查找到对应数据的节点，从而达到快速查找数据的效果；其实宏观来说索引其实是一种概念而不是具体的某项技术，只是我们在某个技术中运用得比较广泛和鲜明（比如说数据库）渐渐的有了特定领域的标签，其实在生活中索引的使用无处不在，比如说：书本里的目录；读书时的座位号，考试编号都有类似索引的功能;

总结来所有通过某规则数据结构和实际目标关联，根据特定规则算法快速寻址的功能都可以称之为索引；

------

#### **二、为什么要用索引**

首先我们看下在没有索引的情况下是怎么查找数据的：

我们用一个例子来解释比较直观

（1）没有索引的情况下访问数据：

![img](https://pic2.zhimg.com/v2-6a6640f82b1fa2b99f45390771d24ff9_720w.jpg?source=d16d100b)



（2）使用平衡二叉树结构作为索引的情况下访问数据：

![img](https://pic2.zhimg.com/v2-75c2b48de87b88fadb3a20e58c8e0daf_720w.jpg?source=d16d100b)



第一张图没有使用索引我们会进行顺序查找，依照数据顺序逐个进行匹配，进行了5次寻址才查询出所需数据，第二张图用了一个简单的平衡二叉树索引之后我们只用了3次，这还是数据量小的情况下，数据量大了效果更明显，所以总结来说创建索引就是为了加快数据查找速度；

------

#### **三、Innodb 的索引选择**

Mysql 的默认存储引擎innodb使用B+树作为索引的存储结构，为了让我们能更深入理解B+树，所以我们会对B+树的衍生过程做一些了解。



##### **1、数组和链表的选择**

作为最基础的数据存储结构数组和链表，是选用数组还是选择链表来作为索引存储的基本结构呢？首先我们需要从索引和两种数据结构的特性来分析。

**数组的特性：** 查找快、但是插入、修改数据慢。

**链表的特性：** 查找慢、插入、修改快。

在数据库的业务场景里插入、修改、查询都是比较频繁的操作，选链表还是数组好像都不完美。既然都不完美，那么我们只能退而求其次，看谁比较容易去完善。从完善的角度来看，那么我们就会从数组里发现一个致命的问题，数组的修改和移动都会导致数组大量的元素迁移，而且在迁移的过程中是不能查找数据的，数组元素迁移没有完成查询出来的数据就可能是错的，这样就导致数组在频繁插入和修改的过程中不仅仅是修改和插入本身慢，而且因为这个而导致查询也用不了，显然这个问题对于修改和插入频繁的数据库来说是无法忍受的。所以我们只能把链表作为索引的基础结构了，那么剩下的就是如何解决链表查询小笼包慢的问题了。



##### **2、从链表到二叉树**

如果使用链表来存储数据，那么必须要解决的一个问题就是要解决链表的查询效率问题，我们必须通过一种算法来解决链表查找数据慢的问题，而这里这里就用到了二分查找法，利用二分法思维把链表拆成N个对半分的节点，然后形成了一个数据结构叫二叉查找树，使用了二分法思维衍生出来的树大大提升了查找的性能。

![img](https://pic3.zhimg.com/v2-83e2891607ba7b761832914b3380d5a6_720w.jpg?source=d16d100b)

##### **3、从二叉查树到平衡二叉树**

二叉查找树极大的提升了链表查找数据的效率，不过我们又发现了一个问题，就是二叉查找树的“高度”不可控，一旦树的节点插入变成向下图一样的结构。

![img](https://pica.zhimg.com/v2-9f41f3b7bd0a9eee7fff66fd0c5e25cb_720w.jpg?source=d16d100b)



如果树的节点不可控编程变成线性结构，那么就会极大的降低我们的查询效率，所以我们就又需要一种算法来保证二叉树节点的平衡，让树的节点高度差不会太大，这个时候就衍生了一些平衡算法，最终我们的二叉树就有像AVL树和红黑树这些新产品，我们也称这些新产品为平衡二叉树，，平衡二叉树通常会保证树的左右两边的节点层级相差不会大于2。



![img](https://pic2.zhimg.com/v2-833fc4079d68de326add7b5bbae503ae_720w.jpg?source=d16d100b)



![img](https://pic1.zhimg.com/v2-e863bda9d8bd6e35cc203443b3063d6a_720w.jpg?source=d16d100b)



##### **4、从平衡二叉树到B树**

平衡二叉树的出现好像很接近于我们的理想状态了，但好像还有什么优化的空间，我们通过上面两个树的演化过程发现，影响这棵树的查询效率的决定性因素就是树的高度，只要树的层级越少，那么树的查询效率就越高，本着这个原则我们就思考每个节点能不能多存点 数据，只要每个数节点的数据保存的越多，那么我们树的层级就会越少，

B树相对平衡二叉树最大的一个改变，就是B树的每个节点可存储的关键字增多了，特别是在B树应用到数据库中的时候，节点存储关键字的数量充分利用了磁盘块IO的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来），B树只要把节点大小限制在磁盘快大小范围，这样就可以只需要一次IO就读取到节点所有数据，节点存储了更多的关键字，但是并不会影响IO的次数。B树树相对于之前节点可以存储更多的关键字，所以树的层级会比原来少很多，树的层级减少了，那么检索的效率就会大大提升。





![img](https://pica.zhimg.com/v2-2c2264cc1c6c603dfeca4f84a2575901_720w.jpg?source=d16d100b)







##### **5、从B树到B+树**

**其实B树已经接近我们的理想预期了，但是还是能从B树的上面找到可以优化的地方，比如以下几个方面：**

1、B树的节点同时保存了索引的key和数据值（如果节点只保存索引key不保存值，那么是不是会把索引树的层层级更进一步的减少）。

2、因为每个节点保存了数据值，这样的话查询不同的数据效率就会显得不稳定，有些在树的第一层匹配成功就返回，有些则可能需要匹配到树的最后一层才返回。

3、如果要查询所有数据，那么就必须遍历整个B树的每个节点。



**B+树在B树的基础上 又做了一些优化，B+树主要做了下面几点的优化。**

1、B+跟B树不同，B+树的非叶子节点不保存实际的数据，只保存索引key，所有的数据都会保存到叶子节点。

**树层级变少：**如果非叶子节点不保存实际的数据值，而只保存索引key，那么相对于B树来说B+树的每个**非叶子**节点存储的索引key会更多，所以树的层级也会更少，那么查询效率也会更快。

**查询更稳定：**因为B+所有数据值都是存在**叶子**节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定；

**遍历整个树更快：**B+树遍历整棵树只需要遍历所有的**叶子**节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。



2、B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。

**排序和范围查询更方便**：B+树所有的叶子节点数据构成了一个有序链表，这样在进行数据排序和询范围大小查询数据的时候更方便，数据紧密性也更高。





![img](https://pic2.zhimg.com/v2-4572578c91103aba4819d24f39741e20_720w.png?source=d16d100b)



**（百度百科算法结构示意图）**



总结来说，从平衡二叉树、B树、B+树，总体来看它们的贯彻的思想是相同的，在链表的基础上，如何采用二分法和数据平衡策略来提升查找数据的速度。不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的，在这个基础上，B+树的查找速度快、性能稳定、排序快、扫表快等诸多特点也就让Mysql选择了B+树来作为索引的存储结构。
#### B+树的特征：
1、有K个孩子的节点就有K个关键字。也就是孩子数量=关键字数。
2、非叶子节点的关键字也会同时存在在子节点中，并且是在子节点中所有关键字的最大或最小。
3、非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。
4、所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。

#### Hash索引与B+树索引的区别
由于Hash索引结构和B+ 树不同，因此在索引使用上也会有差别：

（1）Hash索引不能进行范围查询，而B+树可以。
这是因为Hash索引指向的数据是无序的，而B+ 树的叶子节点是个有序的链表。

（2）Hash索引不支持联合索引的最左侧原则（即联合索引的部分索引无法使用），而B+树可以。
对于联合索引来说，Hash索引在计算Hash值的时候是将索引键合并后再一起计算Hash值，所以不会针对每个索引单独计算Hash值。因此如果用到联合索引的一个或多个索引时，联合索引无法被利用。

（3）Hash索引不支持Order BY排序，而B+树支持。
因为Hash索引指向的数据是无序的，因此无法起到排序优化的作用，而B+树索引数据是有序的，可以起到对该字段Order By 排序优化的作用。

（4）Hash索引无法进行模糊查询。而B+ 树使用 LIKE 进行模糊查询的时候，LIKE后面前模糊查询（比如%开头）的话可以起到优化的作用。
（5）Hash索引在等值查询上比B+树效率更高。
不过也存在一种情况，就是索引列的重复值如果很多，效率就会降低。这是因为遇到Hash冲突时，需要遍历桶中的行指针来进行比较，找到查询的关键字非常耗时。所以Hash索引通常不会用到重复值多的列上，比如列为性别，年龄等。
哈希索引在内存中，b+树索引在磁盘上


#### mysql为什么不用红黑树而用B+树
首先,红黑树是一种近似平衡二叉树（不完全平衡）,结点非黑即红的树,它的树高最高不会超过 2*log(n),因此查找的时间复杂度为 O(log(n)),无论是增删改查,它的性能都十分稳定； 但是,红黑树本质还是二叉树,在数据量非常大时,需要访问+判断的节点数还是会比较多,同时数据是存在磁盘上的,访问需要进行磁盘IO,导致效率较低； 而B+树是多叉的,可以有效减少磁盘IO次数；同时B+树增加了叶子结点间的连接,能保证范围查询时找到起点和终点后快速取出需要的数据。
红黑树作为索引数据结构的弊端即是：树的高度过高导致查询效率变慢。

#### **四、补充**

##### **为什么说Mysql的索引树一般都在1-3层的结构？**

经常听到别人说Mysql的索引树一般会在3层，这个是有什么依据？ 其实这个的确是有数据计算支撑的，我们可以根据B+树的原理进行一下数据推算，因为磁盘每页数据为4K，而Mysql的B+树对此又进行了一次调整，在Mysql也有自己的页概念，Mysql里的每一页数据等于磁盘4个页的大小，所以在Mysql里面的一页数据其实是16K，那么也就意味着Mysql里B+树的非叶子节点可存储16K的数据。



然后我们按照一个索引大小，如果字段类型为varchar，长度为10，字符类型为utf8mb4，在不考虑其他因素的影响下，一个索引的大小等于 10 *3+2=32字节，我们按照每个非叶子节点的16K来计算，Mysql索引树每个节点能容纳(16*1024)/32=512个索引key。

**索引树的第一层：**第一层是树的根节点，所以索引树的第一层保存索引Key的数量为512个；

**索引树的第二层：**B+树根节点可保存512个索引key，也就是当前B+树有512个分叉，那么第二层索引树节点个数为512个，保存索引Key的数量=512*512=262144。

**索引树的第三层：**第二层key数量为262144，那么第三层的树节点数量也就是262144，那么第三层索引树节点个数为512个，保存索引Key的数量=262144*512=134217728。

根据一个计算我们可以基本得出，类型varchar，长度为10，字符类型为utf8mb4的索引字段，数据在512条之内树结构只有一层。数据在262144之内树只有两层，数据在134217728之内，索引树都会保持在3层之内，而我们的表数据一般而言都保持在千万级以内，所以说Mysql的索引树一般都在1-3层。

### 14.Mysql Join算法原理

#### **一、Simple Nested-Loop Join（简单的嵌套循环连接）**

简单来说嵌套循环连接算法就是一个双层for 循环 ，通过循环外层表的行数据，逐个与内层表的所有行数据进行比较来获取结果，当执行select * from  user  tb1  left join  level  tb2 on tb1.id=tb2.user_id

**特点：**

Nested-Loop Join 简单粗暴容易理解，就是通过双层循环比较数据来获得结果，但是这种算法显然太过于粗鲁，如果每个表有1万条数据，那么对数据比较的次数=1万 * 1万 =1亿次，很显然这种查询效率会非常慢。

当然mysql 肯定不会这么粗暴的去进行表的连接，所以就出现了后面的两种对Nested-Loop Join 优化算法，在执行join 查询时mysql 会根据情况选择 后面的两种优join优化算法的一种进行join查询。

**特点：**

Nested-Loop Join 简单粗暴容易理解，就是通过双层循环比较数据来获得结果，但是这种算法显然太过于粗鲁，如果每个表有1万条数据，那么对数据比较的次数=1万 * 1万 =1亿次，很显然这种查询效率会非常慢。

当然mysql 肯定不会这么粗暴的去进行表的连接，所以就出现了后面的两种对Nested-Loop Join 优化算法，在执行join 查询时mysql 会根据情况选择 后面的两种优join优化算法的一种进行join查询。

#### **二、Index Nested-Loop Join（索引嵌套循环连接）**

Index Nested-Loop Join其优化的思路 主要是为了减少内层表数据的匹配次数， 简单来说Index Nested-Loop Join 就是通过外层表匹配条件 直接与内层表索引进行匹配，避免和内层表的每条记录去进行比较， 这样极大的减少了对内层表的匹配次数，从原来的匹配次数=外层表行数 * 内层表行数,变成了 外层表的行数 * 内层表索引的高度，极大的提升了 join的性能。

#### **三Block Nested-Loop Join（缓存块嵌套循环连接）**

**Block Nested-Loop Join** 其优化思路是减少内层表的扫表次数，通过简单的嵌套循环查询的图，我们可以看到，左表的每一条记录都会对右表进行一次扫表，扫表的过程其实也就是从内存读取数据的过程，那么这个过程其实是比较消耗性能的。

所以缓存块嵌套循环连接算法意在通过一次性缓存外层表的多条数据，以此来减少内层表的扫表次数，从而达到提升性能的目的。如果无法使用**Index Nested-Loop Join**的时候，数据库是默认使用的是**Block Nested-Loop Join算法的**。

不论是Index Nested-Loop Join 还是 Block Nested-Loop Join 都是在Simple Nested-Loop Join的算法的基础上进行优化，这里 Index Nested-Loop Join 和Nested-Loop Join 算法是分别对Join过程中循环匹配次数和IO 次数两个角度进行优化。

1、使用**Block Nested-Loop Join** 算法需要[开启优化器管理配置的optimizer_switch的设置block_nested_loop为on ](https://link.zhihu.com/?target=https%3A//link.juejin.im/%3Ftarget%3Dhttp%3A//click.aliyun.com/m/40952/)默认为开启，如果关闭则使用Simple Nested-Loop Join 算法； 

通过指令：Show variables like 'optimizer_switc%'; 查看配置

![img](https://pic4.zhimg.com/v2-4298abf35e3b7642a392e1117f5df61b_b.jpg)

2、设置join buffer 的大小

通过join_buffer_size参数可设置join buffer的大小

指令：Show variables like 'join_buffer_size%'; 

![img](https://pic4.zhimg.com/v2-282106d704a0c1294346137807e467bf_b.jpg)





Index Nested-Loop Join 是通过索引的机制减少内层表的循环匹配次数达到优化效果，而Block Nested-Loop Join 是通过一次缓存多条数据批量匹配的方式来减少外层表的IO次数,同时也减少了内层表的扫表次数，通过 理解join 的算法原理我们可以得出以下表连接查询的优化思路。

1、永远用小结果集驱动大结果集(其本质就是减少外层循环的数据数量)

2、为匹配的条件增加索引(减少内层表的循环匹配次数)

3、增大join buffer size的大小（一次缓存的数据越多，那么内层包的扫表次数就越少）

4、减少不必要的字段查询（字段越少，join buffer 所缓存的数据就越多）

### 15.Mysql慢查询的定位和分析。

##### **慢SQL定位（慢查询日志）**

定位慢SQL相对来说很简单，因为Mysql中已经提供了对应的工鞥，我们只需要开启对应的**“慢查询日志”**功能，然后稍作配置即可，开启功能有Mysql会把查询时间大于你设置时间的SQL记录下来，并且保存到一个专门的文件中，你只需要查看这个文件内容就可以找到对应查询慢的SQL了，配置了慢查询日志后，它会记录在设定时间范围内的数据查询和数据修改语句。



##### **慢查询日志的配置**

在mysql 配置文件中 （不出意外应该在/etc/my.conf)，进行下面配置，修改配置后重启mysql生效。

```text
slow_query_log = ON
long_query_time = 5
slow_query_log_file = /opt/soft/mysql/log/slow.log
log_queries_not_using_indexes=on
```



**配置说明：**

slow_query_log ： 开启或关闭慢查询日志。

slow_query_log_file： 指定生成的慢查询日志路径（未设置则和默认和数据文件放一起）。

long_query_time ： 慢查询记录时间阈值，SQL执行超过此时间则会被记录到日志（单位：秒，默认10秒）。

log_queries_not_using_indexes ： 是否记录未使用索引的SQL。



**可通过下面的命令查看配置是否生效：**

```sql
show VARIABLES like '%slow_query_log%'
show VARIABLES like '%slow_query_log_file%'
show ARIABLES like '%long_query_time%'
show VARIABLES like '%log_queries_not_using_indexes%'
```

##### 慢查询的解决

\1. 打开慢日志查询，确定是否有SQL语句占用了过多资源，如果是，在不改变业务原意的前提下，对insert、group by、order by、join等语句进行优化。

\2. 考虑调整MySQL的系统参数： innodb_buffer_pool_size、innodb_log_file_size、table_cache等。

\3. 确定是否是因为高并发引起行锁的超时问题。

\4. 如果数据量过大，需要考虑进一步的分库分表





##### **SQL性能分析（执行计划）**

Mysql提供了一个非常实用的命令（explain）来便于我们对SQL进行分析，如下面图所示，只要在SQL语句前加上一个explain关键字，那么我们就会得到一个SQL的执行计划，这个执行计划会告诉我们SQL中表的读取顺序、查询类型、用到了什么索引、使用索引的长度 、扫描了多少条记录等信息，通过执行计划提供的信息我们可以快速定位到哪些地方可以进行优化。



![img](https://pic3.zhimg.com/v2-53665d0bb98b9e1d3b95daa1ea9a3c9a_720w.jpg?source=d16d100b)







##### **执行计划字段详解**



##### **1、ID**

ID是表示语句执行顺序的标识：

不同的id值，id越大的优先执行；

相同的id值，则由上往下执行，排在上面的语句先执行。



##### **2、select_type**

此列主要用于区分查询语句的类型，通过这个列可以区分SQL属于简单的select、联合查询、子查询等。



**SIMPLE：** 简单的select查询，不包含任何子查询或联合查询。

![img](https://pic3.zhimg.com/v2-5b36b3c0d91041ed5d2ea2329d694028_720w.jpg?source=d16d100b)



**PRIMARY：** 主查询，如果有子查询的话，最外层的查询会被标记为PRIMARY。

**SUBQUERY：** 该语句属于子查询语句。

![img](https://pic1.zhimg.com/v2-897f2c3aa92999629cc9d84bbceb3574_720w.jpg?source=d16d100b)



**DERIVED ：** 生成的临时表的查询语句会被标记为DERIVED 。

![img](https://pic1.zhimg.com/v2-6745d48e64ff42e3ecc09d09c210b463_720w.jpg?source=d16d100b)



**UNION :**    标记为UNION类型的查询语句。

**UNION RESULT:**  从UNION语句中获取结果。

![img](https://pic1.zhimg.com/v2-57c96d3bffa0d9629d43dfa4b4daf31b_720w.jpg?source=d16d100b)



##### **3、table**

显示这一行的数据是来源于哪张表的



##### **4、type（重要）**

type列是定位SQL性能因素最重要的一个指标，通过type我们可以直观的判断一个SQL的性能的基本情况，type包括以下几种类型的查询system 、const 、eq_ref、ref、Range、Index、All，他们的性能依次从高到底，简单来讲我们进行SQL优化的第一步就是要在type列上定位SQL的性能。



**System：** 表只有一行记录（日常基本上不会出现）。

**Const：**  通过索引一次就找到了数据，一般出现在使用了primary key或者unique索引匹配到了数据，匹配的条件是常量（字符串、数字）。

**eq_ref：** 使用了主键索引，或者非空唯一索引，在表中只有一条记录与索引键相匹配，匹配条件是某个表的列（需要转义替换才能拿到值）。

**ref：**  非唯一性索引扫描，和eq_ref 不同的是eq_ref 匹配的是唯一索引，ref它返回所有匹配某个单独值的行,它可能会找到多个符合条件的行。

**range：** 范围数据扫描。

**index:**  全索引扫描，通过扫描整棵索引树获取到结果。

**All：** 全表扫描。



**Const 和eq_ref 的区别**

 两个都是在用到了主键索引或唯一索引的情况下出现，不同的是Const  的where 条件是常量，eq_ref 的where 条件是其他表的某个列，需要对这个列进行转义才能拿到匹配条件的值，也可以简单的理解为，eq_ref 一般为关联查询。



##### **5、possible_keys，key，key_len（重要）**

**possible_keys:**  可能使用到的索引 。

**Key:** 实际使用的索引。如果为空，则说明没有使用索引。

**key_len：**  使用到的索引key的长度，如果为联合索引则显示已命中的联合索引长度之和（如：联合索引为a+b+c ，如果索引命中了a+b ，那么长度就为a+b的索引长度，通常可以通过key_len 来分析联合索引所命中的情况）。



**关于possible_keys 和key的三种关系场景：**

possible_keys !=null&& key!=null ，这是正常使用到了索引的情况。

possible_keys !=null&& key==null ,这种情况一般说明通过索引并不能提升多少效率，一般而言是表的数据量很少，或者是索引的字段离散型不高，执行计划发现用索引和扫表差不多。

possible_keys ==null&& key!=null , 这种情况一般为where条件没有命中索引，但是查询的列是索引字段，也就是查询的列命中覆盖索引情况。



##### **6、ref** 

实际用到的索引是哪个表的列， const代表常量



##### **7、row**

扫描的数据行数，一般来说扫描的数据行数越少，性能越高。



##### **8、Extra列（重要）**

Extra 可以说是对整个SQL做了一个概括性的总结，包括你用了什么索引、排序方式、使用了临时表包含不适合在其他列显示，但是十分重要的信息

using  where;： 使用了where条件。

using index： 使用了覆盖索引。

using filesort  ： 文件排序，意思就是使用了非索引的字段进行排序（通常这种情况需要优化）。

using index sort ： 使用功能索引排序。

using temporary ： 使用了临时表（常见于group by、order by）。

using join buffer  ：  使用了join  buffer缓存。

### 16.SQL优化原则

##### **一、尽可能使用覆盖索引**

简单来说就是我们的列数据只需要通过索引就可以获得数据，不需要从数据表中去遍历数据，这种索引就已经覆盖了需要查询的列数据情况称为覆盖索引。

##### **如何判断是否使用到了覆盖索引？**

根据上一篇的“如何定位和慢SQL和对SQL进行性能分析”中有说到，当我们使用执行计划分析SQL语句时，当Extra字段说明里有Using index 的字样时，就表示使用到了覆盖索引，我们看一个案例。

##### **为什么什么使用到了覆盖索就会提升效率？**

因为覆盖索引的重要性，所以有必要给大家复习下相关知识。在mysql里分为 聚集索引和辅助索引。聚集索引既是索引又是表数据，而辅助索引里保存的则是聚集索引的键，从下面的图我们可以理解使用mysql辅助索引查询数据时都是先从辅助索引获取到聚集索引的索引键，然后用索引键从聚集索引中找到对应的表数据。

所有通过辅助索引查询数据其实都是先从辅助索引查询到聚集索引的索引key，然后用聚集索引的key从聚集索引里面查找数据，通常也称这个过程为回表，按我们上面理解的覆盖索引，当我们查询的字段已经包含在索引里面时，那么我们就不需要从聚集索引里面去查询数据了，因为你所查询的列本身就是索引的key，那么直接返回当前索引的Key就行了，这就个过程就减少了一次从聚集索引查询表数据的过程，当我们查询的数据越多那么这个效率显而易见会得到巨大的提升，所以这也是覆盖索引的好处。

##### **二、最左匹配原则**

最左匹配原则也是我们SQL中需要重点关注的，因为它会直接影响到你的like语句，组合索引是否命中。

最左匹配原则是指，索引在进行模糊匹配时，必须最左边开始匹配，讲起来有电绕口，我们看两个案例你应该就能理解。

**不符合最左匹配规则：**根据最左匹配原则，我们必须先匹配name 才能匹配到phone,再继续匹配age，所以只有phone和age的查询条件都不会命中索引的。

**符合最左匹配规则：**当使用了name条件则可以使用到组合索引

##### **补充： 如何判断组合索引命中了几个？。**

在我们使用命中组合索引的时候如何判断组合索引是否全部命中，还是只命中了一部分? 这里我们执行计划里的key_len来判断。

##### **三、避免隐式转换**

凡是经过了隐式转换的列是无法用到索引的，这个问题也我们开发人员非常容易犯的错误。 隐式转换发生在匹配的条件和列的类型不一致，导致要对列的值进行隐式转换，才能与条件进行匹配

作者：勤劳的小手
链接：https://zhuanlan.zhihu.com/p/172513484
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



##### **四、只获取必要的列**

禁止使用select *  已经是老生常谈的问题了，每个开发人员谈到SQL优化都会说上个一二，但实际开发中往往又很容易忽略这个问题，一方面的确select * 一劳永逸，一个个字段填写还真有点麻烦，另外一个方面还是由于我们对select * 所带来的问题所知甚少，如果遇到SQL性能问题，那么第一个优化的就是select * 。



使用select * from 查询大量非必要的数据会导致如下情况：

1、数据库IO次数增加，数据库每次IO只会读取固定大小的数据，查询的数据越大，那么IO的次数也就越多。

2、消耗内存，数据读取数据是在内存里面做匹配筛选。

3、数据越大网络的传输速度就变慢，查询的数据要经过网络传输给应用程序。

4、无法合理的使用到覆盖索引。

5、影响sort、group by、join语句的性能，在sort、group by、join会用到sort buffer 、 临时表、join buffer、这些都是一块有限的内存空间，查询的字段越多内存装不下了，就只能转而在磁盘中去做对应操作，而磁盘操作的性相比内存性能相差上百倍。

6、字段越多，在应用层面（JVM）产生的对象体积就越大，对象越大就导致垃圾收集得越频繁、垃圾收集越频繁就会降低整个应用的性能。

作者：勤劳的小手
链接：https://zhuanlan.zhihu.com/p/172513484
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



##### **五、控制事务的粒度**

控制事务的粒度核心思想就是减少对数据加锁的时间。 这样可以大大提升对数据修改的并发性能，这方面我们我们可以从两个方向来入手从而减少锁的影响。



###### **1、减少锁的范围：**

innodb引擎锁的最小粒度为行锁，所以我们在修改数据的时候尽量保证只锁定相关的行，而我们知道只有条件命中了索引才会使用行锁，否则就是使用表锁，那么我们在修改数据的时候就要尽量保证条件是使用的索引字段。

比如我们对t_user表的信息进行变更，如果id是索引那么update语句我们尽量写成第二种方式。

```text
 update t_user set age=18 where user_name="186885868953"  //锁整个表。
 
 update t_user set age=18 where id=1;                    //锁id=1的一行。
```



###### **2、减小事务的粒度。**

当我们在进行事务操作时，加锁是从语句执行开始，但是语句执行完后并不会马上释放对应的锁，而是等整个事务提交之后才会释放所有的锁。



比如下面的事务分别做了三个操作， 修改 table_A（执行2秒）、查询table_B（执行1秒）、往table_C 插入数据（执行2秒）；

那么从事务开启，从开始执行update  直到 事务最后commit,（总共6秒）  表table_A 里id=1的数据都是被锁的状态。

```text
 begin
 
 update table_A  set name="张三"  where id=1;          //执行3秒
 
 select * from table_B where id=2;                   //执行1秒
 
 insert table_C   values(1,2);                       //执行2秒
 
 commit;
```



那么我们其实只要调换一下顺序，把update 语句放到最后就能减少数据锁定的时间，甚至我们都可以把查询table_B的语句放到事务之外去执行。

```text
 select * from table_B where id=2;                   //执行1秒
 
 begin
 
 insert table_C   values(1,2);                       //执行2秒
 
 update table_A  set name="张三"  where id=1;        //执行3秒
 
 commit;
```

------

##### 六**、尽量保证join、oder by、group by的字段使用索引**

1、如果join 的字段使用了索引，就会使用Index Nested-Loop Join  算法，这种算法是最高效的。

2、sort、group by 里都涉及到要对数据排序，如果使用了索引，因为Mysql的索引是B+树天然具备顺序的特性，所以可以避免把数据放到sort buffer排序的过程,提升SQL效率。



------

##### 七**、用小结果集驱动大结果集**

其实很多情况下Mysql都已经对此进行了优化，虽然我们实际过程中基本上不需要再操心了，但这个思路原则还是值得我们学习和遵守的。

**用小结果驱动大结果在Join中的体现:**

Join的过程就是先查询出两个表数据，然后通过一个双层循环来遍历外层表 与内层表匹配的过程，如果关联的表有索引，那么Join的过程就类似于下图，左边的就是驱动表、右边的为被驱动表。

假如左边的表数据为5000条，右边的表数据为10000条，以左表为驱动表的话，那么驱动的扫描次数为5000次，数据匹配次数为5000 x 索引的高度。那么 如果换成右表为驱动表，驱动表被扫描的次数就会变成10000次，而数据匹配次数会变成10000 x 索引高度。

通过上面的逻辑，我们可以在进行SQL优化的时候，在保证业务的情况下尽量使用数据量小的那张表作为驱动表可以减少很多CPU计算次数，提升SQL的性能。

### 17.Mysql表设计优化

作者：勤劳的小手
链接：https://zhuanlan.zhihu.com/p/193122866
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



SQL优化阶段主要是对索引的命中情况进行分析，而我们也知道SQL优化并不是万能的，在绝对的数据量情况下，SQL再怎么优化也终究逃不过慢的结局。所以我们就需要从设计层面去提供一些优化的思路，这里我们主要会介绍一些在索引、表结构上的设计优化，这些优化方式会具有一些场景性并不是万能的，但这些案例的思路是大家可以学习的。



#### **索引设计**

索引的重要性是不言而喻的，我们不仅要在查询的时候进行索引的调整，而是在设计阶段就要根据索引的特性来设计合适的索引，不合适的索引不仅没用反而有可能影响我们的SQL效率，在设计索引的时候我们要遵循一些原则，这会帮助我们能设计出高效的索引。



#### **常用字段建立索引**

经常要用于查询的列 where id=?。

经常要用于排序(order by)，分组(group by)的列，因为索引已经排好序了。

有值唯一性限制的列，比如说主键、用户名。



#### **大字段不适合建立索引**

大字段上建立索引会直接导致我们的索引树变得庞大，因为索引树的节点大小是固定的，当字段越大那么每个索引树节点会变多，导致树层级变多，树的层级越多查询的效率就会越慢。而且数据库默认会把索引加载到内存里，大字段建立的索引会变得庞大，所以也会消耗更多的内存空间。



#### **选择合适的字段长度**

字段的大小会影响到几方面的东西，一是字段大会使表变大，二是字段大会使索引树变大并且层级变高，三是索引变大后又会消耗掉更大的内存。



#### **离散性不高的字段不适合建立索引**

离散性不高是指数据的区分度不高，比如性别，只有男和女，那么这种字段上建立索引就算命中了，那么每次扫描的时候还是需要扫描一半的数据，所以这种字段上建立索引并不能提升检索效率。



#### **更新频繁的数据不适合建索引**

索引本质也是数据库额外维护的一个数据结构，当我们的索引字段频繁变更，那势必也造成索引的结构频繁变更，频繁的数据维护和索引的变更维护会造成数据库性能的损耗。



#### **多使用组合索引**

在合适的业务场景下，我们可以多使用组合索引，Mysql的每次查询只会使用一个索引作为检索数据的依据，如果要让索引使用的更有效率，那么我们可以尽可能的让索引匹配出来的数据越少越好，也就是让我们的索引区分度更高，组合索引就能帮我们达到这一效果，比如我们需要寻找一个人，那么使用姓名+地区+年龄 找到数据显然是要比只使用姓名去查找出来的数据要少得多，而组合索引的功效就在于此，当然设计组合索引的时候不要忘了遵守“最左匹配原则”。

#### **表设计优化**

有时候数据库性能是无法单方面通过优化索引来达到性能的显著提升的，表数据量太大，联表查询数据太多都是索引解决不了的问题，这个时候我们就需要考虑到从业务层面对表结构进行一些设计和调整，反而是解决问题的关键。

#### **字段冗余**

字段冗余主要是减少我们的联表查询的操作，因为进行join 查询的时候，我们需要匹配的数据量是呈笛卡尔积的上升的，所以减少联表的操作有时候对效率有显著的提升。

#### **表冗余**

表冗余一般适合统计类的场景，比如说运营需要分析日报、周报、季报、年报等维度的数据，那么这个时候我们通常可以使用表冗余的思路。

#### **数据冷热分离**

表数据的冷热分离思路就是根据业务场景来区分哪些数据是经常要用到的数据(热数据)，哪些数据基本上不用到或者很少用到（冷数据），如果表数据具备这样的业务特性，那么我们可以采用数据冷热分离的方式对数据库进行优化。

### 18.数据库架构优化

#### **一、硬件升级**

作者：勤劳的小手
链接：https://zhuanlan.zhihu.com/p/206719902
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



#### **二、资源池化**

应用和数据库交互频繁的建立连接是非常消耗性能的，所以数据库后来也衍生了很多连接池技术。而我们这里并不是想在这么多成熟的连接池基础上去重复造轮子，而是学习这种资源池的思维，让消耗资源性能的操作预先做好，等到需要需要的时候直接使用即可，池化技术不仅能够减少资源频繁创建销毁过程中的消耗，同时也可以通过池化技术来限制避免无节制的创建资源导致应用崩溃。



##### **连接池创建思路**

1、创建连接池之前我们首先要对连接池的大概情况有个规划，我们需要考虑连接池最多创建多少线程，然后刚创建的时候也许我们没必要一次性把所有连接都创建出来，而是跟随请求动态的递增，刚开始也许需要的连接很少，所以我们可以为连接池设置一个初始值。

2、当请求获取连接时，如果连接池有空间连接则直接返回一个可用的连接。

3、当请求获取连接时,如果连接池没有空闲的连接，则先看下连接池连接数量是否达到最大值，没有则创建一个连接返回。

4、如果空闲连接没了、线程池数量也已经达到最大值了，则看任务队列是否已满，如果任务队列还有未满则提交一个任务放到队列里面，在有限的超时时间内等待执行。

5、如果空闲连接没了、线程池数量也已经达到最大值了，然后任务队列也满了，那没办法就只能拒绝请求了。



##### **可能会遇到的问题**

如果是数据库连接池，那么会有连接超时问题，数据库对每个连接的有wait_timeout的限制，当数据库连接闲置多长时间后会主动关闭连接，而当用户使用这个已经关闭的连接会出现错误。

**解决思路：**

方案一：使用一个专门的线程专门用于检测连接的可用性，可以对检测的线程发送一条select 1查询指令 来检测连接是否可用，然后把断开的连接移出连接池。

方案二：在获取连接之前先检测连接的可用性，但这种方案会有额外的开销。



#### **三、分流（读写分离）**

当数据库出现并发瓶颈时，我们首先可以考虑的是对请求进行分流，把请求分摊个多个节点。而读写分离的策略就是把流量分配给多个数据库，从而减轻单台数据库的压力，通过把写入的请求分配到主库，把读取的请求分发的从库，通过数据库主从的方式来分摊流量。读写分离依赖于数据库的主从机制，通过配置数据库主从复制把主库的数据同步到从库，主库主要处理数据变更请求，从库处理查询请求。



##### **1、数据库主从**

把数据库分为一个主库和多个从库的方式，主库主要处理写入的请求，从库主要处理读数据的请求从而达到分流的效果，数据库主从复制的原理主要是通过binlog来同步事务型SQL的操作来实现。

1、主库事务操作完毕后都会写一条日志到binlog里。

2、然后主库会创建一个专门的log dump的线程，此线程会监控binlog日志，当有新日志时log dump线程会把log信息发送给从库的IO线程.

3、当从库的IO线程收到主库发送过来的日志后，从库的IO线程会把数据写入到从库自己的relay log中去。

4、 然后从库也创建了一个专门的SQL线程，这个线程会监控自己的relay log，当发现有新的log时，就会把用户把log 中的sql 在从库中进行回放。



![img](https://pic4.zhimg.com/v2-aefbfc733cac7ce3d95882adee9b91ab_b.png)



##### **2、读写分离带来的问题**

##### **问题一：主从复制延迟问题**

因为从库和主库之间进行数据同步需要经过一系列的过程，那么这个过程就必定会有一定的延时性，这就会造成一个问题，当我们一个地方往主库中写入数据后，另外一个地方在从库对这个数据进行查询，因为延时的问题，那么查询的时候很可能查询不到最新的数据。

**解决方案：**

1、即时返回：  如果需要得到最新的数据，那么可以在写入数据成功之后就直接返回最新的数据给应用程序。

2、数据冗余：  在写入数据库的同时也写入一份数据到缓存，应用优先从缓存查询数据。

3、从主库读取：实时性强的业务场景，选择直接从主库的数据中读取数据。



##### **问题二：应用层操作数据库的方式变更。**

应用层需要与多个数据库进行交互，应用如何与多个数据库建立连接，如何区分不同的请求分别使用不同的数据源并且区分请求类型而使用功能不同的库。

**解决方案：**

1、动态数据源： 在应用层面配置多个数据源，通过AOP根据操作类型实现数据源的切换，简单直观，但需要对应用进行改造。

2、第三方组件： 使用shard-jdbc ，需要引入第三方jar包配置使用，轻量级对代码无侵入，不需要额外部署。

3、代理产品:    比如DBProxy 、Mycat，需要安装第三方代理产品，完全与应用区分，支持多种数据库，但会增加额外的运营成本，且代理本身的集群高可用。

------

#### **四、分片(分库分表)**

当数量越来越大时，数据备份的时间也加长，索引文件也会变大，当数据库无法缓存所有数据索引只能从磁盘读取数据的时候，我们查询数据的性能也必然会随之降低，那么当遇到这种因为数据量导致性能产生瓶颈的时候，我就可以采用数据分片的思路来解决问题。在数据库数据分片的方式就是进行分库分表,减少单个数据库和表的数据，来提升数据库的性能，数据库分片也是我们常说的分库分表，数据库分库分表通常以垂直拆分、水平拆分两种方式来进行。



##### **1、垂直拆分**

垂直拆分通常是指通过业务的维度来切分数据，把不同业务维度的数据来切分到不通的数据库,来达到数据拆分的目的。

通常垂直拆分会根据业务功能的模板的分类来对数据库进行垂直拆分，如果你的系统分为用户、订单、产品模快；那我们通常会把不同模快的数据库进行拆分。

![img](https://pic4.zhimg.com/v2-1c7d28406421f4f6fb2f10dfd98b5783_b.png)



##### **2、水平拆分**

水平拆分则是根据数据维度拆分,通常会先指定一个拆分规则，把特定规则的数据拆分到不同的数据库和表中。

**拆分方式：**

1、用ID 哈希方式拆分，对ID进行取余的方式决定数据存到哪个库或表。

2、按字段范围区间，比如时间、地区、属性，不同的时间区域数据存放到不同的数据表中。



##### **3、分库分表带来的问题**

##### **问题一：无法使用数据库自增长ID了**

因为数据拆分到了不同的数据库和表中，数据库的自增长ID就无法保证我们的ID唯一性了，所以我们需要自己来生成一个全局的唯一ID。

全局唯一ID的要求：最后生成的ID必须要保证的就是“全局唯一”性，然后因为日常检索的排序需求，这个ID最好能满足排序的需求，同时生成ID时可以自定义一些业务标识，方面我们直接通过ID就可以分析其所属业务场景和分类。

**解决方案：**

**数据库生成：**数据库生成唯一ID不用依赖其他组件，可有序递增，可增加业务标识性能不高。

**Redis自增：**redis生成的ID有序可自增，性能比数据库要高，可增加业务标识,但依赖Redis，性能偏低。

**UUID：**不依赖任何组件，性能高，但不具备有序性和业务含义，生成的ID由32 个 16 进制数字组成的字符串比较占用空间。

**Snowflake ：**可生成有序递增的ID，也可增加业务标识，但依赖于系统的时间戳，一旦系统时间不准就有可能生成重复的 ID。



##### **问题二：如何定位数据在哪个表**

经过分库分表后就不能像以前一样直接查询某个表了，而是首先要根据其业务特性和数据规则定位到查询的数据在哪个表中，因为我们拆分数据的时候是根据某一个字段的规则进行拆分的，如果想要定位到数据的位置，那么我们每次查询的时候就必须带上分区键（分库分表依赖的字段）才行。

假如根据ID作为分库分表的字段. 那么每次查询都要带上ID，如果要通过名称查询数据，那么就需要通过名称先找到ID，再根据D查询数据，这样的话又会需要建立一个名称和ID的映射表才行。



##### **问题三：Join查询问题。**

经过分库分表后表会存在于不同的库中，所以我们就不能像之前一样通过Join去连表查询数据了。

**解决方案：**

1、冗余：可以冗余一些不太容易变化的数据避免使用Join查询，比如把哪些不太容易变更的表（比如配置信息）冗余一份到每个库中，也可以通过把需要join查询的列冗余一个字段到当前表中（比如过在订单表冗余一个用户姓名字段）。

2、代码筛选：先把多个表的数据查询出来然后在代码里再去做筛选。



##### **问题四：无法直接统计数据**

拆分了数据之后同时也不能直接对表数据进行count了，因为数据都存在于不同的表，这样的话我们通常又会需要专门用一个表记录统计数据又或者放缓存里。



##### **问题五：数分页问题**

我们的运营系统通常需要查询的是某个业务块的所有数据，分页也是在所有数据的基础上进行的，而经过分库分表后数据被分布在不同的库和表中，这样我们就无法直接对数据进行分页了。

**解决方案：**

1、通常我们会通过中间键完成，中间键先把一定的数据查询到缓存里，然后在缓存里进行逻辑分页。但这种方式通常来说性能不佳，页数越靠后性能就会越慢，因为需要查询和扫描的数据越到后面越多了。

2、冗余一份全量数据，比如说把全量的数据放到Elasticsearch 、MogoDB里，后台通过查询Elasticsearch 查询数据进行分页。



##### **问题六：分布式事务问题**

对于单库来说，数据库事务ACID能保证数据的一致性，但是但我们操作的数据存在于不同的库来说，就需要一套全局的事务机制来保证数据的一致性了。解决方案有Spring的JTA、阿里开源的seata强一致性事务；还有基于可靠消息的柔性事务。 

------

#### **五、缓存**

缓存不仅可以加速数据读取，而且通常缓存可以帮数据库抵挡住大部分的查询请求，缓存也是在缓解数据库查询压力的一大杀器。通常我们可以在很多地方对数据进行缓存，从客户端缓存 到CDN缓存、代理缓存、分布式缓存、应用缓存、数据库缓存等，缓存的使用场景无处不在，但使用缓存也会有一些需要注意的事项。



##### **1、使用缓存将会面临的问题**

缓存的使用场景无处不在，但使用缓存也会有一些需要注意的事项，这里主要以分布式缓存案例来了解缓存存在的一些通用问题。



##### **问题一：数据一致性问题**

一般情况下缓存都只是为了我们提升数据检索性能的一个媒介，它不会作为最后的数据存储归宿，通常我们会把最终的数据保存到数据库中去。这样的情况下我们的数据就会分别存在于缓存和数据库中，当我们操作两个数据库和缓存的时候就会存在修改了数据库但是没更新缓存数据、又或者更新了缓存数据库的数据又没同步修改，像这种数据库的数据和缓存数据不同步的问题就属于缓存数据一致性问题。

缓存一致性问题主要原因是在于修改数据库的同时又需要去更新缓存，但是这个过程可能出现一些问题从而导致缓存数据与数据库的数据不一致，如果A、B请求对同一条数据进行变更，A先把用户年龄修改为18、B请求后把年龄修改为20，这个过程可能是以下两种情况。

**正常情况下修改流程如下：**

A先修改完数据库-->A修改缓存-->B修改数据-->B修改缓存。



![img](https://pic4.zhimg.com/v2-6aeb67aaf3a688bd611739a6c75f2927_b.png)



**在并发操作的情况下很有可能产生如下情况**

A先修改完数据库-->B修改数据-->B修改缓存-->A修改缓存，从下图我们也可以看见这种情况会造成数据库和缓存数据的不一致问题。



![img](https://pic2.zhimg.com/v2-19df64df2445fbcf79fbb9e00c18a56d_b.png)



##### **解决方案：**

**1、先修改数据库、再删除缓存**

导致问题主要原因是在于修改缓存这个操作存在并发问题，既然修改有并发问题的话我们就可以采用不对缓存进行修改而直接删除对应的缓存方式、只要数据库修改数据之后直接把缓存的对应的key删除，然后程序在查询缓存时发现key不存在就从数据库读取数据，然后加载到缓存里面来、因为每次修改数据后缓存都是从数据库直接读取的数据，所以也就避免了因为修改缓存数据造成的不一致性问题。

**2、更新缓存时加锁**

既然是并发性修改导致的问题，那么我们也可以通过加锁的方式，A在修改数据之前先加锁，等数据库和缓存的数据都修改完毕之后再释放锁，B在A没有释放锁之前是没办法对数据进行操作的，所以也就避免了并发修改数据的可能，从而避免了缓存不一致问题。

**3、设置较短的过期时间**

设置一个比较短的过期时间，只要数据一过期，然后程序就会从数据库同步数据到缓存，这种方式虽然不是直接解决了缓存不一致性的问题，但是可以控制不一致数据存在的时长。



##### **问题二：缓存穿透**

缓存穿透是指当我们从缓存里面查不到数据而不得不请求从数据库去查询数据的情况，如果在并发请求量大的情况下，当然大部分的缓存穿透本身不是问题，因为缓存本身就是为了保存一些经常使用的活跃数据，对于那些经常不用的冷数据我们也必要长久的保存在内存中，毕竟内存资源是有限的，所以在缓存数据的时候我们也会设置一定的失效时间，当缓存失效了之后，我们的请求发现缓存没有数据就从数据库取读取数据再更新到缓存。

在读取数据时，因为缓存获取不到对应的数据而请求进入数据库查询数据的情况我们称为读缓存穿透，缓存穿透的的风险在于如果大量的请求直接穿透到数据库，有可能导致数据库承受不了并发请求的压力导致数据库瘫痪，从而导致系统整体的可用性问题，在系统中会有几种情况会出现缓存穿透。

##### **缓存过期失效导致穿透**

因为缓存失效需要重新从数据库查询数据同步到缓存，这种属于正常的穿透。



##### **查询不存在的数据导致穿透**

请求一个系统不存在的数据(比如说文章之类的)，因为数据库根本就不存在对应的数据所以不会同步到缓存，每次请求过来发现缓存没有数据那么请求都会进入数据库。

**解决方案：**这种情况下的解决方案是如果数据不存在的情况下，缓存一个对应key的null值，当请求下次进来的时候发现缓存对应的null就直接返回结果，不再穿透到数据库查询。



##### **恶意的攻击导致的穿透**

如果说查询系统不存在的数据可能是用户无意的操作，要是明知道搜索的内存不存在还不断的请求，那么这种就属于恶意的攻击了，这种恶意的请求通常是有目的性的通过频繁的随机请求系统不存在的数据，造成请求穿透到数据库，从而导致系统风险，这种情况下如果我们就算缓存null 值也会有风险，因为这种请求通常是随机请求，每次查询的数据标识都有可能不同。

**解决方案：** 这种情况我们只能把所有数据库存在的ID，如果查询是根据文章ID查询的话，那就缓存所有文章的ID。事先把系统存对应文章的数据ID缓存到缓存中去，当请求过进入系统，先从这个缓存数据里判断系统是否存在对应的数据ID，如果不存在的话直接返回出去，避免请求进入到数据库层，当然我们不能简单把所有数据直接保存起来，常用的方式是采用“布隆过滤器”的算法来保存这些数据，采用布隆过滤器不仅在存储成本还是在判断效率上都会比我们直接存储数据要高得多。

------

#### 六、**Nosql**

相对于传统数据库，非关系型数据库通常要比关系型数据库性能要快、而且变更方便，对内容格式要求宽松，增加删除内容属性不需像数据一样同步修改数据库的表结构。但是关系型数据库完善的事务机制，使得关系型数据库又是必须的，所以Nosql通常作为对关系型数据库的补充，在一些特定场景使用Nosql能让系统性能得到很大的改善，常用的NoSql数据库 有键值数据库、文档型数据库、列族数据库几种类型。

对于一些关系简单的热点数据我们可以使用redis这种键值数据库来存储。对于一些数据量大，数据格式多样化对查询性能又有要求的场景我们可以使用向MogoDB文档型的数据库来存储，而对于一些有全文搜索类的需求的我们可以使用Elasticsearch来满足搜索的需求。

### 19.Mysql主从架构如何保证数据同步?

主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。 binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的重放日志（Relay log）中。 SQL 线程 ：负责读取重放日志并重放其中的 SQL 语句

### 20.为什么es比Mysql快，效率高？

1）在存储上，es是document格式的存储，mysql是行格式的，所以es并不需要显式定义字段，而mysql需要。 2）在架构上，es天然就是分布式的，可以很容易的横向扩容，mysql不行。 3）在针对场景下，es无法做到实时，而mysql可以，因此mysql的OLTP (Online Transactional Processing，联机事务处理)对于es而言需要额外考虑下场景是否适用，可以认为es同时具有oltp和olap的特点，但两边都不是特别突出。 4）在数据存储量及性能上，mysql由于其索引实现（innodb为例）导致在数据量大到一定级别后会出现性能衰减；而es只要给足足够内存就没太大问题。插入速度上如果正确的配置mysql其性能并不低，当然相对于正常状态es而言还是差了一个到多个量级（es>mongo>mysql）。查询速度这个主要看索引和数量，在需要复杂关联查询的时候建议优先考虑mysql。 资源开销上，当数据量上去了后如果为了维持性能的话，es吃内存的能力绝对可以傲视群雄，但毕竟没有不吃草就能跑的快的马儿。 5）易用性上当然是mysql>es。其实刨掉全文检索场景，mysql（5.6以后）加上良好的设计就能很好的支持绝大部分需求了。

6）Elasticsearch会对所有输入的文本进行处理，建立索引放入内存中，从而提高搜索效率。在这一点上ES要优于MySQL的B+树的结构，MySQL需要将索引放入磁盘，每次读取需要先从磁盘读取索引然后寻找对应的数据节点，但是ES能够直接在内存中就找到目标文档对应的大致位置，最大化提高效率。 并且在进行组合查询的时候MySQL的劣势更加明显，它不支持复杂的组合查询比如聚合操作，即使要组合查询也要事先建好索引，但是ES就可以完成这种复杂的操作，默认每个字段都是有索引的，在查询的时候可以各种互相组合。

#### Elasticsearch比MySQL快的原因

对比： 1）基于分词后的全文检索：例如select * from test where name like '%张三%'，对于mysql来说，因为索引失效，会进行全表检索；对es而言分词后，每个字都可以利用FST高速找到倒排索引的位置，并迅速获取文档id列表，大大的提升了性能，减少了磁盘IO。 2）精确检索：进行精确检索，有些时候可能mysql要快一些，当mysql的非聚合索引引用上了聚合索引，无需回表，则速度上可能更快；es还是通过FST找到倒排索引的位置比获取文档id列表，再根据文档id获取文档并根据相关度进行排序。但是es还有个优势，就是es即天然的分布式能够在大量数据搜索时可以通过分片降低检索规模，并且可以通过并行检索提升效率，用filter时，更是可以直接跳过检索直接走缓存。



### 21.hadoop原理

### 22.数据库引擎有哪些？区别？应用？

1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

2. InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；  

3. InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 

4. InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；    

5. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

#### 引擎应用

1. 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM；

2. 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使用InnoDB。

3. 系统奔溃后，MyISAM恢复起来更困难，能否接受，不能接受就选 InnoDB；

4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的。如果你不知道用什么存储引擎，那就用InnoDB，至少不会差。

### 23.mysql分页limit如何优化？（limit性能优化）

#### 使用自增索引优化

根据数据库这种查找的特性，就有了一种想当然的方法，利用自增索引（假设为id）：

```bash
select * from table_name where (id >= 10000) limit 10
```

由于普通搜索是全表搜索，适当的添加 WHERE 条件就能把搜索从全表搜索转化为范围搜索，大大缩小搜索的范围，从而提高搜索效率。

这个优化思路就是告诉数据库：「你别数了，我告诉你，第10001条数据是这样的，你直接去拿吧。」

但是！！！你可能已经注意到了，这个查询太简单了，没有任何的附加查询条件，如果我需要一些额外的查询条件，比如我只要某个用户的数据 ，这种方法就行不通了。

可以见到这种思路是有局限性的，首先必须要有自增索引列，而且数据在逻辑上必须是连续的，其次，你还必须知道特征值。

如此苛刻的要求，在实际应用中是不可能满足的。

#### 先查找出需要数据的索引列，再通过索引列查找出需要的数据。

说起数据库查询优化，第一时间想到的就是索引，所以便有了第二次优化：先查找出需要数据的索引列（假设为 id），再通过索引列查找出需要的数据。

```sql
Select * From table_name Where id in (Select id From table_name where ( user = xxx )) limit 10000, 10;

select * from table_name where( user = xxx ) limit 10000,10
```

相比较结果是（500w条数据）：第一条花费平均耗时约为第二条的 1/3 左右。

同样是较大的 offset，第一条的查询更为复杂，为什么性能反而得到了提升？

这涉及到 mysql 主索引的数据结构 b+Tree ，这里不展开，基本原理就是：

- 子查询只用到了索引列，没有取实际的数据，所以不涉及到磁盘IO，所以即使是比较大的 offset 查询速度也不会太差。
- 利用子查询的方式，把原来的基于 user 的搜索转化为基于主键（id）的搜索，主查询因为已经获得了准确的索引值，所以查询过程也相对较快。

#### 使用 join

在数据量大的时候 in 操作的效率就不怎么样了，我们需要把 in 操作替换掉，使用 join 就是一个不错的选择。

```sql
select * from table_name inner join ( select id from table_name where (user = xxx) limit 10000,10
```

#### 记录上次查询的最大id，向后追溯M行记录

```javascript
endNum = (i + 1)*500;
select id,content from test_table 
where id > 
(select id from test_table order by id asc limit endNum,1)  
limit 500
```

这种方式与原sql对比，原sql需要跨越大量数据块并取出，优化后基本通过直接根据索引字段定位，才取出相应内容，效率自然大大提升。

### 24.mysql分片原则有哪些?

**1、可以不分就不分，参考单表优化。**

**2、片数尽可能少，**片数尽可能均匀地分布在多个数据结点上，因为一个查询SQL的片数越多，整体性能就越差，尽管比所有数据在片数结果上都要好，但只在必要时扩展，增加片数。

**3、分片规则需要慎重选择，**提前规划。分片规则的选择需要考虑数据的增长模式、数据的访问模式、分片的相关性和分片的扩展。最近的分片策略是范围分片、枚举分片、一致性Hash分片，有利于扩展。

**4、尽量不要在一个事务中的SQL跨越多个片段。**分布式事务一直是一个难以处理的问题。

**5、尽可能优化查询条件**，尽可能避免Select*方式，在大量数据结果集中下，会消耗大量带宽和带宽。查询尽量避免返回大量结果集，并尽量为经常使用的查询句子建立索引。

**6、通过数据冗余和表格分区来降低跨库Join的可能性。**



### 数据库范式  

1NF（第一范式）

属性不能再被分割（也就是数据库中的一列不能再被分割）

2NF（第二范式）

2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖。

3NF（第三范式）

3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 

> - **函数依赖（functional dependency）** ：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y；
> - **部分函数依赖（partial functional dependency）** ：如果 X→Y，并且存在 X 的一个真子集 X0，使得 X0→Y，则称 Y 对 X 部分函数依赖。比如学生基本信息表 R 中（学号，身份证号，姓名）当然学号属性取值是唯一的，在 R 关系中，（学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名）；所以姓名部分函数依赖与（学号，身份证号）；
> - **完全函数依赖(Full functional dependency)** ：在一个关系中，若某个非主属性数据项依赖于全部关键字称之为完全函数依赖。比如学生基本信息表 R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在 R 关系中，（学号，班级）->（姓名），但是（学号）->(姓名)不成立，（班级）->(姓名)不成立，所以姓名完全函数依赖与（学号，班级）；
> - **传递函数依赖** ： 在关系模式 R(U)中，设 X，Y，Z 是 U 的不同的属性子集，如果 X 确定 Y、Y 确定 Z，且有 X 不包含 Y，Y 不确定 X，（X∪Y）∩Z=空集合，则称 Z 传递函数依赖(transitive functional dependency) 于 X。传递函数依赖会导致数据冗余和异常。传递函数依赖的 Y 和 Z 子集往往同属于某一个事物，因此可将其合并放到一个表中。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。

### 数据库事务

要么全部执行成功，要么全部不成功。

#### 关系型数据库事务都有ACID特性

1. 原子性（Atomicity） ：     事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. 一致性（Consistency）：     执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
3. 隔离性（Isolation）：     并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. 持久性（Durability）：     一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### MySQL内存不足解决方法

MySQL内存空间不足可以通过错误日志 /var/log/mysql/error.log 查看

MySQL内存不足的解决方法：

1、增加swap交换空间，代码为【dd if=/dev/zero of=/swapfile bs=1M count=1024】

2、增加自动挂载，在文件【/etc/fstab中加入/swapfileswap】

### MySQL B+树存放数据量以及层数

[参考](https://blog.csdn.net/csdnlijingran/article/details/102309593)

在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节；而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k；而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。

 

InnoDB存储引擎的最小存储单元是页，页可以用于存放数据也可以用于存放键值+指针，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。

索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据；

**那么千万级数据需要多少层的B+树？**

这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。

上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右）。

那么现在我们需要计算出非叶子节点能存放多少指针，其实这也很好算，我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384/14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。

根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170*1170*16=21902400条这样的记录。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时 **一次页的查找代表一次IO**， 所以通过主键索引查询通常 **只需要1-3次IO操作** 即可查找到数据。

### Mysql索引失效情况?

在索引列上做任何操作

索引范围条件右边的列

order by所有数据会进行回表会导致索引失效，反而让内存中直接全文排序（比较快）

违反最左前缀法则

使用不等于（!=、<>）

like以通配符开头（'%abc'）

字符串不加单引号索引失效，等于整数

or连接

### Mysql的in与not in是否走索引？

主键索引不用考虑后面的范围，都走索引（除非是所有的范围值）

普通索引notin和in都需要考虑后面取值范围，范围较小走索引，范围太大不走索引（因为要回表）

### MySQL 是怎么加锁的？

对记录加锁时，**加锁的基本单位是 next-key lock**，它是由记录锁和间隙锁组合而成的，**next-key lock 是前开后闭区间，而间隙锁是前开后开区间**。

```text
select * from t_test where id=8 for update;
select * from t_test where id>=8 and id<9 for update;
```

#### 唯一索引等值查询

当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：

- **当查询的记录是存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「记录锁」**。
- **当查询的记录是不存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「间隙锁」**。

#### 唯一索引范围查询

主键索引的锁是记录锁 id=8 和间隙锁(8, 16)。

#### 非唯一索引等值查询

当我们用非唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：

- **当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁**。

1. 先会对普通索引 b 加上 next-key lock，范围是(4,8];
2. 然后因为是非唯一索引，且查询的记录是存在的，所以还会加上间隙锁，规则是向下遍历到第一个不符合条件的值才能停止，因此间隙锁的范围是(8,16)。

- **当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。**

1. 先会对普通索引 b 加上 next-key lock，范围是(8,16];
2. 但是由于查询的记录是不存在的，所以不会再额外加个间隙锁，但是 next-key lock 会退化为间隙锁，最终加锁范围是 (8,16)。



## redis
### Redis的数据类型
Redis主要提供了5种数据结构：字符串(string)、哈希(hash)、列表(list)、集合(set)、有序集合(zset)。Redis还提供了Bitmap、HyperLogLog、Geo类型,但这些类型都是基于上述核心数据类型实现的。
string可以存储字符串、数字和二进制数据,除了值可以是String以外,所有的键也可以是string,string最大可以存储大小为2M的数据。 
list保证数据线性有序且元素可重复,它支持lpush、blpush、rpop、brpop等操作,可以当作简单的消息队列使用,一个list最多可以存储2^32-1个元素 
hash的值本身也是一个键值对结构,最多能存储2^32-1个元素 
set是无序不可重复的,它支持多个set求交集、并集、差集,适合实现共同关注之类的需求,一个set最多可以存储2^32-1个元素 
zset是有序不可重复的,它通过给每个元素设置一个分数来作为排序的依据,一个zset最多可以存储2^32-1个元素。

每种类型支持多个编码,每一种编码采取一个特殊的结构来实现 各类数据结构内部的编码及结构： string：编码分为int、raw、embstr；int底层实现为long,当数据为整数型并且可以用long类型表示时可以用long存储；embstr底层实现为占一块内存的SDS结构,当数据为长度不超过32字节的字符串时,选择以此结构连续存储元数据和值；raw底层实现为占两块内存的SDS,用于存储长度超过32字节的字符串数据,此时会在两块内存中分别存储元数据和值。 

list：编码分为ziplist、linkedlist和quicklist（3.2以前版本没有quicklist）。ziplist底层实现为压缩列表,当元素数量小于2且所有元素长度都小于64字节时,使用这种结构来存储；linkedlist底层实现为双端链表,当数据不符合ziplist条件时,使用这种结构存储；3.2版本之后list一般采用quicklist的快速列表结构来代替前两种。 

hash：编码分为ziplist、hashtable两种,其中ziplist底层实现为压缩列表,当键值对数量小于2,并且所有的键值长度都小于64字节时使用这种结构进行存储；hashtable底层实现为字典,当不符合压缩列表存储条件时,使用字典进行存储。 

set：编码分为inset和hashtable,intset底层实现为整数集合,当所有元素都是整数值且数量不超过2个时使用该结构存储,否则使用字典结构存储。 

zset：编码分为ziplist和skiplist,当元素数量小于128,并且每个元素长度都小于64字节时,使用ziplist压缩列表结构存储,否则使用skiplist的字典+跳表的结构存储。

### 1.跳跃表原理

Skip list(跳表）是一种可以代替平衡树的数据结构，默认是按照Key值升序的。Skip list让已排序的数据分布在多层链表中，以0-1随机数决定一个数据的向上攀升与否，通过“空间来换取时间”的一个算法，**在每个节点中增加了向前的指针**，在插入、删除、查找时可以忽略一些不可能涉及到的结点，从而提高了效率。

跳跃表以有序的方式在层次化的链表中保存元素， 效率和AVL树媲美 —— 查找、删除、添加等操作都可以在O(LogN)时间下完成， 并且比起二叉搜索树来说， 跳跃表的实现要简单直观得多。

![img](https://images2015.cnblogs.com/blog/524341/201604/524341-20160407183241015-758461440.png)

从图中可以看到， 跳跃表主要由以下部分构成：

表头（head）：负责维护跳跃表的节点指针。
跳跃表节点：保存着元素值，以及多个层。
层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次。
表尾：全部由 NULL 组成，表示跳跃表的末尾。

#### 构造过程

1、给定一个有序的链表。
2、选择连表中最大和最小的元素，然后从其他元素中按照一定算法（随机）随即选出一些元素，将这些元素组成有序链表。这个新的链表称为一层，原链表称为其下一层。
3、为刚选出的每个元素添加一个指针域，这个指针指向下一层中值同自己相等的元素。Top指针指向该层首元素
4、重复2、3步，直到不再能选择出除最大最小元素以外的元素。 

### Redis优缺点

优点

- 读写性能优异，     Redis能读的速度是110000次/s，写的速度是81000次/s。
- 支持数据持久化，支持AOF和RDB两种持久化方式。
- 支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。
- 数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。
- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。

缺点

- 数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
- Redis     不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。
- Redis     较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费

### Redis线程模型

Redis是基于Reactor模式来设计的一套高效的事件处理模型，它是单线程的，使用IO多路复用技术来监听来自客户端的大量连接，降低资源消耗

### 缓存异常

#### 缓存雪崩

缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决：

设置不同的失效时间比如随机设置缓存的失效时间

#### 缓存穿透

缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决：

1、对于非法请求进行校验

2、采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

#### 缓存击穿

缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

解决方案：

设置热点数据永不过期

### 2.为什么要用redis？

在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够**迅速响应**。

在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。

### Redis为什么这么快

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4、使用多路 I/O 复用模型，非阻塞 IO；

5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；



### 3.redis常用哪些场景？

缓存，毫无疑问这是Redis当今最为人熟知的使用场景。再提升服务器性能方面非常有效；

排行榜，如果使用传统的关系型数据库来做这个事儿，非常的麻烦，而利用Redis的SortSet数据结构能够非常方便搞定；

计算器/限速器，利用Redis中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等，这类操作如果用MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个API的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；

好友关系，利用集合的一些命令，比如求交集、并集、差集等。可以方便搞定一些共同好友、共同爱好之类的功能；

简单消息队列，除了Redis自身的发布/订阅模式，我们也可以利用List来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力，完全可以用List来完成异步解耦；

Session共享，以PHP为例，默认Session是保存在服务器的文件中，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session信息。

### 4.redis特殊类型？

#### geospatial地理位置

```
朋友的定位，附近的人，打车距离计算？

Redis的Geo在Redis3.2版本就已经推出！这个功能可以推算地理位置的信息，两地之间的距离，方圆几里的人！
```

#### Bitmaps位存储

```
统计疫情感染人数：0 1 0 1 0

统计用户信息，活跃，不活跃！登录、未登录！打卡，365天打卡！两个状态的，都可以使用Bitmaps！

Bitmaps位图，数据结构！都是操作二进制位来进行记录，就只有0和1两个状态！

使用bitmap来记录周一到周日的打卡！
```

#### Redis Hyperloglog基数统计的算法！

优点：占用的内存是固定的，2^64不同的元素的基数，只需要废12KB内存！如果从内存角度来比较的话，Hyperloglog首选！

```
Redis 的基数统计，这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时UV）、在线用户数等。但是它也有局限性，就是只能统计数量，而没办法去知道具体的内容是什么。

当然用集合也可以解决这个问题。但是一个大型的网站，每天 IP 比如有 100 万，粗算一个 IP 消耗 15 字节，那么 100 万个 IP 就是 15M。而 HyperLogLog 在 Redis 中每个键占用的内容都是 12K，理论存储近似接近 2^64 个值，不管存储的内容是什么，它一个基于基数估算的算法，只能比较准确的估算出基数，可以使用少量固定的内存去存储并识别集合中的唯一元素。而且这个估算的基数并不一定准确，是一个带有 0.81% 标准错误的近似值。
```

### Redis哈希表原理

#### 结构定义[#](https://www.cnblogs.com/jiujuan/p/15944061.html#1485656912)

#### 哈希表dictht[#](https://www.cnblogs.com/jiujuan/p/15944061.html#3179282208)

redis3.0 中的哈希表叫 [dictht](https://github.com/redis/redis/blob/3.0/src/dict.h#L69),[dictht](https://github.com/redis/redis/blob/3.0/src/dict.h#L69) 的定义：

```c
Copy// https://github.com/redis/redis/blob/3.0/src/dict.h#L69

/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
typedef struct dictht { // 哈希表
    dictEntry **table; // 哈希表的数组，数组中每个元素都是指针，指向 dictEntry 结构
    unsigned long size; // 哈希表的大小，table 数组的大小
    unsigned long sizemask; // 哈希表掩码，用于计算索引值，等于 size-1
    unsigned long used; // 哈希表已有的节点(键值对)数量
} dictht;
```

![img](https://img2022.cnblogs.com/blog/650581/202203/650581-20220326172312556-1146312408.png)

#### 哈希表节点dictEntry

```
typedef struct dictEntry {
    void *key;  // 键 key
    union { // 值 val
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next; // 指向下一个哈希表节点，链表法解决hash冲突
} dictEntry;
```

key 属性保存键值对中的键，v 属性保存键值对中的值，其中这个 v 值可能是一个指针，或者是一个 uint64_t 整数，或者是 int64_t 整数，或是 double 类型浮点数。

![img](https://img2022.cnblogs.com/blog/650581/202203/650581-20220326172345144-1784893711.png)

next：指向下一个哈希节点，用链表法来解决哈希冲突。

hash冲突：

上面的 [dictEntry](https://github.com/redis/redis/blob/3.0/src/dict.h#L47) 结构里的属性 next 就是解决这个哈希键冲突问题的。

有冲突的值，就用链表来记录下一个值。

在 [Redis](https://redis.io/) 中用 [dictht](https://github.com/redis/redis/blob/3.0/src/dict.h#L69) 来表示哈希表，但是，在使用哈希表时，Redis 又定义了一个字典 dict 的数据结构

为什么要再定义一个 dict 结构？

- 为了扩展哈希表(rehash)的时候，能够方面的操作哈希表。为此里面定义了 2 个哈希表 ht[2]。

#### 字典 [dict.h/dict](https://github.com/redis/redis/blob/3.0/src/dict.h#L76) 结构定义：

```c
Copytypedef struct dict {
    dictType *type; // 指针，指向dictType 结构，dictType 中包含很多自定义函数，见下面
    void *privdata; // 私有数据，保存dictType结构中的函数参数
    dictht ht[2]; // hash表，ht[2] 表示有2张表
    long rehashidx; /* rehashing not in progress if rehashidx == -1 *///rehash 标识，rehashidx=-1，没进行rehash
    int iterators; /* number of iterators currently running */// 正在运行的迭代器数量
} dict;
```

*type：保存了很多函数，这些函数是操作特定类型键值对的函数，Redis 会为用途不同的字典设置不同类型特定函数。

ht[2]：包含 2 个 dictht哈希表，为什么有2张表？rehash 时会用到 ht[1]。一般情况下只使用 ht[0]。

rehashidx：这个属性与 rehash 有关，记录 rehash 目前的进度，如果目前没有进行 rehash，那么 rehashidx=-1。

![img](https://img2022.cnblogs.com/blog/650581/202203/650581-20220326172427847-543328831.png)

#### rehash

##### 什么是 rehash ？

- 扩大或缩小哈希表容量。

##### b. 为什么有 rehash ？

- 当哈希表的数据量持续增长，而哈希表容量大小固定时，就可能会有 2 个或以上数量的键被分配到哈希表数组的同一个索引上，于是就发生了冲突(collision)。
- 当然冲突可以用链表法(separate chaining)解决，但是为了哈希表的性能，要尽量避免冲突，就要对哈希表进行扩容或缩容。

哈希表中有一个负载因子(load factor)的概念:

> 负载因子 = 哈希表已保存的键值对数量(使用的数量) / 哈希表的长度
>
> load_factor = ht[0].used / ht[0].size

这个负载因子的概念是用来衡量哈希表容量大小情况的。哈希表中的键值对数量少，负载因子也小。

当负载因子超过某个阙值时，为了维持哈希的容量在一定合理范围，就会对哈希表容量进行 resize 操作：

1. 扩大哈希表容量
2. 缩小哈希表容量

##### c. 什么时候进行扩容和缩容操作？

- 扩容条件

  满足下面任一条件都会触发哈希表扩容

  1. 服务器目前没有执行 bgsave 命令，或 bgrewriteaof 命令，并且哈希表的负载因子 >=1
  2. 服务器目前在执行 bgsave 命令，或 bgrewriteaof 命令并且哈希表的负载因子 >5

- 缩容条件

  1. 哈希表的负载因子 < 0.1

##### 怎么操作扩容和缩容？

##### 也就是说扩容和缩容的操作步骤是什么？

1. 为字典 ht[1] 分配内存空间，空间大小取决于要执行的操作，以及当前 ht[0] 的键值对数量
   - 如果是扩容操作，那么 ht[1] 的空间大小等于第一个 ht[0].used * 2 的 2^n(2的n次幂)
   - 如果是缩容操作，那么 ht[1] 的空间大小等于第一个 ht[0].used 的 2^n(2的n次幂)
2. 将 ht[0] 上所有键值重新计算哈希值和索引值后存放到 ht[1] 对应位置上
3. 当 ht[0] 上所有的键值移动到 ht[1] 后，释放 ht[0]，将 ht[1] 变成 ht[0]，并在 ht[1] 上新建一个空哈希表

#### 渐进式rehash过程

以下是哈希表渐进式 rehash 的详细步骤：

1. 为 `ht[1]` 分配空间， 让字典同时持有 `ht[0]` 和 `ht[1]` 两个哈希表。
2. 在字典中维持一个索引计数器变量 `rehashidx` ， 并将它的值设置为 `0` ， 表示 rehash 工作正式开始。
3. 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 `ht[0]` 哈希表在 `rehashidx` 索引上的所有键值对 rehash 到 `ht[1]` ， 当 rehash 工作完成之后， 程序将 `rehashidx` 属性的值增一。
4. 随着字典操作的不断执行， 最终在某个时间点上， `ht[0]` 的所有键值对都会被 rehash 至 `ht[1]` ， 这时程序将 `rehashidx` 属性的值设为 `-1` ， 表示 rehash 操作已完成。

渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。

##### 操作辅助rehash

 在redis中每一个增删改查命令中都会判断数据库字典中的哈希表是否正在进行渐进式rehash，如果是则帮助执行一次

##### 定时辅助rehash

 虽然redis实现了在读写操作时，辅助服务器进行渐进式rehash操作，但是如果服务器比较空闲，redis数据库将很长时间内都一直使用两个哈希表。所以在redis周期函数中，如果发现有字典正在进行渐进式rehash操作，则会花费1毫秒的时间，帮助一起进行渐进式rehash操作

#### 渐进式 rehash 执行期间的哈希表操作

因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。

 

另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。

####  渐进式rehash带来的问题

渐进式rehash避免了redis阻塞，可以说非常完美，但是由于在rehash时，需要分配一个新的hash表，在rehash期间，同时有两个hash表在使用，会使得redis内存使用量瞬间突增，在Redis 满容状态下由于Rehash会导致大量Key驱逐。

### 6.redis执行命令过程

#### 发送命令请求

Redis 服务器的命令请求来自 Redis 客户端， 当用户在客户端中键入一个命令请求时， 客户端会将这个命令请求转换成协议格式， 然后通过连接到服务器的套接字， 将协议格式的命令请求发送给服务器。

#### 读取命令请求

当客户端与服务器之间的连接套接字因为客户端的写入而变得可读时， 服务器将调用命令请求处理器来执行以下操作：

1. 读取套接字中协议格式的命令请求， 并将其保存到客户端状态的输入缓冲区里面。
2. 对输入缓冲区中的命令请求进行分析， 提取出命令请求中包含的命令参数， 以及命令参数的个数， 然后分别将参数和参数个数保存到客户端状态的 `argv` 属性和 `argc` 属性里面。
3. 调用命令执行器， 执行客户端指定的命令。

#### 命令执行器（1）：查找命令实现

命令执行器要做的第一件事就是根据客户端状态的 `argv[0]` 参数， 在命令表（command table）中查找参数所指定的命令， 并将找到的命令保存到客户端状态的 `cmd` 属性里面。

命令表是一个字典， 字典的键是一个个命令名字，比如 `"set"` 、 `"get"` 、 `"del"` ，等等； 而字典的值则是一个个 `redisCommand` 结构， 每个 `redisCommand` 结构记录了一个 Redis 命令的实现信息。

#### 命令执行器（2）：执行预备操作

到目前为止， 服务器已经将执行命令所需的命令实现函数（保存在客户端状态的 `cmd` 属性）、参数（保存在客户端状态的 `argv` 属性）、参数个数（保存在客户端状态的 `argc` 属性）都收集齐了， 但是在真正执行命令之前， 程序还需要进行一些预备操作， 从而确保命令可以正确、顺利地被执行， 这些操作包括：

- 检查客户端状态的 `cmd` 指针是否指向 `NULL` ， 如果是的话， 那么说明用户输入的命令名字找不到相应的命令实现， 服务器不再执行后续步骤， 并向客户端返回一个错误。
- 根据客户端 `cmd` 属性指向的 `redisCommand` 结构的 `arity` 属性， 检查命令请求所给定的参数个数是否正确， 当参数个数不正确时， 不再执行后续步骤， 直接向客户端返回一个错误。 比如说， 如果 `redisCommand` 结构的 `arity` 属性的值为 `-3` ， 那么用户输入的命令参数个数必须大于等于 `3` 个才行。
- 检查客户端是否已经通过了身份验证， 未通过身份验证的客户端只能执行 AUTH 命令， 如果未通过身份验证的客户端试图执行除 AUTH 命令之外的其他命令， 那么服务器将向客户端返回一个错误。
- 如果服务器打开了 `maxmemory` 功能， 那么在执行命令之前， 先检查服务器的内存占用情况， 并在有需要时进行内存回收， 从而使得接下来的命令可以顺利执行。 如果内存回收失败， 那么不再执行后续步骤， 向客户端返回一个错误。
- 如果服务器上一次执行 BGSAVE 命令时出错， 并且服务器打开了 `stop-writes-on-bgsave-error` 功能， 而且服务器即将要执行的命令是一个写命令， 那么服务器将拒绝执行这个命令， 并向客户端返回一个错误。
- 如果客户端当前正在用 SUBSCRIBE 命令订阅频道， 或者正在用 PSUBSCRIBE 命令订阅模式， 那么服务器只会执行客户端发来的 SUBSCRIBE 、 PSUBSCRIBE 、 UNSUBSCRIBE 、 PUNSUBSCRIBE 四个命令， 其他别的命令都会被服务器拒绝。
- 如果服务器正在进行数据载入， 那么客户端发送的命令必须带有 `l` 标识（比如 INFO 、 SHUTDOWN 、 PUBLISH ，等等）才会被服务器执行， 其他别的命令都会被服务器拒绝。
- 如果服务器因为执行 Lua 脚本而超时并进入阻塞状态， 那么服务器只会执行客户端发来的 SHUTDOWN nosave 命令和 SCRIPT KILL 命令， 其他别的命令都会被服务器拒绝。
- 如果客户端正在执行事务， 那么服务器只会执行客户端发来的 EXEC 、 DISCARD 、 MULTI 、 WATCH 四个命令， 其他命令都会被放进事务队列中。
- 如果服务器打开了监视器功能， 那么服务器会将要执行的命令和参数等信息发送给监视器。

当完成了以上预备操作之后， 服务器就可以开始真正执行命令了。

#### 命令执行器（3）：调用命令的实现函数

在前面的操作中， 服务器已经将要执行命令的实现保存到了客户端状态的 `cmd` 属性里面， 并将命令的参数和参数个数分别保存到了客户端状态的 `argv` 属性和 `argc` 属性里面， 当服务器决定要执行命令时， 它只要执行以下语句就可以了：

```
// client 是指向客户端状态的指针

client->cmd->proc(client);
```

因为执行命令所需的实际参数都已经保存到客户端状态的 `argv` 属性里面了， 所以命令的实现函数只需要一个指向客户端状态的指针作为参数即可。

被调用的命令实现函数会执行指定的操作， 并产生相应的命令回复， 这些回复会被保存在客户端状态的输出缓冲区里面（`buf` 属性和 `reply` 属性）， 之后实现函数还会为客户端的套接字关联命令回复处理器， 这个处理器负责将命令回复返回给客户端。

#### 命令执行器（4）：执行后续工作

在执行完实现函数之后， 服务器还需要执行一些后续工作：

- 如果服务器开启了慢查询日志功能， 那么慢查询日志模块会检查是否需要为刚刚执行完的命令请求添加一条新的慢查询日志。
- 根据刚刚执行命令所耗费的时长， 更新被执行命令的 `redisCommand` 结构的 `milliseconds` 属性， 并将命令的 `redisCommand` 结构的 `calls` 计数器的值增一。
- 如果服务器开启了 AOF 持久化功能， 那么 AOF 持久化模块会将刚刚执行的命令请求写入到 AOF 缓冲区里面。
- 如果有其他从服务器正在复制当前这个服务器， 那么服务器会将刚刚执行的命令传播给所有从服务器。

当以上操作都执行完了之后， 服务器对于当前命令的执行到此就告一段落了， 之后服务器就可以继续从文件事件处理器中取出并处理下一个命令请求了。

#### 将命令回复发送给客户端

前面说过， 命令实现函数会将命令回复保存到客户端的输出缓冲区里面， 并为客户端的套接字关联命令回复处理器， 当客户端套接字变为可写状态时， 服务器就会执行命令回复处理器， 将保存在客户端输出缓冲区中的命令回复发送给客户端。

当命令回复发送完毕之后， 回复处理器会清空客户端状态的输出缓冲区， 为处理下一个命令请求做好准备。

#### 客户端接收并打印命令回复

当客户端接收到协议格式的命令回复之后， 它会将这些回复转换成人类可读的格式， 并打印给用户观看

### 7.Redis IO多路复用技术

redis 是一个单线程却性能非常好的内存数据库， 主要用来作为缓存系统。 redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。

**为什么 Redis 中要使用 I/O 多路复用这种技术呢？**

首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而  **I/O 多路复用** 就是为了解决这个问题而出现的。

redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。

### 8.redis集群

Redis 集群是 Redis 提供的分布式[数据库](https://cloud.tencent.com/solution/database?from=10680)方案，集群通过分片( sharding )来实现数据共享，并提供复制和故障转移。

可以说上面这句话是对 redis 集群的高度概括了，redis 集群提供分布式数据库方案，前面我们将的主从复制和哨兵模式可以知道，只会有一个主服务器( master )。主从复制，只会有一个 master ，可以有多个 slave。而哨兵模式是在主从复制的基础上，发现 master 挂掉，会自动的将其中一个 salve 升级成 master 。但是最终结果还是只有一个 master。所以如果系统很大，对Redis 写操作的压力就会很大，所以才出现的集群的模式。集群模式可以有多个 master 。

单个节点就是我们之前了解的主从复制的一主多从，加上哨兵模式，来监听节点的 master 是否正常。那集群就是多个节点组成的，多个节点的 master 数据共享，横向分担单个节点 master 的压力。

#### Redis 集群有什么好处，用在哪些场景

集群模式是哨兵模式的一种拓展，既然是拓展，当时是因为哨兵模式不能满足需求才会产生的。

在没有Redis 集群的时候，人们使用哨兵模式，所有的数据都存在 master 上面，master 的压力越来越大，垂直扩容再多的 salve 已经不能分担 master 的压力的，因为所有的写操作集中都集中在 master 上。所以人们就想到了水平扩容，就是搭建多个 master 节点。客户端进行分片，手动的控制访问其中某个节点。但是这几个节点之间的数据是不共享的。并且如果增加一个节点，需要手动的将数据进行迁移，维护起来很麻烦。所以才产生了 Redis 集群。

所以 Redis 集群有什么好处，就是进一步提升 Redis 性能，分布式部署实现高可用性，更加的稳定。当然还包含主从复制的数据热备份以及哨兵模式的故障转移等有点啦。

#### 那 Redis 集群用在哪些场景呢？

其实我感觉一般较大的项目使用了 redis 的话，都会使用 redis 集群。毕竟在部署的时候先做好充分的拓展准备，比到时候项目出现瓶颈再去拓展成本就要小太多了。并且 Redis 是轻量级的，采用 redis 集群，也许在项目初期根本就用不上多个节点，单个节点就够用，多节点造成浪费。但是其实我们启动多个节点没有用到的话，节点所占用的内存和CPU 是非常小的。所以建议一般项目使用 Redis的话，尽量使用 Redis 集群吧。

#### 集群的主从复制和故障转移

Redis 集群的主从复制，其实和单机的主从复制是一样的。前面 Redis 集群结构图可以看到。单个节点中有一个 master 和多个 slave 。这些 slave 会自动的同步 master中的数据。注意的是，这些 salve 只会同步 所属的 master 中的数据，集群中其他的 master 数据是不会同步的。

同样的 ，当个节点中可以配置多个哨兵，来监控这个节点中的master 是否下线了，如果下线了就会将这个节点的slave 选择一个升级成 master 并继承之前 master 的分片，继续工作。

但是其实啊，在集群模式中，并没有配置哨兵，我们也能实现故障的自动转移。

可以看到并没有为每个节点配置 sentinel 。那怎么实现对 master 的监听，实现故障的自动转移呢？

#### 集群如何采用非哨兵模式

我们在讲哨兵模式的时候说过，其实哨兵也是一种特殊的 redis 服务对吧。我们master 是通过 `redis-server` 启动的。我们哨兵是通过 `redis-sentinel`启动的。然后哨兵的作用就是定期的给 master 发送 `ping`检测 master 是否下线，然后通过选举的方式选择 slave 升级成 master 那放在集群中可以发现，哨兵的这些工作，完全可以交给master 来做。之前单个节点，master 做不了才交给 sentinel 的。现在有多个 master ，当然就可以用 master 来代替salve 的工作啦 在集群中，每个节点的master 定期的向其他节点 master 发送 `ping`命令，如果没有收到`pong` 响应，则会认为主观下线，并将这个消息发送给其他的 master。其他的 master 在接收到这个消息后就保存起来。当某个节点的 master 收到 半数以上的消息认为这个节点主观下线后，就会判定这个节点客观下线。并将这个节点客观下线的消息通知给其他的master。 这个客观节点下线后，其他的 master 节点 就会选举 下线的master中的 slave 一个变成 新的master 继续工作。从而实现故障自动转移。这个选举过程和哨兵模式中是一样的，只不过是 master 代替了 sentinel 的工作。

#### Redis集群数据分片

Redis集群没有使用一致性Hash而是使用了**哈希槽**

Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽

新建与删除节点只要将槽进行移动即可。

#### Redis一致性的保证

Redis并不能保证**强一致性**，集群在一定情况下会发生写丢失。

第一个原因是因为集群是用了异步复制. 写操作过程:

- 客户端向主节点B写入一条命令.
- 主节点B向客户端回复命令状态.
- 主节点将写操作复制给他得从节点     B1, B2 和 B3.

第二个原因是发生了网络分区。

### Redis哨兵

主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。

哨兵是用于监控redis集群中Master主服务器的工作状态，在主服务器发生故障时进行故障转移。

### 9.Redis的持久化策略

Redis有RDB持久化、AOF持久化、RDB-AOF混合持久化这三种持久化方式。 RDB持久化是将当前进程数据以生成快照的方式保存到硬盘的过程,也是Redis默认的持久化机制。RDB会创建一个经过压缩的二进制文件,这个文件以’.rdb‘结尾,内部存储了各个数据库的键值对等信息。RDB持久化过程有手动触发和自动触发两种方式。手动触发是指通过SAVE或BGSAVE命令触发RDB持久化操作,创建“.rdb”文件；自动触发是指通过配置选项,让服务器在满足指定条件时自动执行BGSAVE命令。

RDB持久化的优点是其生成的紧凑压缩的二进制文件体积小,使用该文件恢复数据的速度非常快；

缺点则是BGSAVE每次运行都要执行fork操作创建子进程,这属于重量级操作,不宜频繁执行,因此,RBD没法做到实时的持久化。 

AOF以独立日志的方式记录了每次写入的命令,重启时再重新执行AOF文件中的命令来恢复数据。

AOF持久化的优点是与RDB持久化可能丢失大量的数据相比,AOF持久化的安全性要高很多。通过使用everysec选项,用户可以将数据丢失的时间窗口限制在1秒之内。
其缺点则是,AOF文件存储的是协议文本,它的体积要比二进制格式的”.rdb”文件大很多。AOF需要通过执行AOF文件中的命令来恢复数据库,其恢复速度比RDB慢很多。AOF在进行重写时也需要创建子进程,在数据库体积较大时将占用大量资源,会导致服务器的短暂阻塞。AOF解决了数据持久化的实时性,是目前Redis主流的持久化方式。 

RDB-AOF混合持久化模式是Redis4.0开始引入的,这种模式是基于AOF持久化构建而来的。用户可以通过配置文件中的“aof-use-rdb-preamble yes”配置项开启AOF混合持久化。Redis服务器在执行AOF重写操作时,会像执行BGSAVE命令一样,根据数据库当前的状态生成相应的RDB数据,并将其写入AOF文件中；对于重写之后执行的Redis命令,则以协议文本的方式追加到AOF文件的末尾,即RDB数据之后。 通过使用RDB-AOF混合持久化,用户可以同时获得RDB持久化和AOF持久化的优点,服务器既可以通过AOF文件包含的RDB数据来实现快速的数据恢复操作,又可以通过AOF文件包含的AOF数据来将丢失数据的时间窗口限制在1s之内

### 10.Redis的过期键的删除策略

过期策略通常有以下三种： 

定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 

定期清楚：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。 (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

 Redis中同时使用了惰性过期和定期过期两种过期策略。

### 11.Redis 内存淘汰策略有哪些？

volatile-lru：从已设置过期时间的数据集（server. db[i]. expires）中挑选最近最少使用的数据淘汰；

 volatile-ttl：从已设置过期时间的数据集（server. db[i]. expires）中挑选将要过期的数据淘汰。 

volatile-random：从已设置过期时间的数据集（server. db[i]. expires）中任意选择数据淘汰。

 allkeys-lru：从数据集（server. db[i]. dict）中挑选最近最少使用的数据淘汰。

 allkeys-random：从数据集（server. db[i]. dict）中任意选择数据淘汰。 no-enviction（驱逐）：禁止驱逐数据。

### 12.redis集群中分布式锁？

#### Redlock 算法的流程

**Redlock 算法**是在单 Redis 节点基础上引入的**高可用模式**，Redlock 基于 N 个完全独立的 Redis 节点，一般是**大于 3 的奇数个**（通常情况下 N 可以设置为 5），可以基本保证集群内各个节点不会同时宕机。

假设当前集群有 5 个节点，运行 Redlock 算法的客户端依次执行下面各个步骤，来完成获取锁的操作：

- 客户端记录当前系统时间，以毫秒为单位；
- 依次尝试从 5 个 Redis 实例中，使用相同的 key 获取锁，当向 Redis 请求获取锁时，客户端应该设置一个网络连接和响应超时时间，超时时间应该小于锁的失效时间，避免因为网络故障出现的问题；
- 客户端使用当前时间减去开始获取锁时间就得到了获取锁使用的时间，当且仅当从半数以上的 Redis 节点获取到锁，并且当使用的时间小于锁失效时间时，锁才算获取成功；
- 如果获取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间，减少超时的几率；
- 如果获取锁失败，客户端应该在所有的 Redis 实例上进行解锁，即使是上一步操作请求失败的节点，防止因为服务端响应消息丢失，但是实际数据添加成功导致的不一致。

### 13.redis如何保证多个操作的原子性/开启事务？

1. 开启事务（multi）
2. 命令入队（业务操作）incr xxx
3. 执行事务（exec）或取消事务（discard）

| MULTI   | 标记一个事务块的开始                                         |
| ------- | ------------------------------------------------------------ |
| EXEC    | 执行所有事务块内的命令                                       |
| DISCARD | 取消事务，放弃执行事务块内的所有命令                         |
| WATCH   | 监视一个（或多个）key，如果在事务执行之前这个（或多个）key被其他命令所改动，那么事务将被打断 |
| UNWATCH | 取消 WATCH 命令对所有 keys 的监视                            |

### 13.redis分布式锁

del key解锁



#### 基于go-redis的设计Redis分布式锁

https://www.modb.pro/db/77169

#### 1. 使用`INCR`加锁

这种加锁的思路是， `key` 不存在，那么 `key` 的值会先被初始化为 0 ，然后再执行 `INCR` 操作进行加一。然后其它用户在执行 `INCR` 操作进行加一时，如果返回的数大于 `1` ，说明这个锁正在被使用当中。

```php
/***
  1、 客户端A请求服务器获取key的值为1表示获取了锁
  2、 客户端B也去请求服务器获取key的值为2表示获取锁失败
  3、 客户端A执行代码完成，删除锁
  4、 客户端B在等待一段时间后在去请求的时候获取key的值为1表示获取锁成功
  5、 客户端B执行代码完成，删除锁
**/
$res = $redis->incr($key);  // 自增1
$redis->expire($key, $ttl); // 设置锁的有效期
if($res == 1){  
    // 获取资源成功
}else{
    // 资源被其他请求占用
}
```

#### 2. 使用`SETNX`加锁

这种加锁的思路是，如果 `key` 不存在，将 `key` 设置为 `value`，如果 `key` 已存在，则 `SETNX` 不做任何动作。

```php
/***
 1、 客户端A请求服务器设置key的值，如果设置成功就表示加锁成功
 2、 客户端B也去请求服务器设置key的值，如果返回失败，那么就代表加锁失败
 3、 客户端A执行代码完成，删除锁
 4、 客户端B在等待一段时间后在去请求设置key的值，设置成功
 5、 客户端B执行代码完成，删除锁
**/
$res = $redis->setNX($key, $value); // 当key不存在时设置key=value
$redis->expire($key, $ttl); // 设置锁的有效期
if($res){  
    // 获取资源成功
}else{
    // 资源被其他请求占用
}
```

上面两种方法都有一个问题，会发现，都需要设置 `key` 过期时间。那么为什么要设置`key`过期时间呢？如果请求执行因为某些原因意外退出了，导致创建了锁但是没有删除锁，那么这个锁将一直存在（redis不设置key的过期时间，默认是永久的），以至于一直处于加锁状态。于是乎我们需要给锁加一个过期时间以防不测。

但是借助 `Expire` 来设置就不是原子性操作了。所以还可以通过`redis`事务来确保原子性。那上面的代码就要优化成：

```php
// 第一种方式的加锁
$redis->multi();    // 标记一个事务块的开始
$res = $redis->incr($key);  
$redis->expire($key, $ttl);
$redis->exec();   // 提交事务
if($res == 1){  
    // 获取资源成功
}else{
    // 资源被其他请求占用
}

// 第二种方式的加锁
$redis->multi();    // 标记一个事务块的开始
$res = $redis->setNX($key, $value); 
$redis->expire($key, $ttl); 
$redis->exec();   // 提交事务
if($res){  
    // 获取资源成功
}else{
    // 资源被其他请求占用
}
```

上面代码看起来是不是很繁琐。好在`redis`官方从版本 2.6.12 开始 `SET` 命令本身已经包含了设置过期时间的功能。

#### 3. 使用`SET`加锁

```php
/*** 
 1、 客户端A请求服务器设置key的值，如果设置成功就表示加锁成功
 2、 客户端B也去请求服务器设置key的值，如果返回失败，那么就代表加锁失败
 3、 客户端A执行代码完成，删除锁
 4、 客户端B在等待一段时间后在去请求设置key的值，设置成功
 5、 客户端B执行代码完成，删除锁
**/    

$res = $redis->set($key, $value, ['nx', 'ex' => $ttl]);  //nx代表当key不存在时设置 ex代表设置过期时间
if($res){  
    // 获取资源成功
}else{
    // 资源被其他请求占用
}
```

#### 4. 问题

#####  1、 redis发现锁失败了要怎么办？中断请求还是循环请求？ -

使用循环请求，循环请求去获取锁

#####  2、 循环请求的话，如果有一个获取了锁，其它的在去获取锁的时候，是不是容易发生抢锁的可能？

针对第二个问题，在循环请求获取锁的时候，加入睡眠功能，等待几毫秒在执行循环

#####  - 3、 锁提前过期后，客户端A还没执行完，然后客户端B获取到了锁，这时候客户端A执行完了，会不会在删锁的时候把B的锁给删掉？

在加锁的时候存入的key是随机的。这样的话，每次在删除key的时候判断下存入的key里的value和自己存的是否一样

```php
do {  //针对问题1，使用循环
    $timeout = 10;
    $roomid = 10001;
    $key = 'room_lock';
    $value = 'room_'.$roomid;  //分配一个随机的值针对问题3
    $isLock = $redis->set($key, $value, 'ex', $timeout, 'nx');//ex 秒
    if ($isLock) {
        if ($redis->get($key) == $value) {  //防止提前过期，误删其它请求创建的锁
            //执行内部代码
            $redos->del($key);
            continue;//执行成功删除key并跳出循环
        }
    } else {
        usleep(5000); //睡眠，降低抢锁频率，缓解redis压力，针对问题2
    }
} while(!$isLock);
```

##### **解锁的原子化实现**

上述解锁操作中，仍存在一个问题：在确认当前锁是自己的锁之后，删除锁之前，这段时间内，锁可能会恰巧过期释放且被其他竞争者抢占，那么继续删除则删除的是别人的锁，又会出现误删问题。

因此需要将整个解锁过程原子化，使得在解锁期间，其他竞争者的任何操作不能被Redis执行。

这里我采用了Lua脚本，封装了判断标识与删除键的整个操作，通过KEYS与ARGV 数组将键与值传入:



##### 4.SETNX 和 EXPIRE 非原子性

假设一个场景中，某一个线程刚执行setnx，成功得到了锁。此时setnx刚执行成功，还未来得及执行expire命令，节点就挂掉了。此时这把锁就没有设置过期时间，别的线程就再也无法获得该锁。

**解决措施:**

由于setnx指令本身是不支持传入超时时间的，而在Redis2.6.12版本上为set指令增加了可选参数, 用法如下：

```java
SET key value [EX seconds][PX milliseconds] [NX|XX]
```

- EX second: 设置键的过期时间为second秒；
- PX millisecond：设置键的过期时间为millisecond毫秒；
- NX：只在键不存在时，才对键进行设置操作；
- XX：只在键已经存在时，才对键进行设置操作；
- SET操作完成时，返回OK，否则返回nil。

##### 设置了过期时间，如果业务还没有执行完成，但是redis锁过期了，怎么办?

需要对锁进行续约。

设置锁成功后，启动一个watchdog，每隔一段时间(比如10s)为当前分布式锁续约，也就是每隔10s重新设置当前key的超时时间。

<img src="https://s2.51cto.com/oss/202108/30/e9ad1f9a82ceed70619460100c631504.png" alt="img" style="zoom: 67%;" />

当客户端加锁成功后，可以启动一个定时任务，每隔10s(最好支持配置)来检测业务是否处理完成，检测的依据就是判断分布式锁的key是否还存在，如果存在，就进行续约。

###### 如果当前线程已经处理完，这个key是被其他客户端写入的呢?

可以为每个客户端指定一个clientID，在VALUE中增加一个clientID的前缀，这样在续锁的时候，可以判断当前分布式锁的value前缀来确定是不是当前客户端的，如果是再续锁，否则不做处理。



##### 5.**超时解锁导致并发**

如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。

A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：

- 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
- 续约：为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

##### **锁续约的看门狗实现**

以上完成与解决了锁的期限、唯一性等问题，仍存在一个问题：当锁的持有者任务未完成，但是锁已过期。此时虽然他仍可以将任务继续完成，并且也不会误删其他持锁者的锁，但是此时可能会存在多个执行者同时执行临界区代码，使得数据的一致性难以保证，造成意外的后果，分布式锁就失去了意义。

因此，需要一个锁的自动续期机制，分布式锁框架Redission中就有这么一个看门狗，专门为将要到期的锁进行续期。

```
func watchDog(goId int) {

  // 创建一个定时器NewTicker, 每隔8s触发一次

  expTicker := time.NewTicker(time.Second * 8)

  //确认锁与锁续期打包原子化

  script := redis.NewScript(`

    if redis.call('get', KEYS[1]) == ARGV[1]

    then 

      return redis.call('expire', KEYS[1], ARGV[2]) 

    else 

      return 0 

    end
    `)

  for {

    select {

    case <-expTicker.C: //因为上边是用NewTicker创建的定时器，所以每隔8s都会触发

      resp := script.Run(client, []string{lockKey}, goId, 10)

      if result, err := resp.Result(); err != nil || result == int64(0) {

        log.Println("expire lock failed", err)

      }

    case <-unlockCh: //任务完成后用户解锁通知看门狗退出

      return

    }

  }

}
```

上述代码实现了一个简单看门狗，鉴于我们的锁的默认期限是10s，因此看门狗将每隔8s触发一次，这里我们使用了go语言标准库中的Ticker实现。在select 语句中，每隔8s就会触发一次 Expire 操作进行续期，将 my_lock 键的过期时间重置为10s。注意，这里使用Lua脚本封装了确认锁与锁续期的操作，以防止误续期了其他持有者的锁。因此需要将Goroutine id传入看门狗函数中，而且不可以在看门狗函数中获取Goroutine id，因为这将获取的是看门狗线程的Goroutine id。

只需要在加锁成功时，以启动看门狗线程即可

当任务完成后，进行解锁操作时需要通知看门狗退出，这里使用了一个unlockCh 通道，当解锁时会向 unlockCh 发送一个信号，让select 去选择执行，使得看门狗线程return退出。因此，我们只需要在删除锁成功时，发送信号通知看门狗退出即可

##### **6、不可重入**

当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

##### **7、无法等待锁释放**

上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。

- 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
- 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。

##### 8.主从集群锁问题

它加锁时只作用在一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况:

- 在Redis的master节点上拿到了锁;
- 但是这个加锁的key还没有同步到slave节点;
- master故障，发生故障转移，slave节点升级为master节点;
- 导致锁丢失。

不过这种不安全也仅仅是在主从发生 failover 的情况下才会产生，而且持续时间极短，业务系统多数情况下可以容忍。

如果你很在乎高可用性，希望挂了一台 redis 完全不受影响，可以考虑 redlock。

当不同客户端连接不同的主节点时，两个客户端可以同时拥有同把锁
### zookeeper 分布式锁

### 双写一致性/缓存一致性

#### 先删除缓存，后更新数据库

该方案也会出问题，此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作） 

请求A进行写操作，删除缓存 

请求B查询发现缓存不存在 

请求B去数据库查询得到旧值 

请求B将旧值写入缓存

 请求A将新值写入数据库。 

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据

**延时双删**

先淘汰缓存
再写数据库（这两步和原来一样）

休眠1秒，再次淘汰缓存，这么做，可以将1秒内所造成的缓存脏数据，再次删除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。自行评估自己的项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。

如果使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时间差。

此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）

1. 请求 A 更新操作，删除了 Redis
2. 请求主库进行更新操作，主库与从库进行同步数据的操作
3. 请 B 查询操作，发现 Redis 中没有数据
4. 去从库中拿去数据
5. 此时同步数据还未完成，拿到的数据是旧数据

此时的解决办法就是如果是对 Redis 进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。

 **更新与读取操作进行异步串行化**

**异步串行化**

一个数据变更的操作，先执行删除缓存，然后再去更新数据库，但是还没完成更新的时候，如果此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，排在刚才更新库的操作之后，然后同步等待缓存更新完成，再读库。

**读操作去重**

多个读库更新缓存的请求串在同一个队列中是没意义的，因此可以做过滤，如果发现队列中已经有了该数据的更新缓存的请求了，那么就不用再放进去了，直接等待前面的更新操作请求完成即可，待那个队列对应的工作线程完成了上一个操作（数据库的修改）之后，才会去执行下一个操作（读库更新缓存），此时会从数据库中读取最新的值，然后写入缓存中。

如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。

#### 先更新数据库，后删除缓存

如更新数据库成功了，但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都是错误的数据了。

解决方案就是利用消息队列进行删除的补偿。

1. 请求 A 先对数据库进行更新操作
2. 在对 Redis 进行删除操作的时候发现报错，删除失败
3. 此时将Redis 的 key 作为消息体发送到消息队列中
4. 系统接收到消息队列发送的消息后再次对 Redis 进行删除操作

会有一个缺点就是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。

## Docker

### 1. 什么是 Docker 容器？

[Docker 容器]()在应用程序层创建抽象并将应用程序及其所有依赖项打包在一起。这使我们能够快速可靠地部署应用程序。容器不需要我们安装不同的操作系统。相反，它们使用底层系统的 CPU 和内存来执行任务。这意味着任何容器化应用程序都可以在任何平台上运行，而不管底层操作系统如何。我们也可以将容器视为 Docker 镜像的运行时实例。

### 2. 什么是 DockerFile？

Dockerfile 是一个文本文件，其中包含我们需要运行以构建 Docker 映像的所有命令。Docker 使用 Dockerfile 中的指令自动构建镜像。我们可以`docker build`用来创建按顺序执行多个命令行指令的自动构建。

### 3. 如何从 Docker 镜像创建 Docker 容器？

为了从镜像创建容器，我们从 Docker 存储库中提取我们想要的镜像并创建一个容器。我们可以使用以下命令：

```
$ docker run -it -d <image_name>
```



### 4. Docker Compose 可以使用 JSON 代替 YAML 吗？

是的，我们可以对[Docker Compose]()文件使用 JSON 文件而不是[YAML]()

```
$ docker-compose -f docker-compose.json up
```



### 5. 什么是Docker Swarm？

Docker Swarm 是一个容器编排工具，它允许我们跨不同主机管理多个容器。使用 Swarm，我们可以将多个 Docker 主机变成单个主机，以便于监控和管理。

### 6. 如果你想使用一个基础镜像并对其进行修改，你怎么做？

我们可以使用以下 Docker 命令将图像从 Docker Hub 拉到我们的本地系统上：

$ docker pull <image_name>

### 7. 如何启动、停止和终止容器？

要启动 Docker 容器，请使用以下命令：

$ docker start <container_id>

要停止 Docker 容器，请使用以下命令：

$ docker stop <container_id>

要终止 Docker 容器，请使用以下命令：

$ docker kill <container_id>

### 8. Docker 运行在哪些平台上？

Docker 在以下 Linux 发行版上运行：

- CentOS 6+
- Gentoo
- ArchLinux
- CRUX 3.0+
- openSUSE 12.3+
- RHEL 6.5+
- Fedora 19/20+
- Ubuntu 12.04、13.04

Docker 还可以通过以下云服务在生产中使用：

- 微软[Azure]()
- 谷歌计算引擎
- 亚马逊 AWS EC2
- 亚马逊 AWS ECS
- 机架空间

> **提示**：我们始终建议您在面试之前进行一些公司研究。要为这个特定问题做准备，请了解公司如何使用 Docker 并在您的答案中包含他们使用的平台。

### 9. 解释 Docker 组件。

三个架构组件包括 Docker 客户端、主机和注册表。

- **Docker 客户端**：该组件执行构建和运行操作以与 Docker 主机通信。
- **Docker 主机**：该组件包含 Docker 守护程序、Docker 镜像和 Docker 容器。守护进程建立到 Docker Registry 的连接。
- **Docker Registry**：该组件存储 Docker 镜像。它可以是公共注册表，例如 Docker Hub 或 Docker Cloud，也可以是私有注册表。

### 10. 虚拟化和容器化有什么区别？

虚拟机(VM)是计算机系统的仿真器，通过软件模拟具有完整硬件系统功能的、运行在一个完全隔离环境中的完整计算机系统，能提供物理计算机的功能。

虚拟机通过在当前的真实操作系统上通过 Hypervisor 技术进行虚拟机运行环境与体系的建立并通过该技术进行资源控制，一个性能较好的物理机通常可以承载多个虚拟机，每个虚拟机都会有自己操作系统。

虚拟机提供了物理机硬件级别的操作系统隔离，这让不同虚拟机之间的隔离很彻底，但也需要消耗更多资源，而有时不需要这么彻底的隔离，而更希望不消耗那么多资源，此时就可以使用容器技术。

容器可以提供操作系统级别的进程隔离，以 Docker 为例，当我们运行 Docker 容器时，此时容器本身只是操作系统中的一个进程，只是利用操作系统提供的各种功能实现了进程间网络、空间、权限等隔离，让多个 Docker 容器进程相互不知道彼此的存在

虚拟机技术与容器技术的最大区别在于：多个虚拟机使用多个操作系统内核，而多个容器共享宿主机操作系统内核。



### 11. 管理程序的功能是什么？

管理程序或虚拟机监视器是帮助我们创建和运行虚拟机的软件。它使我们能够使用单个主机来支持多个来宾虚拟机。它通过划分主机的系统资源并将它们分配给已安装的来宾环境来实现这一点。可以在单个主机操作系统上安装多个操作系统。有两种类型的管理程序：

- **Native**：本机管理程序或裸机管理程序，直接在底层主机系统上运行。它使我们可以直接访问主机系统的硬件，并且不需要基本服务器操作系统。
- **托管**：托管管理程序使用底层主机操作系统。

### 12.如何构建Dockerfile？

为了使用我们概述的规范创建映像，我们需要构建一个 Dockerfile。要构建 Dockerfile，我们可以使用以下`docker build`命令：

$ docker build <path to dockerfile>

### 13. 使用什么命令将新镜像推送到 Docker Registry？

要将新镜像推送到 Docker Registry，我们可以使用以下`docker push`命令：

$ docker push myorg/img

### 14.什么是Docker引擎？

Docker Engine 是一种开源容器化技术，我们可以使用它来构建和容器化我们的应用程序。Docker Engine 由以下组件支持：

- Docker 引擎 REST API
- Docker 命令行界面 (CLI)
- Docker 守护进程

### 15. 如何访问正在运行的容器？

要访问正在运行的容器，我们可以使用以下命令：

$ docker exec -it <container_id> bash

### 16.如何列出所有正在运行的容器？

要列出所有正在运行的容器，我们可以使用以下命令：

$ docker ps

### 17. 描述 Docker 容器的生命周期。

Docker 容器经历以下阶段：

- 创建容器
- 运行容器
- 暂停容器（可选）
- 取消暂停容器（可选）
- 启动容器
- 停止容器
- 重启容器
- 杀死容器
- 销毁容器

### 18. 什么是Docker对象标签？

Docker 对象标签是存储为字符串的键值对。它们使我们能够将元数据添加到 Docker 对象，例如容器、网络、本地守护进程、图像、Swarm 节点和服务。

### 19. 使用Docker Compose时如何保证容器1先于容器2运行？

Docker Compose 在继续下一个容器之前不会等待容器准备就绪。为了控制我们的执行顺序，我们可以使用“取决于”条件，`depends_on`。这是在 docker-compose.yml 文件中使用的示例：



```bash
version: "2.4"

services:

 backend:

   build: .

   depends_on:

     - db

 db:

   image: postgres
```

该`docker-compose up`命令将按照我们指定的依赖顺序启动和运行服务。

### 20.`docker create`命令有什么作用？

该`docker create`命令在指定映像上创建可写容器层，并准备该映像以运行指定命令。命令能够基于镜像创建容器。
该命令执行的效果类似于docker run -d，即创建一个将在系统后台运行的容器。
但是与docker run -d不同的是，docker create创建的容器并未实际启动，还需要执行docker start命令或docker run命令以启动容器。
事实上，docker create命令常用于在启动容器之前进行必要的设置。

### 21docker根据容器名查询容器

```
docker ps -a | grep* xxx
```

CONTAINER ID   IMAGE    COMMAND                   CREATED

### 22.镜像是什么

镜像是一种轻量级、可执行的独立软件保，用来打包软件运行环境和基于运行环境开发的软件，他包含运行某个软件所需的所有内容，包括代码、运行时库、环境变量和配置文件。

所有应用，直接打包[docker](https://cloud.tencent.com/product/tke?from=10680)镜像，就可以直接跑起来！

### **Docker镜像加载原理**

UnionFs（联合文件系统）：Union文件系统（UnionFs）是一种分层、轻量级并且高性能的文件系统，他支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（ unite several directories into a single virtual filesystem)。Union文件系统是 Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。

docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。 boots(boot file system）主要包含 bootloader和 Kernel, bootloader主要是引导加 kernel, Linux刚启动时会加bootfs文件系统，在 Docker镜像的最底层是 boots。这一层与我们典型的Linux/Unix系统是一样的，包含boot加載器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由 bootfs转交给内核，此时系统也会卸载bootfs。 rootfs（root file system),在 bootfs之上。包含的就是典型 Linux系统中的/dev,/proc,/bin,/etc等标准目录和文件。 rootfs就是各种不同的操作系统发行版，比如 Ubuntu, Centos等等。

#### 理解

所有的 Docker镜像都起始于一个基础镜像层，当进行修改或培加新的内容时，就会在当前镜像层之上，创建新的镜像层。

举一个简单的例子，假如基于 Ubuntu Linux16.04创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加 Python包， 就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创健第三个镜像层该像当前已经包含3个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。

在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点. 

![img](https://ask.qcloudimg.com/http-save/yehe-5751817/g2qu656bqr.png?imageView2/2/w/1620)

在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含3个文件，而镜像包含了来自两个镜像层的6个文件。

![img](https://ask.qcloudimg.com/http-save/yehe-5751817/wgs4bqymmr.png?imageView2/2/w/1620)

上图中的镜像层跟之前图中的略有区別，主要目的是便于展示文件 下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有6个文件，这是因为最上层中的文件7是文件5的一个更新版。

![img](https://ask.qcloudimg.com/http-save/yehe-5751817/ujrzdzv6jj.png?imageView2/2/w/1620)

文种情況下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中

Docker通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统

Linux上可用的存储引撃有AUFS、 Overlay2、 Device Mapper、Btrfs以及ZFS。顾名思义，每种存储引擎都基于 Linux中对应的 件系统或者块设备技术，井且每种存储引擎都有其独有的性能特点。

Docker在 Windows上仅支持 windowsfilter 一种存储引擎，该引擎基于NTFS文件系统之上实现了分层和CoW [1]。

### 为什么Docker容器这里比较小？

平时我们安装进虚拟机的CentOS都是好几个G，

对于个精简的OS,rootfs可以很小，只需要包合最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的Linux发行版， boots基本是一致的， rootfs会有差別，因此不同的发行版可以公用bootfs.

虚拟机是分钟级别，[容器](https://cloud.tencent.com/product/tke?from=10680)是秒级！

最大的好处，我觉得莫过于资源共享了！比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的[容器服务](https://cloud.tencent.com/product/tke?from=10680)了，而且镜像的每一层都可以被共享。

### 查看镜像分层的方式

可以通过docker image inspect 命令
### Docker 资源隔离：Linux Namespace

各种隔离机制实现：https://coolshell.cn/articles/17010.html

https://coolshell.cn/articles/17029.html

Linux Namespace(Linux 命名空间)是 Linux 内核(Kernel)提供的功能，它可以隔离一系列的系统资源，如 PID(进程 ID，Process ID)、User ID、Network、文件系统等。

如果你熟悉 Linux，你可能会联想到 linux 中的 chroot 命令，该命令允许将当前目录修改成根目录(即根目录 / 的挂载点切换了)，相当于文件系统被隔离了，Namespace 也具有相似的功能，但更加强大。

目前 Linux 主要提供 6 种不同类型的 Namespace，UTS、IPC、mount、PID、network、User等的隔离机制。

以一个具体的例子来解释 Namespace 的作用，假设你有一台性能非常好的计算机，你向用户出售自己的计算机的资源，每个用户买到一个 ssh 实例，为了避免不同客户之间相互干扰，你可能会对不同用户进行权限限制，让用户只能访问自己 ssh 实例下的资源。

但有些操作需要 root 权限，而我们不能将 root 权限提供给用户，此时就可以使用 Namespae 了，通过 User Namespace 对 UID 进行隔离，具体而言，UID 为 x 的用户在该 Namespace 中具有 root 权限，但在真实物理机中，他依旧是 UID 为 x 的用户，这就解决了用户间隔离的问题。

举个例子，我们都知道，Linux下的超级父亲进程的PID是1，所以，同chroot一样，如果我们可以把用户的进程空间jail到某个进程分支下，并像chroot那样让其下面的进程 看到的那个超级父进程的PID为1，于是就可以达到资源隔离的效果了（不同的PID namespace中的进程无法看到彼此）

主要是三个系统调用

- **`clone`****()** – 实现线程的系统调用，用来创建一个新的进程，并可以通过设计上述参数达到隔离。
- **`unshare`****()** – 使某进程脱离某个namespace
- **`setns`****()** – 把某进程加入到某个namespace

Docker 利用 Linux Namespace 功能实现多个 Docker 容器相互隔离，具有独立环境的功能，Go 语言对 Namespce API 进行了相应的封装，从 Docker 源码中可以看到相关的实现。

IPC全称 Inter-Process Communication，是Unix/Linux下进程间通信的一种方式，IPC有共享内存、信号量、消息队列等方法。所以，为了隔离，我们也需要把IPC给隔离开来，这样，只有在同一个Namespace下的进程才能相互通信。

### Docker 资源限制：Linux Cgroups

https://coolshell.cn/articles/17049.html



Docker 通过 Linux Namespace 帮进程隔离出自己单独的空间 / 资源，那 Docker 如何限制进程对这些资源的使用呢?

Docker 容器本质依旧是一个进程，多个 Docker 容器运行时，如果其中一个 Docker 进程占用大量 CPU 和内存就会导致其他 Docker 进程响应缓慢，为了避免这种情况，可以通过 Linux Cgroups 技术对资源进行限制。

Linux Cgroups(Linux Contorl Groups，简称 Cgroups)可以对一组进程及这些进程的子进程进行资源限制、控制和统计的能力，其中包括 CPU、内存、存储、网络、设备访问权限等，通过 Cgroups 可以很轻松的限制某个进程的资源占用并且统计该进程的实时使用情况。

##### Cgroups作用

实现 cgroups 的主要目的是为不同用户层面的资源管理提供一个统一化的接口。从单个任务的资源控制到操作系统层面的虚拟化，cgroups 提供了四大功能：

- 资源限制：cgroups 可以对任务是要的资源总额进行限制。比如设定任务运行时使用的内存上限，一旦超出就发 OOM。
- 优先级分配：通过分配的 CPU 时间片数量和磁盘 IO 带宽，实际上就等同于控制了任务运行的优先级。
- 资源统计：cgoups 可以统计系统的资源使用量，比如 CPU 使用时长、内存用量等。这个功能非常适合当前云端产品按使用量计费的方式。
- 任务控制：cgroups 可以对任务执行挂起、恢复等操作。

##### CGroup有下述术语：

- **任务（Tasks）**：就是系统的一个进程。
- **控制组（Control Group）**：一组按照某种标准划分的进程，比如官方文档中的Professor和Student，或是WWW和System之类的，其表示了某进程组。Cgroups中的资源控制都是以控制组为单位实现。一个进程可以加入到某个控制组。而资源的限制是定义在这个组上，就像上面示例中我用的haoel一样。简单点说，cgroup的呈现就是一个目录带一系列的可配置文件。
- **层级（Hierarchy）**：控制组可以组织成hierarchical的形式，既一颗控制组的树（目录结构）。控制组树上的子节点继承父结点的属性。简单点说，hierarchy就是在一个或多个子系统上的cgroups目录树。
- **子系统（Subsystem）**：一个子系统就是一个资源控制器，比如CPU子系统就是控制CPU时间分配的一个控制器。子系统必须附加到一个层级上才能起作用，一个子系统附加到某个层级以后，这个层级上的所有控制族群都受到这个子系统的控制。Cgroup的子系统可以有很多，也在不断增加中。

有个几个规则需要注意。

1. 一个 subsystem 只能附加到一个 hierarchy，而一个 hierarchy 可以附加多个 subsystem 
2. 一个进程可以作为多个 cgroup 的成员，但这些 cgroup 只能在不同的 hierarchy 中 
3. 一个进程 fork 出子进程，此时子进程与父进程默认是在同一个 cgroup 中，可以根据需要移动到其他 cgroup



##### Cgroup中的CPU资源控制

##### cpu.cfs_period_us

cfs_period_us表示一个cpu带宽，单位为微秒。系统总CPU带宽： cpu核心数 * cfs_period_us

##### cpu.cfs_quota_us

cfs_quota_us表示Cgroup可以使用的cpu的带宽，单位为微秒。cfs_quota_us为-1，表示使用的CPU不受cgroup限制。cfs_quota_us的最小值为1ms(1000)，最大值为1s。

##### cpu.shares

通过cfs_period_us和cfs_quota_us可以以绝对比例限制cgroup的cpu使用，即cfs_quota_us/cfs_period_us 等于进程可以利用的cpu cores，不能超过这个数值。



##### cgroup有哪些子系统：

- blkio — 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。
- cpu — 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。
- cpuacct — 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。
- cpuset — 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。
- devices — 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。
- freezer — 这个子系统挂起或者恢复 cgroup 中的任务。
- memory — 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成内存资源使用报告。
- net_cls — 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。
- net_prio — 这个子系统用来设计网络流量的优先级
- hugetlb — 这个子系统主要针对于HugeTLB系统进行限制，这是一个大页文件系统。

### **Gossip数据分发协议**

HyperLedger Fabric通过把工作节点分解为执行交易（背书和提交）节点和交易排序节点来优化区块链网络性能，安全性和可扩展性。这种解耦网络操作的方式需要一个安全、可靠、可扩展的数据分发协议来保证数据的完整性和一致性。为了满足这些要求，Fabric应用了**Gossip数据分发协议**。

节点利用Gossip来以一种可扩展的方式广播账本和通道数据。Gossip出来消息是连续的，并且通道上的每个节点都在不断地接收当前来自多个节点的账本中已达成一致性的数据。每个通过Gossip传输的消息都会被签名，因此由拜占庭节点发送的伪造的消息将会很容易地被识别出来，而且可以防止将消息分发到不希望发送的目标处。节点因为受到延迟、网络分区或者其他原因的影响导致缺少部分区块的情况，最终将通过联系已拥有这些缺失的区块的节点的方式，与当前账本状态进行同步。

基于Gossip的数据传播协议在Fabric网络上执行三个主要功能： 1. 通过不断识别可用的成员节点并最终监测节点离线状态的方式，对节点的发现和通道中的成员进行管理。 2. 通过通道中的所有节点来分发账本数据。任何数据未同步的节点都可以通过通道中其他节点来标识缺失的区块，并通过复制正确的数据来进行同步。 3. 通过允许点对点状态传输更新账本数据，使新加入连接的节点快速得到同步。

基于Gossip的广播由节点接收来自该通道中的其他节点的消息，然后将这些消息转发到通道上的多个随机选择的节点。这个节点数是个可配置的常数。节点也可以主动拉取消息，而不是等待消息发送。循环重复这个操作，使通道中成员的账本和状态信息不断保持和当前最新状态同步。为了传播新区块，通道中的**领导者**节点从排序服务中拉取数据，并向其他节点发送Gossip消息。

在线的节点通过持续地广播“活跃”消息来表明他们的可用性，每条消息都包含**公钥基础设施（PKI）**的ID和消息发送者对消息的签名。节点通过收集这些活跃消息来维护通道成员身份。如果没有节点能从某个特定的节点收到活跃消息，那么这个“死亡”的节点最终将从通道成员身份列表中被删除。由于“活跃”信息是通过密码学算法进行签名的，因此恶意节点无法伪装成其他节点，因为他们缺少根证书颁发机构（CA）授权的签名密钥。

除了将接收到的消息的自动转发之外，状态协程还会在每个通道上同步节点间的**世界状态**。每个节点不停地从通道中的其他节点中提取区块，以便在出现差异时修正自己的状态。由于不需要固定连接来维护基于Gossip的数据传播，因此该流程可以可靠地为共享账本保证数据的一致性和完整性，包括对节点崩溃的容错。

由于通道之间相互隔离，一个通道上的节点不能在其他任何通道上发送或共享信息。尽管任何节点都可能属于多个通道，但是通过将基于节点通道订阅的机制作为消息分发策略，节点无法将被分隔开的消息传播给不在通道中的节点。

## 设计模式
### 设计模式有哪些？
创建型包括：单例模式、工厂方法模式、抽象工厂模式、建造者模式和原型模式； 
结构型包括：代理模式、装饰模式、适配器模式、组合模式、桥梁模式、外观模式和享元模式； 
行为型包括：模板方法模式、命令模式、责任链模式、策略模式、迭代器模式、中介者模式、观察者模式、备忘录模式、访问者模式、状态模式和解释器模式。

#### 单例模式
单例模式（Singleton Pattern）是最简单的创建型设计模式。它会确保一个类只有一个实例存在。单例模式最重要的特点就是构造函数私有,从而避免外界直接使用构造函数直接实例化该类的对象。

单例模式通常有两种表现形式： 
- 饿汉式：类加载时就进行对象实例化 
- 直接创建好对象，不需要判断为空，同时也是线程安全，唯一的缺点是在导入包的同时会创建该对象，并持续占有在内存中。
```
package singleton

// Singleton 饿汉式单例
type Singleton struct{}

var singleton *Singleton

func init() {
	singleton = &Singleton{}
}

// GetInstance 获取实例
func GetInstance() *Singleton {
	return singleton
}
```
- 懒汉式：第一次引用类时才进行对象实例化 
懒汉式——非线程安全
```
//使用结构体代替类
type Tool struct {
    values int
}
//建立私有变量
var instance *Tool
//获取单例对象的方法，引用传递返回
func GetInstance() *Tool {
    if instance == nil {
        instance = new(Tool)
    }
    return instance
}
```
懒汉式--线程安全
```
//锁对象
var lock sync.Mutex
//加锁保证线程安全
func GetInstance() *Tool {
    lock.Lock()
    defer lock.Unlock()
    if instance == nil {
        instance = new(Tool)
    }
    return instance
}
```
##### 使用once实现懒汉式线程安全（用这个）
```
package main

import (
	"fmt"
	"sync"
)
type Singleton struct{}
var (
	lazySingleton *Singleton
	once          = &sync.Once{}
)

// GetLazyInstance 懒汉式
func GetLazyInstance() *Singleton {
	if lazySingleton == nil {
		once.Do(func() {
			lazySingleton = &Singleton{}
		})
	}
	return lazySingleton
}
func main()  {
	A:=GetLazyInstance()
	B:=GetLazyInstance()
	fmt.Print(A==B)
}
```
双重检查
在懒汉式（线程安全）的基础上再进行优化，减少加锁的操作，保证线程安全的同时不影响性能。
```
var lock sync.Mutex
//第一次判断不加锁，第二次加锁保证线程安全，一旦对象建立后，获取对象就不用加锁了。
func GetInstance() *Tool {
    if instance == nil {
        lock.Lock()
        if instance == nil {
            instance = new(Tool)
        }
        lock.Unlock()
    }
    return instance
}
```
#### 工厂模式
 工厂模式（Factory Method Pattern）也叫虚拟构造函数模式或多态性工厂模式,其用意是定义一个创建产品对象的工厂接口,将实际创建性工作推迟到子类中。

工厂模式可以分为简单工厂、工厂方法和抽象工厂模式 简单工厂模式严格来讲并不算是一种设计模式,更多的时候是一种编程习惯。
简单工厂模式
```
package simple

import "fmt"

// 简单工厂模式

type Girl interface {
    weight()
}

// 胖女孩
type FatGirl struct {
}

func (FatGirl) weight() {
    fmt.Println("80kg")
}

// 瘦女孩
type ThinGirl struct {
}

func (ThinGirl) weight() {
    fmt.Println("50kg")
}

type GirlFactory struct {
}

func (*GirlFactory) CreateGirl(like string) Girl {
    if like == "fat" {
        return &FatGirl{}
    } else if like == "thin" {
        return &ThinGirl{}
    }
    return nil
}
```
抽象工厂模式
```
package abstract

import (
    "fmt"
)

// 抽象工厂模式

type Girl interface {
    weight()
}

// 中国胖女孩
type FatGirl struct {
}

func (FatGirl) weight() {
    fmt.Println("chinese girl weight: 80kg")
}

// 瘦女孩
type ThinGirl struct {
}

func (ThinGirl) weight() {
    fmt.Println("chinese girl weight: 50kg")
}

type Factory interface {
    CreateGirl(like string) Girl
}

// 中国工厂
type ChineseGirlFactory struct {
}

func (ChineseGirlFactory) CreateGirl(like string) Girl {
    if like == "fat" {
        return &FatGirl{}
    } else if like == "thin" {
        return &ThinGirl{}
    }
    return nil
}

// 美国工厂
type AmericanGirlFactory struct {
}

func (AmericanGirlFactory) CreateGirl(like string) Girl {
    if like == "fat" {
        return &AmericanFatGirl{}
    } else if like == "thin" {
        return &AmericanThainGirl{}
    }
    return nil
}

// 美国胖女孩
type AmericanFatGirl struct {
}

func (AmericanFatGirl) weight() {
    fmt.Println("American weight: 80kg")
}

// 美国瘦女孩
type AmericanThainGirl struct {
}

func (AmericanThainGirl) weight() {
    fmt.Println("American weight: 50kg")
}

// 工厂提供者
type GirlFactoryStore struct {
    factory Factory
}

func (store *GirlFactoryStore) createGirl(like string) Girl {
    return store.factory.CreateGirl(like)
}
```

#### 策略模式

定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。

实现同一个接口

**应用实例:**

1. 主题的更换，每个主题都是一种策略
2. 旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略

```go
package strategy

// 策略模式

// 实现此接口，则为一个策略
type IStrategy interface {
    do(int, int) int
}

// 加
type add struct{}

func (*add) do(a, b int) int {
    return a + b
}

// 减
type reduce struct{}

func (*reduce) do(a, b int) int {
    return a - b
}

// 具体策略的执行者
type Operator struct {
    strategy IStrategy
}

// 设置策略
func (operator *Operator) setStrategy(strategy IStrategy) {
    operator.strategy = strategy
}

// 调用策略中的方法
func (operator *Operator) calculate(a, b int) int {
    return operator.strategy.do(a, b)
}
```

```go
package strategy

import (
   "fmt"
 "testing")

func TestStrategy(t *testing.T) {
   operator := Operator{}

   operator.setStrategy(&add{})
   result := operator.calculate(1, 2)
   fmt.Println("add:", result)

   operator.setStrategy(&reduce{})
   result = operator.calculate(2, 1)
   fmt.Println("reduce:", result)
}
```

## Elasticsearch

Elasticsearch 是基于 Lucene 的 Restful 的分布式实时全文搜索引擎，每个字段都被索引并可被搜索，可以快速存储、搜索、分析海量的数据。

全文检索是指对每一个词建立一个索引，指明该词在文章中出现的次数和位置。当查询时，根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程。


### elasticsearch基本概念

| ES存储结构    | Mysql存储结构 |
| :------------ | :------------ |
| Index（索引） | 表            |
| 文档          | 行，一行数据  |
| Field（字段） | 表字段        |
| mapping(映射) | 表结构定义    |

#### index

索引类似于mysql 中的数据库，Elasticesearch 中的索引是存在数据的地方，包含了一堆有相似结构的文档数据。

#### type

类型是用来定义数据结构，可以认为是 mysql 中的一张表，type 是 index 中的一个逻辑数据分类

#### document

`ES`是面向文档的数据库，文档是`ES`存储的最基本的存储单元，文档类似mysql`表中的一行数据。其实在`ES`中，文档指的就是一条JSON数据。`ES`中文档使用`JSON`格式存储，因此存储上要比`mysql`灵活的很多，因为`ES`支持任意格式的`json`数据。

#### Field

文档由多个`json`字段，这个字段跟`mysql`中的表的字段是类似的。`ES`中的字段也是有类型的，常用字段类型有：

- 数值类型(long、integer、short、byte、double、float)
- Date 日期类型
- boolean布尔类型
- Text 支持全文搜索
- Keyword 不支持全文搜索，例如：phone这种数据，用一个整体进行匹配就`ok`了，也不要进行分词处理
- Geo 这里主要用于地理信息检索、多边形区域的表达。

#### mapping

`Elasticsearch`的`mapping`类似于`mysql`中的表结构体定义，每个索引都有一个映射的规则，我们可以通过定义索引的映射规则，提前定义好文档的`json`结构和字段类型，如果没有定义索引的映射规则，`ElasticSearch`会在写入数据的时候，根据我们写入的数据字段推测出对应的字段类型，相当于自动定义索引的映射规则。

**注意：**`ES`的自动映射是很方便的，但是实际业务中，对于关键字段类型，我们都是通常预先定义好，这样可以避免`ES`自动生成的字段类型不是你想要的类型。

#### shard 分片

单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。

#### replica 副本：

任何服务器随时可能故障或宕机，此时 shard 可能会丢失，通过创建 replica 副本，可以在 shard 故障时提供备用服务，保证数据不丢失，另外 replica 还可以提升搜索操作的吞吐量。

shard 分片数量在建立索引时设置，设置后不能修改，默认5个；replica 副本数量默认1个，可随时修改数量；

#### elasticsearch的分布式特性

Elasticsearch致力于隐藏分布式系统的复杂性。以下这些操作都是在底层自动完成的:

将你的文档分区到不同的容器或者分片**(shards)**中，它们可以存在于一个或多个节点中。 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。 冗余每一个分片，防止硬件故障造成的数据丢失。 将集群中任意一个节点上的请求路由到相应数据所在的节点。 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。

#### 倒排索引

传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。

倒排索引是 关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了该关键词。

有了倒排索引，就能实现 o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。

##### 倒排索引的底层实现

是基于：FST（Finite State Transducer）数据结构。

lucene 从 4+版本后开始大量使用的数据结构是 FST。FST 有两个优点：

1、空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；

2、查询速度快。O(len(str))的查询时间复杂度。

##### FST（Finite State Transducer）

1）插入“cat”

插入cat，每个字母形成一条边，其中t边指向终点。



![img](https://pic2.zhimg.com/80/v2-faaaed78b9352325afaa9c4db03bc67d_1440w.png)



2）插入“deep”

与前一个单词“cat”进行最大前缀匹配，发现没有匹配则直接插入，P边指向终点。



![img](https://pic1.zhimg.com/80/v2-257571d300c8b82c5eba3efc5433d7ec_1440w.jpg)



3）插入“do”

与前一个单词“deep”进行最大前缀匹配，发现是d，则在d边后增加新边o，o边指向终点。



![img](https://pic3.zhimg.com/80/v2-06d65e079e2bf5a8fba86561d0c74fda_1440w.jpg)



4）插入“dog”

与前一个单词“do”进行最大前缀匹配，发现是do，则在o边后增加新边g，g边指向终点。



![img](https://pic1.zhimg.com/80/v2-a791b7a7785196b03571e2298823eb18_1440w.jpg)



5）插入“dogs”

与前一个单词“dog”进行最大前缀匹配，发现是dog，则在g后增加新边s，s边指向终点。



![img](https://pic2.zhimg.com/80/v2-b16af4e19803bd19b8fdfac9612e9e1d_1440w.jpg)



最终我们得到了如上一个有向无环图。利用该结构可以很方便的进行查询，如给定一个term “dog”，我们可以通过上述结构很方便的查询存不存在，甚至我们在构建过程中可以将单词与某一数字、单词进行关联，从而实现key-value的映射。

FST压缩率一般在3倍~20倍之间，相对于TreeMap/HashMap的膨胀3倍，内存节省就有9倍到60倍！

### ES 中常见的存储与检索的 mapping 配置项：

#### **_all：**

all 字段的作用是提供跨字段查询的支持，把 mapping 中的所有字段通过空格拼接起来做索引。ES在查询的过程中，需要指定在哪一个field里面查询。

#### _source：

source 字段用于存储 post 到 ES 的原始 json 文档。为什么要存储原始文档呢？因为 ES 采用倒排索引对文本进行搜索，而倒排索引无法存储原始输入文本。一段文本交给ES后，首先会被分析器(analyzer)打散成单词，为了保证搜索的准确性，在打散的过程中，会去除文本中的标点符号，统一文本的大小写，甚至对于英文等主流语言，会把发生形式变化的单词恢复成原型或词根，然后再根据统一规整之后的单词建立倒排索引，经过如此一番处理，原文已经面目全非。因此需要有一个地方来存储原始的信息，以便在搜到这个文档时能够把原文返回给查询者。

那么一定要存储原始文档吗？不一定！如果没有取出整个原始 json 结构体的需求，可以在 mapping 中关闭 source 字段或者只在 source 中存储部分字段（使用store）。 但是这样做有些负面影响：

（1）不能获取到原文
（2）无法reindex：如果存储了 source，当 index 发生损坏，或需要改变 mapping 结构时，由于存在原始数据，ES可以通过原始数据自动重建index，如果不存 source 则无法实现
（3）无法在查询中使用script：因为 script 需要访问 source 中的字段

#### **store：**

store 决定一个字段是否要被单独存储



（1）如果禁用了 source 保存，可以通过指定 store 属性来单独保存某个或某几个字段，而不是将整个输入文档保存到 source 中。

（2）如果 source 中有长度很长的文本（如一篇文章）和较短的文本（如文章标题），当只需要取出标题时，如果使用 source 字段，ES需要读取整个 source 字段，然后返回其中的 title，由此会引来额外的IO开销，降低效率。此时可以选择将 title 的 store 设置为true，在 source 字段外单独存储一份。读取时不必在读取整 source 字段了。但是需要注意，应该避免使用 store 查询多个字段，因为 store 的存储在磁盘上不连续，ES在读取不同的 store 字段时，每个字段的读取均需要在磁盘上进行查询操作，而使用 source 字段可以一次性连续读取多个字段。

#### doc_values：

倒排索引可以提供全文检索能力，但是无法提供对排序和数据聚合的支持。doc_values 本质上是一个序列化的列式存储结构，适用于聚合（aggregations）、排序（Sorting）、脚本（scripts access to field）等操作。默认情况下，ES几乎会为所有类型的字段存储doc_value，但是 text 或 text_annotated 等可分词字段不支持 doc values 。如果不需要对某个字段进行排序或者聚合，则可以关闭该字段的doc_value存储。

##### **doc_values 的作用：**

        倒排索引虽然可以提高搜索性能，但也存在缺陷，比如我们需要对数据做排序或聚合等操作时，lucene 会提取所有出现在文档集合的排序字段，然后构建一个排好序的文档集合，而这个步骤是基于内存的，如果排序数据量巨大的话，容易造成内存溢出和性能缓慢。
    
        doc_values 就是 es 在构建倒排索引的同时，会对开启 doc_values 的字段构建一个有序的 “document文档 ==> field value” 的列式存储映射，可以看作是以文档维度，实现了根据指定字段进行排序和聚合的功能，降低对内存的依赖。另外 doc_values 保存在操作系统的磁盘中，当 doc_values 大于节点的可用内存，ES可以从操作系统页缓存中加载或弹出，从而避免发生内存溢出的异常，但如果 docValues 远小于节点的可用内存，操作系统就自然将所有 doc_values 存于内存中（堆外内存），有助于快速访问。
##### doc_values 与 source 的区别？使用 docvalue_fields 检索指定的字段？

post 提交到 ES 的原始 Json 文档都存储在 source 字段中，默认情况下，每次搜索的命中结果都包含文档 source，即使仅请求少量字段，也必须加载并解析整个 source 对象，而 source 每次使用时都必须加载和解析，所以使用 source 非常慢。为避免该问题，当我们只需要返回相当少的支持 doc_values 的字段时，可以使用 docvalue_fields 参数获取选定字段的值。

doc values 存储与 _source 相同的值，但在磁盘上基于列的结构中进行了优化，以进行排序和汇总。由于每个字段都是单独存储的，因此 Elasticsearch 仅读取请求的字段值，并且可以避免加载整个文档 _source。通过 docvalue_fields 可以从建好的列式存储结果中直接返回字段值，毕竟 source 是从一大片物理磁盘去，理论上从 doc values 处拿这个字段值会比 source 要快一点，页面抖动少一点。

##### **如何在 ES 中使用 doc values？**

doc values 通过牺牲一定的磁盘空间带来的好处主要有两个：

- 节省内存
- 提升排序，分组等聚合操作的性能

1.我们首先关注如何激活 doc values，只要开启 doc values 后，排序，分组，聚合的时候会自动使用 doc values 提速。在 ElasticSearch 中，doc values 默认是开启的，比较简单暴力，我们也可以酌情关闭一些不需要使用 doc values 的字段，以节省磁盘空间，只需要设置 doc_values 为 false 就可以了

2.使用 docvalue_fields 的检索指定的字段

#### index：

控制倒排索引，用于标识指定字段是否需要被索引。默认情况下是开启的，如果关闭了 index，则该字段的内容不会被 analyze 分词，也不会存入倒排索引，即意味着该字段无法被搜索。

#### 6、enabled：

这是一个 index 和 doc_value 的总开关，如果 enabled 设置为false，则这个字段将会仅存在于 source 中，其对应的 index 和 doc_value 都不会被创建。这意味着，该字段将不可以被搜索、排序或者聚合，但可以通过 source 获取其原始值。

#### 7、term_vector：

在对文本进行 analyze 的过程中，可以保留有关分词结果的相关信息，包括单词列表、单词之间的先后顺序、单词在原文中的位置等信息。查询结果返回的高亮信息就可以利用其中的数据来返回。默认情况下，term_vector是关闭的，如有需要（如加速highlight结果）可以开启该字段的存储。


### text 和 keyword类型的区别：

        两个类型的区别主要是分词：keyword 类型是不会分词的，直接根据字符串内容建立倒排索引，所以keyword类型的字段只能通过精确值搜索到；Text 类型在存入 Elasticsearch 的时候，会先分词，然后根据分词后的内容建立倒排索引
### **query 和 filter 的区别？**

（1）query：查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；

（2）filter：查询操作仅判断是否满足查询条件，不会计算任何分值，也不会关心返回的排序问题，同时，filter 查询的结果可以被缓存，提高性能。

